<html>
<head>
<title>The future of photography is code • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">摄影的未来是代码 TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2018/10/22/the-future-of-photography-is-code/">https://web.archive.org/web/https://techcrunch.com/2018/10/22/the-future-of-photography-is-code/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">相机里有什么？一个镜头，一个快门，一个感光表面，以及越来越多的一套高度复杂的算法。虽然物理组件仍在一点一点地改进，但谷歌、三星和苹果正越来越多地投资(并展示)完全由代码构成的改进。计算摄影是现在唯一真正的战场。</p>
<p class="translated">这种转变的原因很简单:相机不可能比现在的<em>好太多，或者至少在它们的工作方式没有一些相当极端的转变的情况下是不可能的。以下是智能手机制造商如何在摄影上碰壁，以及他们如何被迫跳过它。</em></p>
<h2 class="translated">没有足够的水桶</h2>
<p/><div id="attachment_1414873" class="wp-caption aligncenter"><a href="https://web.archive.org/web/20230128120905/https://techcrunch.com/wp-content/uploads/2016/11/gettyimages-155858842_image-sensor.jpg"><img aria-describedby="caption-attachment-1414873" decoding="async" loading="lazy" class="breakout size-full wp-image-1414873" src="../Images/689e862c48af8e1cb72c9fe31bb27d24.png" alt="" srcset="https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2016/11/gettyimages-155858842_image-sensor.jpg 2092w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2016/11/gettyimages-155858842_image-sensor.jpg?resize=150,103 150w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2016/11/gettyimages-155858842_image-sensor.jpg?resize=300,205 300w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2016/11/gettyimages-155858842_image-sensor.jpg?resize=768,526 768w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2016/11/gettyimages-155858842_image-sensor.jpg?resize=680,466 680w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2016/11/gettyimages-155858842_image-sensor.jpg?resize=1536,1052 1536w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2016/11/gettyimages-155858842_image-sensor.jpg?resize=2048,1403 2048w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2016/11/gettyimages-155858842_image-sensor.jpg?resize=1200,822 1200w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2016/11/gettyimages-155858842_image-sensor.jpg?resize=50,34 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2016/11/gettyimages-155858842_image-sensor.jpg"/></a><p id="caption-attachment-1414873" class="wp-caption-text translated">数码相机中的图像传感器</p></div>
<p class="translated">我们智能手机摄像头中的传感器是真正令人惊叹的东西。索尼、OmniVision、三星和其他公司在设计和制造微小而敏感的多功能芯片方面所做的工作真的非常令人兴奋。对于一个从早期就开始关注数码摄影发展的摄影师来说，这些微型传感器提供的质量水平是惊人的。</p>
<p class="translated">但是这些传感器没有摩尔定律。或者说，正如摩尔定律现在在亚 10 纳米水平上遇到量子极限一样，相机传感器在更早的时候就达到了物理极限。想象光线打在传感器上就像雨水落在一堆水桶上；可以放大一点的桶，但是少一点；你可以放小一点的，但是它们每个都抓不到那么多；你可以把它们弄成方形，或者交错排列，或者做其他各种各样的把戏，但最终只有这么多雨滴，再多的水桶重新排列也改变不了这一点。</p>
<p class="translated">没错，传感器正在变得越来越好，但这种速度不仅太慢，无法让消费者年复一年地购买新手机(想象一下，试图出售一款好 3%的相机)，而且手机制造商经常使用相同或类似的相机堆栈，因此这些改进(如最近改用背面照明)是他们共同分享的。因此，没有人能单独在传感器上领先。</p>

<p class="translated">也许他们可以改进镜头？不完全是。透镜已经达到了难以改进的精密和完美的水平，尤其是在小范围内。说智能手机摄像头堆栈内的空间有限是一种轻描淡写的说法——几乎没有一平方微米可以节省。你也许可以稍微改善它们，只要有多少光通过，失真有多小，但这些都是老问题，大多已经优化。</p>
<p class="translated">收集更多光线的唯一方法是增加透镜的尺寸，要么让它 A:从身体向外突出；b:替换身体内的关键部件；或者 C:增加手机厚度。苹果可能会接受这些选项中的哪一个？</p>
<p class="translated">回想起来，苹果(以及三星、华为和其他公司)不得不选择 D:以上都不是。如果你不能得到更多的光，你只需要用你现有的光做更多的事情。</p>
<h2 class="translated">摄影不都是计算的吗？</h2>
<p class="translated">计算摄影最广泛的定义包括所有的数字成像。与胶片不同，即使是最基本的数码相机也需要计算才能将照射到传感器上的光线转化为可用的图像。相机制造商在这方面有很大不同，生产不同的 JPEG 处理方法、RAW 格式和颜色科学。</p>
<p class="translated">很长一段时间以来，人们对这个基础层没有太多兴趣，部分原因是缺乏处理能力。当然，已经有了滤镜和快速的相机内置调整来提高对比度和色彩。但最终这些只是自动拨号盘。</p>
<p class="translated"><a href="https://web.archive.org/web/20230128120905/https://techcrunch.com/wp-content/uploads/2018/04/object-recognition-color.png"><img decoding="async" loading="lazy" class="breakout aligncenter size-full wp-image-1623191" src="../Images/cc66065d836a7e1dec4090da4543969a.png" alt="" srcset="https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/04/object-recognition-color.png 2560w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/04/object-recognition-color.png?resize=150,84 150w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/04/object-recognition-color.png?resize=300,169 300w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/04/object-recognition-color.png?resize=768,432 768w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/04/object-recognition-color.png?resize=680,383 680w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/04/object-recognition-color.png?resize=1536,864 1536w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/04/object-recognition-color.png?resize=2048,1152 2048w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/04/object-recognition-color.png?resize=1200,675 1200w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/04/object-recognition-color.png?resize=50,28 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/04/object-recognition-color.png"/>T2】</a></p>
<p class="translated">第一个真正的计算摄影功能可以说是为了自动对焦而进行的物体识别和跟踪。面部和眼睛跟踪使捕捉复杂光线或姿势中的人物变得更容易，而物体跟踪使体育和动作摄影变得更容易，因为系统会将自动对焦点调整为在帧中移动的目标。</p>
<p class="translated">这些是早期的例子<em>从图像中获取元数据并主动使用它</em>，以改进该图像或反馈到下一个图像。</p>
<p class="translated">在单反相机中，自动对焦的准确性和灵活性是标志性的特点，所以这个早期的用例是有意义的；但是除了一些噱头之外，这些“严肃”的相机通常以相当普通的方式部署计算。更快的图像传感器意味着更快的传感器卸载和突发速度，一些额外的周期专用于颜色和细节保存等等。数码单反相机没有被用于直播视频或增强现实。直到最近，智能手机摄像头也是如此，它更像是傻瓜相机，而不是我们今天所知的多功能媒体工具。</p>
<h2 class="translated">传统成像的局限性</h2>
<p class="translated">【T2<img decoding="async" loading="lazy" class="breakout aligncenter size-full wp-image-1546344" src="../Images/2cc5b5a8e7ec029f9dff535ddbe4579b.png" alt="" srcset="https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2017/09/iphone_xray.jpg 887w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2017/09/iphone_xray.jpg?resize=150,95 150w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2017/09/iphone_xray.jpg?resize=300,190 300w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2017/09/iphone_xray.jpg?resize=768,487 768w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2017/09/iphone_xray.jpg?resize=680,432 680w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2017/09/iphone_xray.jpg?resize=50,32 50w" sizes="(max-width: 887px) 100vw, 887px" data-original-src="https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2017/09/iphone_xray.jpg"/></p>
<p class="translated">尽管到处都有实验，偶尔也有例外，但智能手机摄像头几乎是一样的。它们必须安装在几毫米的深度内，这将它们的光学系统限制在几个配置内。传感器的尺寸同样受到限制——DSLR 可能使用 23×15 毫米宽的 APS-C 传感器，面积为 345 毫米<sup>2</sup>；iPhone XS 中的传感器可能是目前市场上最大和最先进的，大约为 7 乘 5.8 毫米，总共为 40.6 毫米<sup> 2 </sup>。</p>
<p class="translated">粗略地说，它收集的光线比“普通”相机少一个数量级，但有望以大致相同的保真度、颜色等重建场景——大约相同的百万像素数量。从表面上看，这是一个不可能解决的问题。</p>
<p class="translated">传统意义上的改进有所帮助——例如，光学和电子稳定，使得曝光时间更长而不模糊，收集更多的光成为可能。但是这些设备仍然被要求把稻草变成金子。</p>
<p class="translated">幸运的是，正如我提到的，每个人都差不多在同一条船上。由于游戏中的基本限制，苹果或三星不可能重新发明相机或提出一些疯狂的镜头结构，使他们在竞争中领先。它们都被赋予了相同的基础。</p>
<p class="translated">因此，所有的竞争都包括这些公司在这个基础上建立的东西。</p>
<h2 class="translated">图像作为流</h2>
<p class="translated">【T2<img decoding="async" loading="lazy" class="breakout aligncenter size-full wp-image-1711284" src="../Images/50129d7803cded6ea3a1e275c899bcb5.png" alt="" srcset="https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/09/cam3.jpg 1203w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/09/cam3.jpg?resize=150,93 150w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/09/cam3.jpg?resize=300,186 300w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/09/cam3.jpg?resize=768,477 768w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/09/cam3.jpg?resize=680,422 680w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/09/cam3.jpg?resize=1200,745 1200w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/09/cam3.jpg?resize=50,31 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/09/cam3.jpg"/></p>
<p class="translated">计算摄影的关键在于，来自数码相机传感器的图像不是人们通常认为的快照。在传统相机中，快门打开和关闭，曝光感光介质几分之一秒。这不是数码相机能做的，或者至少不是它们能做的。</p>
<p class="translated">照相机的传感器不断受到光的轰击；回到我们的比喻，雨水不断地落在水桶上，但当你不拍照时，这些水桶是无底的，没有人检查它们的内容。但是雨还是在下。</p>
<p class="translated">为了捕捉图像，相机系统选择一个点开始计数雨滴，测量到达传感器的光。然后它选择一个点停下来。对于传统摄影来说，这可以实现几乎任意短的快门速度，这对微小的传感器来说没什么用。</p>
<p class="translated">为什么不一直录音呢？理论上你可以，但这会耗尽电池并产生大量热量。幸运的是，在过去的几年里，图像处理芯片已经变得足够高效，当相机应用程序打开时，它们可以保持该流的特定持续时间——例如，有限分辨率的最后 60 帧捕捉。当然，它需要一点电池，但它是值得的。</p>
<p class="translated">访问流允许摄像机做各种事情。它添加了<em>上下文。</em></p>
<p class="translated">背景可能意味着很多事情。它可以是摄影元素，如光线和主体的距离。但也可以是动作、物体、意图。</p>
<p class="translated">一个简单的例子就是通常所说的 HDR 或高动态范围影像。这种技术使用连续拍摄的具有不同曝光的多个图像来更准确地捕捉图像中可能在单次曝光中曝光不足或曝光过度的区域。这种情况下的背景是理解这些是哪些区域，以及如何智能地将图像组合在一起。</p>
<p class="translated">这可以通过曝光包围来实现，这是一种非常古老的摄影技术，但如果图像流一直被操纵来产生多个曝光范围，它可以立即完成，并且没有警告。这正是谷歌和苹果现在所做的。</p>
<p class="translated">【T2<img decoding="async" loading="lazy" class="breakout aligncenter size-full wp-image-1735741" src="../Images/e3e0635eece89a1fcaf7ed83419b4e57.png" alt="" srcset="https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/10/bokeh.jpg 1087w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/10/bokeh.jpg?resize=150,91 150w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/10/bokeh.jpg?resize=300,183 300w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/10/bokeh.jpg?resize=768,468 768w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/10/bokeh.jpg?resize=680,414 680w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/10/bokeh.jpg?resize=50,30 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/10/bokeh.jpg"/></p>
<p class="translated">更复杂的当然是越来越普遍的“肖像模式”和人工背景模糊或散景。这里的上下文不仅仅是一张脸的距离，而是对图像的哪些部分构成特定物理对象以及该对象的确切轮廓的理解。这可以从流中的运动、从多个相机中的立体分离、以及从已经被训练来识别和描绘人类形状的机器学习模型中导出。</p>
<p class="translated">这些技术之所以可行，首先是因为首先已经从数据流中捕获了必要的图像(图像传感器和 RAM 速度的进步)，其次是因为公司开发了高效的算法来执行这些计算，这些算法是在巨大的数据集和大量的计算时间上训练出来的。</p>
<p class="translated">然而，这些技术的重要之处不仅仅在于它们可以实现，而是一家公司可能比另一家公司做得更好。这种质量完全是软件工程工作和艺术监督的功能。</p>

<p class="translated">DxOMark 做了一些早期人工散景系统的对比；然而，结果并不令人满意。这与其说是哪个看起来更好的问题，不如说是他们在应用效果上是成功还是失败的问题。计算摄影还处于早期阶段，这个功能足以给人们留下深刻印象。就像一只用后腿走路的狗，我们惊讶于它的出现。</p>
<p class="translated">但苹果已经推出了一些人会说是对散景问题近乎荒谬的过度设计的解决方案。它不仅学会了如何复制这种效果——它还利用自己掌握的计算能力，创建了产生这种效果的光学现象的虚拟物理模型。这就像动画一个弹跳的球和模拟现实的重力和弹性材料物理的区别。</p>
<p class="translated">为什么要走这么远？因为苹果知道其他人越来越清楚的事情:担心计算能力的极限是荒谬的。如果你走高斯模糊这样的捷径，光学现象的复制效果是有限的。如果你在光子的层面上模拟它，那么它的复制是没有限制的。</p>
<p class="translated">类似地，将 5 张、10 张或 100 张照片组合成一张 HDR 照片的想法似乎很荒谬，但事实是，在摄影中，信息越多越好。如果这些计算技巧的成本可以忽略不计，结果可以衡量，为什么我们的设备不应该执行这些计算呢？几年后，它们也会变得普通。</p>
<p class="translated">如果结果是一个更好的产品，计算能力和工程能力已经部署成功；正如徕卡或佳能可能会花费数百万美元来弥补一个稳定的光学系统(如 2000 美元的变焦镜头)的微小性能改善，苹果和其他公司正在他们可以创造价值的地方花钱:不是在玻璃上，而是在硅上。</p>
<h2 class="translated">复视觉</h2>
<p class="translated">一个可能与我描述的计算摄影叙事相冲突的趋势是由多个相机组成的系统的出现。</p>
<p class="translated">这种技术不会给传感器增加更多的光——从光学角度来看，这将是非常复杂和昂贵的，而且可能无论如何都不会起作用。但是如果你能纵向腾出一点空间(而不是我们认为不切实际的深度方向)，你可以在第一个旁边放一个完整的独立相机，拍摄与第一个非常相似的照片。</p>
<p/><div id="attachment_1668316" class="wp-caption aligncenter"><a href="https://web.archive.org/web/20230128120905/https://techcrunch.com/wp-content/uploads/2018/07/1iphones.jpg"><img aria-describedby="caption-attachment-1668316" decoding="async" loading="lazy" class="breakout size-full wp-image-1668316" src="../Images/67bf0cf45e91d0fd226161361b8be7d9.png" alt="" srcset="https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/07/1iphones.jpg 2500w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/07/1iphones.jpg?resize=150,84 150w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/07/1iphones.jpg?resize=300,169 300w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/07/1iphones.jpg?resize=768,432 768w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/07/1iphones.jpg?resize=680,382 680w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/07/1iphones.jpg?resize=1536,864 1536w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/07/1iphones.jpg?resize=2048,1152 2048w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/07/1iphones.jpg?resize=1200,675 1200w, https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/07/1iphones.jpg?resize=50,28 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230128120905im_/https://techcrunch.com/wp-content/uploads/2018/07/1iphones.jpg"/></a><p id="caption-attachment-1668316" class="wp-caption-text translated">一系列彩色 iPhones 的实体模型</p></div>
<p class="translated">现在，如果你想做的只是以难以察觉的比例重现韦恩的世界(一号摄像机、二号摄像机……一号摄像机、二号摄像机……)，这就是你所需要的。但是没有人真的想同时拍摄两张相距不到一英寸的照片。</p>
<p class="translated">这两个相机要么独立工作(广角和变焦)，要么一个用于增强另一个，形成一个具有多个输入的单一系统。</p>
<p class="translated">事情是这样的，从一个摄像头获取数据并使用它来增强另一个摄像头的数据——你猜对了——计算量非常大。这就像多重曝光的 HDR 问题，除了更复杂，因为图像不是用相同的镜头和传感器拍摄的。它可以优化，但这并不容易。</p>
<p class="translated">所以虽然增加第二个摄像头确实是物理手段改善成像系统的一种方式，但是可能性只是因为计算摄影的状态而存在。计算图像的质量决定了照片的好坏。带有 16 个传感器和镜头的轻型相机是一个雄心勃勃的努力的例子，它根本没有产生更好的图像，尽管它使用成熟的计算摄影技术来收集和筛选更大的图像集合。</p>
<h2 class="translated">光和代码</h2>
<p class="translated">摄影的未来是计算的，而不是光学的。这是一个巨大的范式转变，每个制造或使用相机的公司目前都在努力应对。这将在传统相机中产生影响，如单反相机(迅速让位于无反光镜系统)、手机、嵌入式设备以及任何可以捕捉光线并将其转化为图像的地方。</p>
<p class="translated">有时，这意味着我们听到的相机将与去年的相机大同小异，就百万像素计数、ISO 范围、f 数等而言。没关系。除了一些例外，这些已经变得和我们合理预期的一样好了:眼镜没有变得更清晰，我们的视觉没有变得更敏锐。光线穿过我们的设备和眼球的方式不太可能发生太大变化。</p>
<p class="translated">然而，这些设备对光的作用正以令人难以置信的速度变化着。这将产生听起来荒谬的功能，或舞台上的伪科学胡言乱语，或耗尽的电池。那也没关系。正如我们在上个世纪对相机的其他部分进行了实验，并使它们达到不同程度的完美，我们已经进入了一个新的，非物理的“部分”，但它对我们拍摄的图像的质量甚至可能性有着非常重要的影响。</p>
			</div>

			</div>    
</body>
</html>