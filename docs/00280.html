<html>
<head>
<title>Facebook says it removed 8.7M child exploitation posts with new machine learning tech • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">脸书称用新的机器学习技术TechCrunch删除了870万个剥削儿童的帖子</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2018/10/24/facebook-says-it-removed-8-7m-child-exploitation-posts-with-new-machine-learning-tech/">https://web.archive.org/web/https://techcrunch.com/2018/10/24/facebook-says-it-removed-8-7m-child-exploitation-posts-with-new-machine-learning-tech/</a></blockquote><div><header class="article__header ">
	<p class="article__title-wrapper">
						</p><h1 class="article__title translated">脸书称用新的机器学习技术删除了870万个剥削儿童的帖子</h1>
		

			
	
			
	</header>

			<div class="article-content">
				<p id="speakable-summary" class="translated">脸书今天宣布，由于采用了新技术，上个季度已经删除了870万条违反禁止剥削儿童规定的内容。脸书全球安全主管Antigone Davis在一篇博客文章中<a href="https://web.archive.org/web/20221203134734/https://newsroom.fb.com/news/2018/10/fighting-child-exploitation/">说，该公司在过去一年中开发和实施的新的人工智能和机器学习技术，在任何人举报之前删除了99%的帖子。</a></p>
<p class="translated">这项新技术可以检查上传的儿童裸体和其他剥削内容，如果有必要，照片和账户会报告给国家失踪和被剥削儿童中心。脸书已经在使用<a href="https://web.archive.org/web/20221203134734/https://techcrunch.com/2017/04/05/facebook-addresses-revenge-porn-with-tech-to-prevent-people-from-re-sharing-intimate-images/">照片匹配技术</a>将新上传的照片与已知的儿童剥削和报复色情图片进行比较，但新工具旨在防止之前未经确认的内容通过其平台传播。</p>
<p class="translated">这项技术并不完美，许多家长抱怨他们孩子的无关痛痒的照片被删除了。Davis在她的帖子中提到了这一点，她写道，为了“避免潜在的滥用，我们也对非性内容采取行动，比如看似温和的儿童洗澡照片”，这种“综合方法”是脸书上个季度删除如此多内容的原因之一。</p>
<p class="translated">但是脸书的调节技术绝非完美，许多人认为它不够全面或准确。除了家庭快照，它还被批评删除了一些内容，比如被称为“凝固汽油弹女孩”的潘氏潘金淑在1972年的标志性照片，她在南越凝固汽油弹袭击她的村庄时遭受三度烧伤后裸体逃离，首席运营官·雪莉·桑德伯格为这个决定道歉。</p>
<p class="translated">去年，该公司的节制政策也受到了英国国家防止虐待儿童协会的批评，该协会呼吁社交媒体公司接受独立的节制，并对不合规者进行罚款。脸书直播的推出有时也让平台及其版主(软件和人)不堪重负，播放着性侵、自杀和谋杀的视频——包括一个11个月大的婴儿被其父亲杀害的视频。</p>
<p class="translated">然而，调节社交媒体内容是基于人工智能的自动化如何惠及人类工人的一个值得注意的例子。上个月，<a href="https://web.archive.org/web/20221203134734/https://www.nytimes.com/2018/09/25/technology/facebook-moderator-job-ptsd-lawsuit.html">前脸书内容版主赛琳娜·斯科拉起诉了</a>公司，声称观看数以千计的暴力图像导致她患上了创伤后应激障碍。其他主持人，其中许多是承包商，也谈到了这份工作的心理负担，并说脸书没有提供足够的培训、支持或经济补偿。</p>
			</div>

			</div>    
</body>
</html>