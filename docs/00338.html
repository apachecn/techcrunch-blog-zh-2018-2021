<html>
<head>
<title>YC-backed Observant uses the iPhone's infrared depth sensors to analyze user emotions • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">YC支持的Observant使用iPhone的红外深度传感器来分析用户情绪TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2018/10/29/observant-launch/">https://web.archive.org/web/https://techcrunch.com/2018/10/29/observant-launch/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">观察力敏锐的发现了一种使用iPhone X、XS和XR上的奇特红外深度传感器的新方法:分析人们的面部表情，以了解他们对一件产品或一段内容的反应。</p>
<p class="translated">Observant是加速器Y Combinator冬季创业公司的一员，但在演示日仍处于隐形模式<a href="https://web.archive.org/web/20221212135149/https://techcrunch.com/2018/03/19/here-are-64-startups-that-launched-today-at-y-combinators-w18-demo-day/">。它是由错误报告产品</a><a href="https://web.archive.org/web/20221212135149/https://buglife.com/"> Buglife </a>的同一家公司创建的，首席执行官戴夫·舒金说他的团队创建它是因为他们想找到更好的方法来捕捉用户的反应。</p>
<p class="translated">我们已经写了其他创业公司试图使用网络摄像头和<a href="https://web.archive.org/web/20221212135149/https://techcrunch.com/2017/02/19/unlocking-the-potential-of-eye-tracking-technology/">眼球追踪</a>做类似的事情<a href="https://web.archive.org/web/20221212135149/https://techcrunch.com/2016/05/25/affectiva-raises-14-million-to-bring-apps-robots-emotional-intelligence/">，但是Schukin(他与首席技术官Daniel DeCovnick共同创立了该公司)认为这些方法不如Observant的方法准确——特别是，他认为它们不能捕捉更微妙的“微表情”，并且在弱光环境下也做得不好。</a></p>
<p class="translated">相比之下，他说，无论光线如何，红外深度传感器都可以绘制出你的面部高层次细节，Observant还创造了深度学习技术，可以实时将面部数据转化为情绪。</p>
<p class="translated">Observant创建了一个可以安装在任何iOS应用程序中的SDK，它可以提供完整的实时情绪分析流，也可以提供与特定应用程序内事件相关的用户响应的单独快照。该产品目前只接受邀请，但Schukin表示，它已经在一些零售和电子商务应用程序中使用，并且还用于焦点小组测试。</p>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-large wp-image-1738924" src="../Images/a9871b1834a7c20d9162230eacc68caa.png" alt="Observant" srcset="https://web.archive.org/web/20221212135149im_/https://techcrunch.com/wp-content/uploads/2018/10/w99bBp1w.png 1751w, https://web.archive.org/web/20221212135149im_/https://techcrunch.com/wp-content/uploads/2018/10/w99bBp1w.png?resize=150,91 150w, https://web.archive.org/web/20221212135149im_/https://techcrunch.com/wp-content/uploads/2018/10/w99bBp1w.png?resize=300,182 300w, https://web.archive.org/web/20221212135149im_/https://techcrunch.com/wp-content/uploads/2018/10/w99bBp1w.png?resize=768,466 768w, https://web.archive.org/web/20221212135149im_/https://techcrunch.com/wp-content/uploads/2018/10/w99bBp1w.png?resize=680,413 680w, https://web.archive.org/web/20221212135149im_/https://techcrunch.com/wp-content/uploads/2018/10/w99bBp1w.png?resize=1536,932 1536w, https://web.archive.org/web/20221212135149im_/https://techcrunch.com/wp-content/uploads/2018/10/w99bBp1w.png?resize=1200,728 1200w, https://web.archive.org/web/20221212135149im_/https://techcrunch.com/wp-content/uploads/2018/10/w99bBp1w.png?resize=50,30 50w" sizes="(max-width: 680px) 100vw, 680px" data-original-src="https://web.archive.org/web/20221212135149im_/https://techcrunch.com/wp-content/uploads/2018/10/w99bBp1w.png?w=680"/></p>
<p class="translated">当然，你的iPhone捕捉你所有的面部表情的想法可能听起来有点令人毛骨悚然，所以他强调，随着Observant带来新客户，它正在与他们合作，以确保在收集数据时，“用户非常清楚它是如何被使用的。”此外，所有的分析实际上都发生在用户的设备上，所以没有面部镜头或生物数据被上传。</p>
<p class="translated">最后，Schukin建议这项技术可以应用得更广泛，无论是通过帮助公司提供更好的建议，为他们的聊天机器人引入更多的“情绪智能”，甚至是检测困倦驾驶。</p>
<p class="translated">至于当Observant只在三款手机上工作时，它是否能实现这些目标，Schukin说，“当我们开始在这方面工作近一年时，iPhone X是唯一一款(带有这些深度传感器的)iPhone。我们当时的想法是，我们知道苹果是如何工作的，我们知道这项技术是如何随着时间的推移而传播的，所以我们打算打赌，最终这些深度传感器将出现在每部iPhone和每部iPad上，它们将在Android上被模仿和复制。”</p>
<p class="translated">因此，虽然现在说观察的赌注是否会有回报还为时过早，但Schukin指出，这些传感器已经从一个<a href="https://web.archive.org/web/20221212135149/https://techcrunch.com/2018/09/12/comparing-iphone-xs-vs-xs-max-vs-xr/">扩展到三个iPhone型号</a>的事实表明事情正在朝着正确的方向发展。</p>
			</div>

			</div>    
</body>
</html>