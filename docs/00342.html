<html>
<head>
<title>Privacy group calls on US government to adopt universal AI guidelines to protect safety, security and civil liberties • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">隐私组织呼吁美国政府采用通用人工智能准则来保护安全、安保和公民自由TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2018/10/29/us-government-universal-artificial-intelligence-guidelines/">https://web.archive.org/web/https://techcrunch.com/2018/10/29/us-government-universal-artificial-intelligence-guidelines/</a></blockquote><div><header class="article__header ">
	<p class="article__title-wrapper">
						</p><h1 class="article__title translated">隐私组织呼吁美国政府采用通用人工智能准则来保护安全、安保和公民自由</h1>
		

			
	
			
	</header>

			<div class="article-content">
				<p id="speakable-summary" class="translated">经过几个月的工作，一套旨在保护人类免受人工智能带来的一系列威胁的指导方针已经提出。</p>
<p class="translated">现在，一个隐私组织希望美国政府也采纳它们。</p>
<p class="translated">上周在布鲁塞尔举行的一次会议上公布的12条通用指导方针<a href="https://web.archive.org/web/20221025223234/https://thepublicvoice.org/ai-universal-guidelines/">旨在通过在降低风险的同时最大化收益来“告知和改善人工智能的设计和使用”。多年来，人工智能一直是基于机器的决策的统称，但随着技术变得更好，被更广泛地采用，基于人工智能的成果对人类生活产生了更大的影响——从获得信贷、就业，甚至到</a><a href="https://web.archive.org/web/20221025223234/https://www.wired.com/2017/04/courts-using-ai-sentence-criminals-must-stop-now/">刑事判决</a>。</p>
<p class="translated">但是<a href="https://web.archive.org/web/20221025223234/https://hbr.org/2018/07/we-need-transparency-in-algorithms-but-too-much-can-backfire">这些决定</a>通常是由专有的封闭算法做出的，因此几乎不可能知道这些决定是否公平或合理。</p>
<p class="translated">根据电子隐私信息中心(EPIC)的说法，这些指导方针是为了确保对人权的保护而设计的。这包括有权了解决定结果所使用的因素、逻辑和技术；消除歧视性决策的公平义务；以及保护系统免受网络安全威胁的义务。这些原则还包括禁止单一评分——以防止政府使用人工智能为其公民和居民评分——这是对中国有争议的社会信用体系的微妙抨击。</p>
<p class="translated">现在，EPIC希望将这些原则带到美国，许多下一代人工智能技术正在美国开发。</p>
<p class="translated">在向国家科学基金会提交的一封信中，EPIC呼吁这个鲜为人知的政府机构采纳通用指南，几个月前，它对国家人工智能政策的提案敞开了大门。</p>
<p class="translated">EPIC总裁兼执行董事马克·罗滕博格写道:“通过投资于努力满足[通用]原则的人工智能系统，国家科学基金会可以从一开始就促进准确、透明和负责任的系统的发展。”“合乎道德的开发、实施和维护的人工智能系统可以而且应该比不符合道德的系统花费更多，因此值得投资和研究。”</p>
<p class="translated">EPIC表示，这12项原则完全符合美国迄今为止已经制定的七项战略，这使得采纳这些原则变得更加容易。</p>
<p class="translated">200多名专家和50个组织已经在T2签署了指导方针，包括美国科学家联盟和政府责任项目。</p>
<p class="translated">随着政府对信息的要求<a href="https://web.archive.org/web/20221025223234/https://www.federalregister.gov/documents/2018/09/26/2018-20914/request-for-information-on-update-to-the-2016-national-artificial-intelligence-research-and">现在截止</a>，在政府决定接下来的步骤(如果有的话)之前，很可能还要多几个星期——如果不是几个月的话。这不是由国家科学基金会决定的，但很可能是白宫的科学和技术政策办公室。</p>
<p class="translated">白宫发言人没有回应置评请求。</p>
<p class="translated">你可以阅读下面的<a href="https://web.archive.org/web/20221025223234/https://thepublicvoice.org/ai-universal-guidelines/">全套指南</a>:</p>
<ul>
<li class="translated"><blockquote> <p> <b>透明权。</b>所有个人都有权知道与其相关的人工智能决定的依据。这包括获得产生结果的因素、逻辑和技术。</p>T13】</blockquote></li>
<li class="translated"><blockquote> <p> <b>人类决心的权利。</b>所有个人都有权由一个人做出最终决定。</p> </blockquote></li>
<li class="translated"><blockquote> <p> <b>鉴定义务。负责人工智能系统的机构必须为公众所知。</b></p>T29】</blockquote></li>
<li class="translated"><blockquote> <p> <b>公平义务。</b>机构必须确保人工智能系统不会反映不公平的偏见或做出不允许的歧视性决定。</p> </blockquote></li>
<li class="translated"><blockquote> <p> <b>考核和问责义务。只有在对其目的和目标、好处以及风险进行充分评估后，才能部署人工智能系统。机构必须对人工智能系统做出的决定负责。</b></p> </blockquote></li>
<li class="translated"><blockquote> <p> <b>准确性、可靠性和有效性的义务。</b>机构必须确保决策的准确性、可靠性和有效性。</p>T15】</blockquote></li>
<li class="translated"><blockquote> <p> <b>数据质量义务。</b>机构必须建立数据来源，并保证输入算法的数据的质量和相关性。</p> </blockquote></li>
<li class="translated"><blockquote> <p> <b>公共安全义务。</b>机构必须评估因部署指导或控制物理设备的人工智能系统而产生的公共安全风险，并实施安全控制。</p> </blockquote></li>
<li class="translated"><blockquote> <p> <b>网络安全义务。</b>机构必须保护人工智能系统免受网络安全威胁。</p> </blockquote></li>
<li class="translated"><blockquote> <p> <b>禁止秘密剖析。</b>任何机构不得建立或维护秘密的特征分析系统。</p>T47】</blockquote></li>
<li class="translated"><blockquote> <p> <b>禁止一元计分。</b>任何国家政府都不得对其公民或居民建立或保持通用评分。</p>T55】</blockquote></li>
<li class="translated"><blockquote> <p> <b>终止义务。如果人工控制系统不再可能，已经建立人工智能系统的机构有义务终止该系统。</b></p> </blockquote></li>
</ul>

			</div>

			</div>    
</body>
</html>