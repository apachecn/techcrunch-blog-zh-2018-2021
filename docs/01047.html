<html>
<head>
<title>WhatsApp has an encrypted child abuse problem </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">WhatsApp有加密虐童问题</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2018/12/20/whatsapp-pornography/">https://web.archive.org/web/https://techcrunch.com/2018/12/20/whatsapp-pornography/</a></blockquote><div><div class="article-content">
				<p class="p1 translated">WhatsApp聊天群被用来传播非法虐待儿童的图片，并被该应用的端到端加密所掩盖。由于没有必要数量的人类版主，令人不安的内容正从WhatsApp的自动化系统中溜走。TechCrunch查阅了两家以色列非政府组织的一份报告，报告详细介绍了用于发现WhatsApp群体的第三方应用程序如何包括“成人”部分，这些部分提供邀请链接，以加入用户交易儿童剥削图像的圈子。TechCrunch查阅了一些材料，这些材料显示，许多这样的组织目前都很活跃。</p>
<p class="p1 translated"><span class="s1"> TechCrunch的调查显示，脸书在监管WhatsApp和删除这类内容方面可以做得更多。即使没有需要削弱加密的技术解决方案，WhatsApp的版主也应该能够找到这些团体，并阻止他们。在群组发现应用<a href="https://web.archive.org/web/20230316161113/https://play.google.com/store/apps/details?id=com.lisastudio.unlimitedwhatsgroup&amp;hl=en_US"> <span class="s2">、Lisa Studio </span> </a>的“什么是群组链接”上发现的名称为“仅儿童色情无广告”和“儿童色情x视频”的群组甚至没有试图隐藏它们的本质。反剥削初创公司AntiToxin提供的一张截图显示，活跃的WhatsApp群的名称类似于“Children </span> <span class="s3">💋👙👙</span> <span class="s1">”或“视频CP”——一个众所周知的“儿童色情”的缩写。</span></p>
<p id="speakable-summary" class="translated"><span class="s1">【2018年12月27日更新:在我们发布报告并请求置评后，Google Play从Google Play中移除了至少六个第三方应用。] </span></p>
<p/><div id="attachment_1761594" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-1761594" decoding="async" class="size-large wp-image-1761594" src="../Images/36429a92254bfce90472f015b9f17112.png" alt="" data-original-src="https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/WhatsApp_Pornography_Problem.jpg?w=510"/><p id="caption-attachment-1761594" class="wp-caption-text translated">今日WhatsApp上活跃的儿童剥削团体截图。电话号码和照片被编辑了。由<a href="https://web.archive.org/web/20230316161113/http://antitoxin.io/">抗毒素</a>提供。</p></div>
<p class="p1 translated"><span class="s1">对这些群发现应用和WhatsApp本身进行更好的人工调查，应该会立即导致这些群被删除，其成员被禁止。虽然脸书在2018年将其审核人员从1万人增加了一倍，达到2万人，以打击选举干扰、欺凌和其他违反政策的行为，但这些人员并不审核WhatsApp的内容。WhatsApp只有300名员工，半独立运营，该公司证实它处理自己的适度努力。事实证明，这不足以管理一个拥有15亿用户的社区。</span></p>
<p class="translated">【2018年12月27日更新:<a href="https://web.archive.org/web/20230316161113/https://techcrunch.com/2018/12/27/funding-filth/"> TechCrunch随后报道称，发现WhatsApp虐童图片组的应用程序正在运行谷歌和脸书的广告网络</a>。这使他们能够赚钱和维持自己，同时也为这些平台赚取不义之财。报告发布后，两个平台都从广告网络中屏蔽了这些应用，脸书同意向广告商退款。]</p>

<p class="p1 translated"><span class="s1">非政府组织Screen Savers和Netivei Reshet的调查结果今天由<a href="https://web.archive.org/web/20230316161113/https://www.ft.com/content/bff119b8-0424-11e9-99df-6183d3002ee1"> <span class="s2">【金融时报】</span> </a>撰写，但TechCrunch正在发布<a href="https://web.archive.org/web/20230316161113/https://www.scribd.com/document/396103249/Child-Exploitation-On-WhatsApp-by-Screen-Savers-and-Netivei-Reshet-English-TechCrunch">完整的报告</a>，他们翻译的<a href="https://web.archive.org/web/20230316161113/https://www.scribd.com/document/396103381/Translation-of-Letter-Sent-to-Facebook-on-Sept-4th-2018-by-NGOs-TechCrunch">给脸书的</a>信，<a href="https://web.archive.org/web/20230316161113/https://www.scribd.com/document/396103382/Emails-To-Facebook-Regarding-Child-Exploitation-On-WhatsApp-by-Screen-Savers-and-Netivei-Reshet-English-TechCrunch">翻译的</a>与脸书的电子邮件，他们的<a href="https://web.archive.org/web/20230316161113/https://www.scribd.com/document/396103385/Police-report-by-Screen-Savers-and-Netivei-Reshet-English-TechCrunch">警方报告</a>，加上WhatsApp上的虐童图片团体的名称和上面列出的团体发现应用程序。一家名为<a href="https://web.archive.org/web/20230316161113/http://antitoxin.io/"> AntiToxin Technologies </a>的研究该主题的初创公司支持该报告，提供了上面的截图，并表示已经在WhatsApp群中发现了超过1300个未成年人参与性行为的视频和照片。鉴于Tumblr的应用程序最近因涉嫌包庇虐待儿童的图像而被苹果应用商店暂时下架，我们已经询问苹果是否会暂时停止WhatsApp，但尚未得到回复。</span></p>
<p class="translated">[scribd id = 396103249 key = key-ludjlsxqb 13 C5 en impuy mode = scroll]</p>
<h2 class="translated">揭开一场噩梦</h2>
<p class="p1 translated"><span class="s1">2018年7月，非政府组织在一名男子向他们的热线报告他在WhatsApp上看到了核心色情内容后意识到了这个问题。10月份，他们花了20天的时间对10多个儿童虐待图像组、它们的内容以及允许人们找到它们的应用程序进行了编目。</span></p>
<p class="p1 translated">从9月4日开始，非政府组织开始联系脸书的政策主管乔丹娜·卡特勒。他们四次要求开会讨论他们的发现。卡特勒要求提供电子邮件证据，但不同意会面，而是按照以色列执法部门的指导，指示研究人员联系当局。该非政府组织向以色列警方报告了他们的发现，但拒绝向脸书提供他们的研究。WhatsApp今天才从TechCrunch收到他们的报告和活跃的虐待儿童图像组的截图。</p>
<p/><div id="attachment_1761589" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-1761589" decoding="async" loading="lazy" class="wp-image-1761589 size-large" src="../Images/79017c46c9ce5653dfe646f575d31995.png" alt="" srcset="https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/Sample-Of-Child-Exploitation-Groups-On-WhatsApp.png 1020w, https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/Sample-Of-Child-Exploitation-Groups-On-WhatsApp.png?resize=133,150 133w, https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/Sample-Of-Child-Exploitation-Groups-On-WhatsApp.png?resize=267,300 267w, https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/Sample-Of-Child-Exploitation-Groups-On-WhatsApp.png?resize=768,864 768w, https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/Sample-Of-Child-Exploitation-Groups-On-WhatsApp.png?resize=604,680 604w, https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/Sample-Of-Child-Exploitation-Groups-On-WhatsApp.png?resize=44,50 44w" sizes="(max-width: 604px) 100vw, 604px" data-original-src="https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/Sample-Of-Child-Exploitation-Groups-On-WhatsApp.png?w=604"/><p id="caption-attachment-1761589" class="wp-caption-text translated">WhatsApp上儿童剥削团体的团体发现应用列表。网址和照片已被编辑。</p></div>
<p class="p2 translated">WhatsApp告诉我，它现在正在调查我们提供的研究中可见的群体。<span class="Apple-converted-space"> </span>脸书发言人告诉TechCrunch，“ <span class="s5">保证脸书人民的安全是我们全球团队工作的基础。我们主动提出与以色列警方合作展开调查，以制止这种虐待行为。”以色列警方儿童在线保护局负责人梅厄·哈扬(Meir Hayoun)在一份声明中指出:“在过去与乔丹娜的会面中，我指示她告诉任何想举报任何恋童癖内容的人，联系以色列警方进行投诉。”</span></p>
<p class="p1 translated">WhatsApp的一位发言人告诉我，虽然WhatsApp上允许合法的成人色情内容，但在最近10天内，该公司禁止了13万个账户，因为它们违反了禁止剥削儿童的政策。 <span class="s4">在一份声明中，WhatsApp写道:</span></p>
<blockquote>
<p class="p2 translated"><span class="s5"> WhatsApp对儿童性虐待采取零容忍政策。我们部署了我们最先进的技术，包括人工智能，来扫描报告内容中的个人资料照片和图像，并主动禁止涉嫌分享这种卑鄙内容的账户。我们还响应世界各地的执法请求，并立即向国家失踪和被剥削儿童中心报告虐待情况。可悲的是，由于应用商店和通信服务都被滥用来传播滥用内容，技术公司必须共同努力来阻止它。</span></p>
</blockquote>
<p class="p1 translated">但是，正是对技术的过度依赖和随之而来的人员配备不足似乎让这个问题愈演愈烈。AntiToxin的首席执行官Zohar Levkovitz告诉我，“可以说脸书在不知情的情况下成长为恋童癖吗？是的。作为父母和科技高管，我们不能对此沾沾自喜。”</p>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-large wp-image-1761584" src="../Images/4f3159741031094bf6730fdaa4b1496f.png" alt="" srcset="https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/WhatsApp-Group-Link-Apps-1.png 1691w, https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/WhatsApp-Group-Link-Apps-1.png?resize=150,86 150w, https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/WhatsApp-Group-Link-Apps-1.png?resize=300,172 300w, https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/WhatsApp-Group-Link-Apps-1.png?resize=768,440 768w, https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/WhatsApp-Group-Link-Apps-1.png?resize=680,390 680w, https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/WhatsApp-Group-Link-Apps-1.png?resize=1536,880 1536w, https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/WhatsApp-Group-Link-Apps-1.png?resize=1200,688 1200w, https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/WhatsApp-Group-Link-Apps-1.png?resize=50,29 50w" sizes="(max-width: 680px) 100vw, 680px" data-original-src="https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/WhatsApp-Group-Link-Apps-1.png?w=680"/></p>
<h2 class="translated">自动调节并不能解决问题</h2>
<p class="p1 translated"><span class="s1"> WhatsApp在2016年末推出了群组邀请链接功能，在不认识任何成员的情况下，发现和加入群组变得更加容易。Telegram等竞争对手受益于公众群聊参与度的上升。WhatsApp可能将群邀请链接视为增长的机会，但没有分配足够的资源来监控围绕不同主题聚集的陌生人群体。</span> <span class="s1">应用程序如雨后春笋般涌现，允许人们按类别浏览不同的群组。这些应用程序的一些使用是合法的，因为人们寻求社区来讨论体育或娱乐。但是这些应用程序中的许多现在都有“成人”部分，可以包括合法色情共享组和非法儿童剥削内容的邀请链接。</span></p>
<p class="p1 translated"><span class="s1">WhatsApp的一位发言人告诉我，它扫描其网络上所有未加密的信息——基本上是聊天线程本身以外的任何信息——包括用户资料照片、群组资料照片和群组信息。它试图将内容与索引儿童虐待图像的照片DNA库进行匹配，许多科技公司使用这些照片DNA库来识别之前报告的不当图像。如果找到匹配，该账户或该群组及其所有成员将被WhatsApp终身封禁。</span></p>
<p/><div id="attachment_1761583" class="wp-caption alignright"><img aria-describedby="caption-attachment-1761583" decoding="async" loading="lazy" class="vertical wp-image-1761583 size-large" src="../Images/b2751a854dde20dbecc774d12db04c4a.png" alt="" srcset="https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/WhatsApp-Child-Porn-Group-Discovery-on-Lisa-Studio.png 766w, https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/WhatsApp-Child-Porn-Group-Discovery-on-Lisa-Studio.png?resize=79,150 79w, https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/WhatsApp-Child-Porn-Group-Discovery-on-Lisa-Studio.png?resize=158,300 158w, https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/WhatsApp-Child-Porn-Group-Discovery-on-Lisa-Studio.png?resize=358,680 358w, https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/WhatsApp-Child-Porn-Group-Discovery-on-Lisa-Studio.png?resize=633,1200 633w, https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/WhatsApp-Child-Porn-Group-Discovery-on-Lisa-Studio.png?resize=26,50 26w" sizes="(max-width: 358px) 100vw, 358px" data-original-src="https://web.archive.org/web/20230316161113im_/https://techcrunch.com/wp-content/uploads/2018/12/WhatsApp-Child-Porn-Group-Discovery-on-Lisa-Studio.png?w=358"/><p id="caption-attachment-1761583" class="wp-caption-text translated">WhatsApp group discovery应用程序列出了WhatsApp上的儿童剥削团体</p></div>
<p class="p1 translated">如果图像与数据库不匹配，但被怀疑显示了对儿童的剥削，就要进行人工审查。如果被发现是非法的，WhatsApp会禁止这些账户和/或群组，防止其在未来被上传，并将内容和账户报告给国家失踪和被剥削儿童中心。英国《金融时报》向WhatsApp报告的一个示例群组已经被其自动系统标记为人工审查，然后与所有256名成员一起被禁止。</p>
<p class="p1 translated"><span class="s1">为了防止滥用，WhatsApp表示，它将群组成员限制在256人以内，并有意不在其应用程序中提供搜索功能。它不鼓励发布群组邀请链接，并且绝大多数群组只有六个或更少的成员。它已经与谷歌和苹果合作，针对滥用WhatsApp的儿童剥削组织discovery apps等应用强制执行其服务条款。这类群组在苹果应用商店已经找不到了，但在Google Play上仍然可以找到。我们已经联系了Google Play，询问它如何处理非法内容发现应用程序，以及Lisa Studio will的群组链接是否仍然可用，如果我们收到回复，将会更新。[下午3点PT更新:谷歌尚未提供评论，但Lisa Studio的Whats应用的群组链接已从Google Play中移除。这是朝着正确方向迈出的一步。] </span></p>
<p class="p1 translated"><span class="s1">但更大的问题是，如果WhatsApp已经知道这些群体发现应用，为什么它不利用它们来追踪和禁止违反其政策的群体。一位发言人声称，带有“CP”或其他儿童剥削指标的小组名称是它用来追捕这些小组的一些信号，小组发现应用程序中的名称不一定与WhatsApp上的小组名称相关。但TechCrunch随后提供了一张截图，显示了截至今天早上WhatsApp内的活跃团体，名字像“儿童</span> <span class="s3">💋👙👙</span> <span class="s1">”或“视频cp”。这表明WhatsApp的自动化系统和精干的员工不足以阻止非法图像的传播。</span></p>
<p class="p1 translated"><span class="s1">这种情况也引发了关于加密权衡的问题，因为澳大利亚等一些政府试图阻止消息应用使用加密。这项技术可以保护言论自由，提高持不同政见者的安全性，并防止政府和技术平台的审查。然而，这也会使侦查犯罪更加困难，加剧对受害者造成的伤害。</span></p>
<p class="p1 translated">WhatsApp的发言人告诉我，它支持强大的端到端加密，保护与亲人、医生等的对话。他们说，端到端加密有很多很好的理由，它将继续支持它。以任何方式改变这一点，即使是为了帮助抓住那些剥削儿童的人，也需要对其给予用户的隐私保障做出重大改变。他们建议，手机制造商必须在设备上扫描非法内容，以防止其传播，同时不妨碍加密。</p>
<p class="p1 translated"><span class="s1">但目前，WhatsApp需要更多愿意使用主动且不可扩展的人工调查来解决其儿童虐待图像问题的人类版主。随着脸书每个季度赚取数十亿美元的利润，并为自己的温和派队伍配备人员，WhatsApp所谓的自主权没有理由阻止它在这个问题上应用足够的资源。WhatsApp试图通过大型公共团体来发展，但未能采取必要的预防措施来确保它们不会成为儿童剥削的天堂。像WhatsApp这样的科技公司需要停止假设廉价高效的技术解决方案就足够了。如果他们想从庞大的用户群中赚钱，他们必须愿意花钱保护和监管他们。</span></p>

			</div>

			</div>    
</body>
</html>