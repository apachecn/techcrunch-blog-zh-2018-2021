<html>
<head>
<title>Facebook urged to give users greater control over what they see </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">脸书呼吁让用户对他们看到的东西有更大的控制权</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2019/01/16/facebook-urged-to-give-users-greater-control-over-what-they-see/">https://web.archive.org/web/https://techcrunch.com/2019/01/16/facebook-urged-to-give-users-greater-control-over-what-they-see/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">牛津大学和斯坦福大学的学者认为，脸书应该让用户对其平台上看到的内容拥有更大的透明度和控制权。</p>
<p class="translated">他们还认为，这家社交网络巨头应该彻底改革其治理结构和流程，以更多地关注内容决策，包括通过引入更多外部专家来指导政策。</p>
<p class="translated">他们在今天发表的一份报告中指出，这些改变是必要的，以解决人们对脸书对民主和言论自由的影响的广泛担忧，该报告包括一系列改革脸书的建议(题为:<i>开放！脸书让自己成为更好的言论自由和民主论坛的九种方式。)</i></p>
<p class="translated">首席作者<span class="il">蒂莫西</span> <span class="il">加顿</span>阿什写道:“像脸书这样的平台现在可以做很多事情来解决公众广泛关注的问题，并采取更多措施来履行其公共利益责任和国际人权规范。”。</p>
<p class="translated">“脸书做出的行政决策在世界范围内产生了重大的政治、社会和文化影响。对新闻订阅算法或内容政策的一个小小的改变，其影响可能比任何一项国家立法(甚至是EU-范围内的立法)都更快、更广。”</p>
<p class="translated">以下是该报告九项建议的概要:</p>
<ol>
<li class="translated">收紧关于仇恨言论的社区标准措辞 —学者们认为，脸书目前在关键领域的措辞“过于宽泛，导致了不稳定、不一致且通常对上下文不敏感的撤销”也产生了“高比例的争议案件”他们认为，更清晰、更严谨的措辞会让一致的实施变得更容易。</li>
<li class="translated">雇佣更多的专家内容审查员——“质量和数量都是问题，”报告指出，迫使脸书雇佣更多的人类内容审查员，再加上一层具有“相关文化和政治专业知识”的高级审查员并与非政府组织等可信的外部来源进行更多的接触。“很明显，人工智能不会解决深度依赖上下文的判断问题，例如，在确定仇恨言论何时成为危险言论时，需要做出这种判断，”他们写道。</li>
<li class="translated"><strong>增加“决策透明度”</strong> —他们认为，脸书在内容审核政策和实践方面仍然没有提供足够的透明度，认为它需要公布其程序的更多细节，包括特别要求该公司“张贴并广泛宣传案例研究”，为用户提供更多指导，并提供潜在的上诉理由。</li>
<li class="translated"><strong>扩展和改进申诉流程</strong> —同样在申诉方面，报告建议脸书为评论者提供更多有争议内容的背景信息，并向分析师和用户提供申诉统计数据。“在目前的制度下，最初的内部审查者对发布一条内容的个人的信息非常有限，尽管上下文对于裁决上诉很重要，”他们写道。“由大屠杀幸存者或新纳粹分子发布的大屠杀图片具有非常不同的意义。”他们还建议，脸书应该与用户对话，例如在内容政策咨询小组的帮助下，致力于开发“对普通用户来说功能更强、更有用”的上诉正当程序。</li>
<li class="translated"><strong>为用户提供有意义的新闻反馈控制</strong>——报告建议脸书用户应该对他们在新闻反馈中看到的内容有更有意义的控制，作者认为目前的控制“完全不够”，并倡导更多的控制。例如完全关闭算法提要的能力(当用户重新加载时，时间顺序视图不会默认回到算法，现在任何人从人工智能控制的视图切换过来都是这种情况)。该报告还建议增加一个新闻分析功能，为用户提供他们正在查看的来源的分类，以及与其他用户的控制组进行比较的情况。他们建议，脸书还可以提供一个按钮，通过向用户展示他们通常不会看到的内容，让他们采用不同的视角。</li>
<li class="translated"><strong>扩大背景和事实核查设施</strong>——该报告推动投入“大量”资源，为每个国家、地区和文化确定“最佳、最权威和最可信的”背景信息来源——以帮助支持脸书现有的(但仍不充分且未普遍分布的)事实核查工作。</li>
<li class="translated"><strong>建立定期的审计机制</strong> —已经有一些对脸书程序的民权审计(<a href="https://web.archive.org/web/20230306043024/https://techcrunch.com/2018/11/06/facebook-still-isnt-taking-myanmar-seriously/">比如这个</a>，它建议脸书正式制定一项人权战略)，但是报告敦促该公司向更多这样的机制开放，建议有意义的审计模式应该被复制并扩展到公众关注的其他领域，包括隐私、算法公平和偏见、多样性等等。</li>
<li class="translated"><strong>创建外部内容政策咨询小组</strong> —脸书应招募来自民间社会、学术界和新闻业的主要内容利益相关方，组成专家政策咨询小组，就其内容标准和实施提供持续反馈；并审查其上诉记录。他们写道，“创建一个在地理、文化和政治上广泛的脸书用户中具有公信力的机构将是一个重大挑战，但一个精心选择的、正式的专家咨询小组将是第一步，”他们指出，脸书已经开始朝着这个方向前进，但补充说:“这些努力应该以透明的方式正式化和扩大。”</li>
<li class="translated"><strong>建立一个外部上诉机构</strong>——该报告还敦促通过一个位于母舰之外的上诉机构，对脸书的内容政策进行“独立的、外部的”最终控制，该上诉机构包括来自民间社会和数字权利倡导团体的代表。作者引用马克·扎克伯格去年11月的评论指出，脸书已经在考虑这个想法，但也警告说，如果要“有意义地”移交权力，这需要妥善处理。“脸书应该努力让这个上诉机构尽可能透明……并允许它影响广泛的内容政策领域……而不仅仅是裁定特定的内容删除，”他们警告说。</li>
</ol>
<p class="translated">最后，报告指出，它所关注的内容问题不仅与脸书的业务有关，而且广泛应用于各种互联网平台——因此人们对某种形式的“全行业自律机构”越来越感兴趣尽管这表明实现这种全面监管将是“一项长期而复杂的任务”。</p>
<p class="translated">与此同时，学者们仍然相信，“像脸书这样的平台现在可以做很多事情来解决公众广泛关注的问题，并采取更多措施来履行其公共利益责任和国际人权规范”——鉴于其庞大的规模(22亿多活跃用户)，公司处于框架的前端和中心。</p>
<p class="translated">“我们认识到，脸书的员工每天都在做出艰难、复杂、有关联的判断，平衡相互竞争的利益，并非所有这些决策都会受益于完全透明。但如果能与学术研究、调查性新闻报道和公民社会倡导领域进行更经常、更积极的交流，一切都会变得更好，”他们补充道。</p>
<p class="translated">我们联系了脸书，征求他们对建议的意见。</p>
<p class="translated">该报告由牛津大学圣安东尼学院Dahrendorf自由研究方案的自由言论辩论项目与牛津大学路透社新闻研究所、斯坦福大学民主与互联网项目和斯坦福大学胡佛研究所合作编写。</p>
<p class="translated">去年，我们提出了一些自己的解决脸书问题的想法——包括建议公司雇佣更多的专家内容审查员，以及为关键决策和流程提供更大的透明度。</p>
			</div>

			</div>    
</body>
</html>