<html>
<head>
<title>YouTube under fire for recommending videos of kids with inappropriate comments </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">YouTube因推荐带有不当评论的儿童视频而受到批评</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2019/02/18/youtube-under-fire-for-recommending-videos-of-kids-with-inappropriate-comments/">https://web.archive.org/web/https://techcrunch.com/2019/02/18/youtube-under-fire-for-recommending-videos-of-kids-with-inappropriate-comments/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">YouTube上的儿童安全内容审核丑闻已经过去一年多了，该平台的推荐算法只需点击几下，就可以将对成年女性“比基尼”视频的搜索重定向到衣着暴露的未成年人进行身体扭曲体操或洗冰浴或吮吸冰棒“挑战”的视频</p>
<p class="translated">一位名叫马特·沃森(Matt Watson)的YouTube创建者在Reddit <a href="https://web.archive.org/web/20230308214451/https://old.reddit.com/user/Mattwatson07">的一篇重要帖子</a>中指出了这一问题，他说他发现YouTube用户在几十个孩子的视频中交换不适当的评论和文件夹下的时间戳，谴责该公司未能阻止他所描述的“软核心恋童癖集团”在其平台上公开运营。</p>
<p class="translated">他还发布了一个<a href="https://web.archive.org/web/20230308214451/https://www.youtube.com/watch?v=O13G5A5w5P0"> YouTube视频</a>，展示该平台的推荐算法如何将用户推入他称之为恋童癖的“虫洞”，指责该公司为儿童性剥削提供便利并将其货币化。</p>
<p class="translated">我们很容易地复制了YouTube算法的行为，沃森在一个历史清除的私人浏览器会话中描述了这一行为，在点击了两个穿着比基尼的成年女性视频后，建议我们观看一个名为“甜蜜十六岁泳池派对”的视频。</p>
<p class="translated">点击它会导致YouTube的侧栏在“下一个”部分提供多个青春期前女孩的视频，该算法会提供相关内容以鼓励用户继续点击。</p>
<p class="translated">我们在这个侧边栏中得到推荐的视频包括显示年轻女孩展示体操姿势、炫耀她们的“早晨惯例”或舔冰棒或冰棍的缩略图。</p>
<p class="translated">沃森说，他很容易找到包含不当/掠夺性评论的视频，包括性暗示表情符号和时间戳，这些表情符号和时间戳似乎旨在突出、快捷和分享未成年人视频中最妥协的位置和/或时刻。</p>
<p class="translated">我们还在YouTube的算法推荐我们观看的儿童视频上发现了多个时间戳和不当评论的例子。</p>
<p class="translated">其他YouTube用户的一些评论谴责了那些在视频中对儿童发表性暗示言论的人。</p>
<p class="translated">早在2017年11月，在BBC和《泰晤士报》的一项调查发现儿童视频上有类似的淫秽评论后，几家主要广告商<a href="https://web.archive.org/web/20230308214451/https://techcrunch.com/2017/11/27/youtube-faces-brand-freeze-over-ads-and-obscene-comments-on-videos-of-kids/">冻结了YouTube平台上的支出</a>。</p>
<p class="translated">同月早些时候，YouTube也因其平台上针对儿童观众的低质量内容而受到批评。</p>
<p class="translated">该公司接着在<a href="https://web.archive.org/web/20230308214451/https://techcrunch.com/2017/11/09/after-disturbing-reports-youtube-kids-implements-new-policy-to-flag-inappropriate-videos-targeted-at-children/">宣布</a>一系列<a href="https://web.archive.org/web/20230308214451/https://techcrunch.com/2017/11/22/youtube-tightens-rules-on-kid-related-content/">与儿童视频</a>相关的政策变化，包括说它将积极监管对儿童视频的评论，如果发现视频中有对儿童的不当评论，评论将被完全关闭。</p>
<p class="translated">YouTube推荐我们观看的一些年轻女孩的视频已经被禁用了评论——这表明它的人工智能之前已经发现了大量不恰当的评论被分享(因为它的政策是在评论被认为“不恰当”时关闭对包含孩子的剪辑的评论)——但视频本身仍被建议在以短语“比基尼大捞”发起的测试搜索中观看</p>
<p class="translated">沃森还表示，他发现一些儿童视频中显示的广告包含不恰当的评论，并声称他发现YouTube评论中也有儿童色情内容的链接。</p>
<p class="translated">我们无法在简短的测试中验证这些发现。</p>
<p class="translated">我们问YouTube，为什么它的算法倾向于推荐未成年人的视频，即使观众是从观看成年女性的视频开始的，以及为什么在调查性新闻报道强调同一问题一年多后，未成年人视频上的不当评论仍然是一个问题。</p>
<p class="translated">针对我们的问题，该公司向我们发送了以下声明:</p>
<blockquote><p class="translated">任何危及未成年人的内容(包括评论)都是令人憎恶的，我们有明确的政策禁止在YouTube上发布这些内容。我们积极执行这些政策，向有关当局报告，将其从我们的平台上删除并终止帐户。我们将继续在技术、团队和与慈善机构的合作方面投入巨资，以解决这一问题。我们有严格的政策来管理我们允许广告出现的地方，并严格执行这些政策。当我们发现违反我们政策的内容时，我们会立即停止提供广告或将其完全删除。</p></blockquote>
<p class="translated">YouTube的一位发言人还告诉我们，鉴于沃森强调的内容，它正在审查其政策，并补充说，它正在审查他的视频中的特定视频和评论——同时还指出，由于审查，一些内容已经被删除。</p>
<p class="translated">然而，这位发言人强调，沃森标记的大多数视频都是孩子们做日常事情的无辜记录。(当然，问题是无辜的内容正被重新规划和时间分割，以满足滥用和剥削。)</p>
<p class="translated">这位发言人补充说，YouTube与国家失踪和被剥削儿童中心合作，向发现对儿童发表不当评论的执法机构账户进行报告。</p>
<p class="translated">在关于这个问题的更广泛的讨论中，发言人告诉我们，确定上下文对于其人工智能调节系统来说仍然是一个挑战。</p>
<p class="translated">在人工审核方面，他说该平台现在有大约10，000名人工审核人员，负责评估标记为审核的内容。</p>
<p class="translated">他补充说，上传到YouTube的视频内容量约为每分钟400小时。</p>
<p class="translated">在用户生成的内容平台上，围绕内容审核仍然存在非常明显的不对称，鉴于在理解上下文方面的持续弱点，人工智能不太适合填补这一空白，即使平台的人类审核团队仍然资源不足，与任务的规模相比，人力不足。</p>
<p class="translated">YouTube没有提到的另一个关键点是基于广告的商业模式和内容安全问题之间的明显紧张关系，前者根据观众参与度(如其自身)将内容货币化，后者需要仔细考虑内容的实质和消费内容的背景。</p>
<p class="translated">这当然不是YouTube的推荐算法第一次因为负面影响而被叫停。近年来，该平台被指控通过将观众推向极端主义甚至恐怖主义内容来自动化激进化——这导致YouTube宣布<a href="https://web.archive.org/web/20230308214451/https://techcrunch.com/2017/11/14/in-major-policy-change-youtube-is-now-taking-down-more-videos-of-known-extremists/">2017年的另一项政策变化</a>与它如何处理已知极端分子创建的内容有关。</p>
<p class="translated">夸大阴谋论和/或宣传虚假、反事实的健康或科学内容的算法建议的更广泛的社会影响也被反复提出，作为一个问题——包括在YouTube上。</p>
<p class="translated">就在上个月 YouTube表示，它将减少推荐它所谓的“边缘内容”和“可能以有害的方式误导用户”的内容，引用了一些例子，如宣传严重疾病的虚假奇迹疗法的视频，或声称地球是平的，或对历史事件如纽约9/11恐怖袭击做出“公然错误的声明”。</p>
<p class="translated">“虽然这一转变将适用于YouTube上不到1%的内容，但我们相信，限制推荐这些类型的视频将意味着YouTube社区的更好体验，”它当时写道。“与往常一样，人们仍然可以访问所有符合我们社区准则的视频，并且在相关时，这些视频可能会出现在为频道订户提供的推荐和搜索结果中。我们认为这一变化在维护言论自由平台和履行我们对用户的责任之间取得了平衡。”</p>
<p class="translated">YouTube表示，围绕阴谋视频的算法推荐的变化将是渐进的，最初只会影响美国一小部分视频的推荐</p>
<p class="translated">它还指出，对其推荐引擎进行调整将涉及机器学习技术和人类评估员以及帮助训练人工智能系统的专家。</p>
<p class="translated">“随着时间的推移，随着我们的系统变得更加准确，我们将在更多国家推出这一变化。这只是一个持续过程中的又一步，但它反映了我们改善YouTube上推荐体验的承诺和责任感，”它补充道。</p>
<p class="translated">YouTube是否会扩大这一政策转变，并决定它必须在未来如何推荐和提供儿童视频供远程消费方面承担更大责任，还有待观察。</p>
<p class="translated">政治压力可能是一个推动力，对在线平台的监管势头越来越大——包括呼吁互联网公司<a href="https://web.archive.org/web/20230308214451/https://techcrunch.com/2019/02/17/uk-parliament-calls-for-antitrust-data-abuse-probe-of-facebook/">面对明确的法律责任</a>，甚至对用户分发和货币化的内容负有法律责任。</p>
<p class="translated">例如，英国监管机构已将互联网和社交媒体安全立法作为政策优先事项——政府将于今年冬天发布一份白皮书，阐述其治理平台的计划。</p>
			</div>

			</div>    
</body>
</html>