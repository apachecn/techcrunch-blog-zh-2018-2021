<html>
<head>
<title>MuseNet generates original songs in seconds, from Bollywood to Bach (or both) • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">MuseNet在几秒钟内生成原创歌曲，从宝莱坞到巴赫(或两者都有)</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2019/04/25/musenet-generates-original-songs-in-seconds-from-bollywood-to-bach-or-both/">https://web.archive.org/web/https://techcrunch.com/2019/04/25/musenet-generates-original-songs-in-seconds-from-bollywood-to-bach-or-both/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">你有没有想过听凯蒂·佩里演奏的莫扎特风格的钢琴和竖琴协奏曲？为什么不呢？因为现在你可以了，有了OpenAI的最新(幸运的是没有潜在的灾难性)创造，<a href="https://web.archive.org/web/20230108124747/https://openai.com/blog/musenet/"> MuseNet </a>。这种机器学习模型基于对艺术家和几个酒吧的了解来制作从未听过的音乐。</p>
<p class="translated">这远不是前所未有的——计算机生成的音乐已经存在了几十年——但OpenAI的方法似乎很灵活，可以扩展，产生各种流派和艺术家的音乐，并以听觉风格转移的形式交叉授粉。它与GPT2、<a href="https://web.archive.org/web/20230108124747/https://techcrunch.com/2019/02/17/openai-text-generator-dangerous/">、</a>语言模型“太危险了，不能发布”，有很多相同的DNA，但与无法检测的计算机生成文本相比，向世界释放无限音乐的威胁似乎很小。</p>

<p class="translated">穆塞内接受了数十位艺术家作品的训练，从著名的历史人物如肖邦和巴赫，到(相对而言)现代艺术家如阿黛尔和披头士，再加上非洲、阿拉伯和印度音乐的收藏。其复杂的机器学习系统付出了大量的“注意力”，这是人工智能工作中的一个技术术语，本质上是模型用来通知其创建的下一步的上下文量。</p>
<p class="translated">举个例子，莫扎特的一首曲子。如果这个模型一次只关注几秒钟，它将永远也不能在一首交响乐的成长和后退、音调和乐器的切换中学习更大的音乐结构。但这个模型被赋予了足够的虚拟大脑空间来保存大约整整四分钟的声音，足以掌握一些东西，比如从缓慢的开始到大的结束，或者基本的独唱-合唱-独唱结构。</p>
<p/><div id="attachment_1817373" class="wp-caption aligncenter"><a href="https://web.archive.org/web/20230108124747/https://techcrunch.com/wp-content/uploads/2019/04/haydn.png"><img aria-describedby="caption-attachment-1817373" decoding="async" loading="lazy" class="size-full wp-image-1817373" src="../Images/5e672a21e0eca8922b830aa9eef87f47.png" alt="" srcset="https://web.archive.org/web/20230108124747im_/https://techcrunch.com/wp-content/uploads/2019/04/haydn.png 916w, https://web.archive.org/web/20230108124747im_/https://techcrunch.com/wp-content/uploads/2019/04/haydn.png?resize=150,99 150w, https://web.archive.org/web/20230108124747im_/https://techcrunch.com/wp-content/uploads/2019/04/haydn.png?resize=300,199 300w, https://web.archive.org/web/20230108124747im_/https://techcrunch.com/wp-content/uploads/2019/04/haydn.png?resize=768,509 768w, https://web.archive.org/web/20230108124747im_/https://techcrunch.com/wp-content/uploads/2019/04/haydn.png?resize=680,451 680w, https://web.archive.org/web/20230108124747im_/https://techcrunch.com/wp-content/uploads/2019/04/haydn.png?resize=50,33 50w" sizes="(max-width: 916px) 100vw, 916px" data-original-src="https://web.archive.org/web/20230108124747im_/https://techcrunch.com/wp-content/uploads/2019/04/haydn.png"/></a><p id="caption-attachment-1817373" class="wp-caption-text translated">你是说海顿没有直接影响苏悦华？现实点吧。</p></div>
<p class="translated">理论上是这样的。这个模型实际上并不理解音乐理论，只是这个音符跟在这个音符后面，这个音符跟在这个音符后面，这个音符往往跟在这个类型的和弦后面，等等。它的创作在结构上很简单，但听它们的声音就很清楚，它确实成功地模仿了它所摄取的歌曲。</p>
<p class="translated">令人印象深刻的是，一个单一的模型在如此多类型的音乐中可靠地做到了这一点。人工智能已经被创造出来，就像几周前为巴赫的生日创作的精彩的谷歌涂鸦一样，它专注于一个特定的艺术家或流派。作为比较，我一直在听<a href="https://web.archive.org/web/20230108124747/https://generative.fm/"> Generative.fm </a>，它创造了我喜欢在工作时听的那种稀疏的环境音乐(如果你也喜欢，看看我最喜欢的标签之一，<a href="https://web.archive.org/web/20230108124747/https://www.serein.co.uk/"> Serein </a>)。但是这两种模型都有非常严格的限制。穆塞内却不是这样。</p>
<p class="translated">除了能够演奏出无限的蓝草音乐或巴洛克风格的钢琴曲之外，MuseNet还可以运用一种风格转换过程来结合两者的特点。一幅作品的不同部分可以有不同的属性——在一幅画中，你可以从构图、主题、颜色选择和画笔风格开始。想象一个拉斐尔前派的主题和构图，但是带有印象派的风格。听起来很有趣，对吧？人工智能模型在这方面做得很好，因为它们将这些不同的方面划分开来。这在音乐中是同样的事情:流行歌曲的音符选择、节奏和其他模式可以从乐器中分离出来单独使用——为什么沙滩男孩不在竖琴上和声呢？</p>
<p class="translated">然而，如果没有阿黛尔独特的声音，很难感受到她这样的人，而且团队选择的相当基础的合成器降低了整体效果。在听了团队在Twitch上的“现场音乐会”后，我不相信MuseNet会是下一个热门产品。另一方面，它经常有很好的节奏，特别是在爵士乐和古典即兴创作中，可以播放一点跑调的音符，节奏不会感觉太做作。</p>
<p class="translated">这是干什么用的？你的想法和其他人一样好，真的。这个领域相当新。MuseNet的项目负责人Christine Payne对这个模型很满意，并且已经找到了使用它的人:</p>
<blockquote><p class="translated">作为一名受过古典音乐训练的钢琴家，我特别兴奋地看到穆塞内能够理解贝多芬和肖邦复杂的和声结构。我现在正与一位作曲家合作，他计划将MuseNet融入他自己的作品中，我很兴奋地看到人类/人工智能合作作曲的未来将带我们走向何方。</p></blockquote>
<p class="translated">OpenAI的一名代表还表示，该团队已经开始整合当代作曲家的作品，他们希望看到模型如何诠释或模仿他们的风格。</p>
<p class="translated">MuseNet将在5月中旬供你使用，届时它将离线，并根据用户的反馈进行调整，不久(想想几周)它将至少部分开源。我想流行的组合和人们一直在听的组合会在调整中得到更多的权重。这里希望他们也能在MIDI演奏中加入更多的表情——感觉这些曲子确实经常像是由机器人演奏的。但这也证明了OpenAI作品的质量，它们经常听起来也非常好。</p>
			</div>

			</div>    
</body>
</html>