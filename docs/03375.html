<html>
<head>
<title>Mona Lisa frown: Machine learning brings old paintings and photos to life • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">蒙娜丽莎皱眉:机器学习让老画和老照片变得栩栩如生 TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2019/05/22/mona-lisa-frown-machine-learning-brings-old-paintings-and-photos-to-life/">https://web.archive.org/web/https://techcrunch.com/2019/05/22/mona-lisa-frown-machine-learning-brings-old-paintings-and-photos-to-life/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">机器学习研究人员已经开发出一种系统，可以从一个人的单帧面部重建逼真的运动，这不仅为照片动画化开辟了可能性，也为绘画动画化开辟了可能性。它并不完美，但当它工作时，就像现在的许多人工智能工作一样，怪异而迷人。</p>
<p class="translated">该模型记录在三星人工智能中心发布的一篇论文中，你可以在 Arxiv 上阅读该论文。这是一种将源人脸上的面部标志(任何会说话的头部都可以)应用到目标人脸的面部数据的新方法，使目标人脸做源人脸做的事情。</p>
<p class="translated">这本身并不新鲜——这是人工智能世界目前面临的整个合成图像问题的一部分(<a href="https://web.archive.org/web/20230106125736/https://techcrunch.com/video/this-reality-does-not-exist-trust-in-an-age-of-synthetic-media-with-alexei-efros-uc-berkeley-and-hany-farid-dartmouth-college/">我们最近在 Berkeley </a>的机器人+人工智能活动中就此进行了有趣的讨论)。我们已经可以让一个视频中的一张脸反映另一个视频中的一张脸，根据这个人在说什么或者他们在看哪里。但是这些模型中的大多数需要大量的数据，例如一两分钟的视频来分析。</p>
<p class="embed breakout embed--video embed--youtube translated"><iframe title="Few-Shot Adversarial Learning of Realistic Neural Talking Head Models" src="https://web.archive.org/web/20230106125736if_/https://www.youtube.com/embed/p1b5aiTrGzY?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">视频</iframe></p>
<p class="translated">然而，三星驻莫斯科研究人员的新论文显示，仅使用一张人脸图像，就可以生成一段视频，显示人脸转动、说话和做出普通表情的过程——虽然远非完美，但逼真度令人信服。</p>
<p class="translated">它通过在面部标志识别过程中预先加载大量数据来实现这一点，使模型在找到目标面部与源相对应的部分时非常高效。它拥有的数据越多越好，但它可以用一张图像来完成它——称为单次学习——并侥幸逃脱。这使得给爱因斯坦或玛丽莲·梦露，甚至蒙娜丽莎拍照，并让它像真人一样移动和说话成为可能。</p>
<p/><div id="attachment_1831497" class="wp-caption aligncenter"><a href="https://web.archive.org/web/20230106125736/https://techcrunch.com/wp-content/uploads/2019/05/monalisa.gif"><img aria-describedby="caption-attachment-1831497" decoding="async" loading="lazy" class="wp-image-1831497 size-full" src="../Images/c10b1510054d00c673f084df96a06c9c.png" alt="" data-original-src="https://web.archive.org/web/20230106125736im_/https://techcrunch.com/wp-content/uploads/2019/05/monalisa.gif"/></a><p id="caption-attachment-1831497" class="wp-caption-text translated">在这个例子中，蒙娜丽莎是用三个不同的源视频制作的，正如你所看到的，它们在面部结构和行为上产生了非常不同的结果。</p></div>
<p class="translated">它还使用了所谓的生成对抗网络，这实质上是让两个模型相互对抗，一个试图欺骗另一个，让它认为它创造的是“真实的”通过这些手段，结果满足了创作者设定的一定程度的真实性——“鉴别者”模型必须 90%确定这是一张人脸，才能继续这个过程。</p>
<p class="translated">在研究人员提供的其他例子中，假说话头的质量和明显程度差异很大。一些人试图复制一个人，他的图像取自有线新闻，他们还重新创建了图像底部显示的新闻字幕，并用胡言乱语填充它。如果你知道要找什么，通常的涂片和奇怪的人造物是无所不在的。</p>
<p class="translated">也就是说，它的效果如此之好，这是非常了不起的。然而，请注意，这只对脸部和上半身有效——你不能让蒙娜丽莎打响指或跳舞。反正还没有。</p>
			</div>

			</div>    
</body>
</html>