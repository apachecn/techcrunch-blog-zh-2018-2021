<html>
<head>
<title>AntiToxin sells safetytech to clean up poisoned platforms • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">抗毒素出售安全技术清理中毒平台TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2019/06/05/antitoxin-technologies/">https://web.archive.org/web/https://techcrunch.com/2019/06/05/antitoxin-technologies/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">大型社交网络和视频游戏未能将用户福祉置于自身发展之上。因此，社会正在输掉与欺凌、掠夺者、仇恨言论、错误信息和骗子的斗争。通常情况下，当一整类科技公司遇到他们自己无法经济高效地解决的严重问题时，软件即服务就会出现，以填补网络托管、支付处理等领域的空白。于是<a href="https://web.archive.org/web/20220929221933/http://antitoxin.com/">抗毒素技术</a>出现了，这是一家新的创业公司，希望通过其安全即服务来帮助网络巨头解决滥用问题。</p>
<p class="translated">这一切都始于《我的世界》。AntiToxin的联合创始人罗恩·波拉特是网络安全专家，他创办了广告拦截器Shine。然而就在他的眼皮底下，他的一个孩子在热门儿童游戏上被无情地欺负。如果连那些最熟悉互联网的父母都对网上虐待感到惊讶，波拉特意识到这个问题比试图保护自己的受害者所能解决的还要大。研究证实，这些平台必须做得更多。</p>
<p class="translated"><img loading="lazy" class="aligncenter size-large wp-image-1836948" src="../Images/6410989b14f24dfe930a4464e4d044f1.png" alt="" srcset="https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2019/06/bullying-the-bullies-image.png 645w, https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2019/06/bullying-the-bullies-image.png?resize=150,100 150w, https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2019/06/bullying-the-bullies-image.png?resize=300,200 300w, https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2019/06/bullying-the-bullies-image.png?resize=50,33 50w" sizes="(max-width: 645px) 100vw, 645px" data-original-src="https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2019/06/bullying-the-bullies-image.png?w=645"/></p>
<p class="translated">Ofcom最近的一项研究发现，近80%的儿童在过去的一年中有过潜在的有害网络经历。事实上，23%的人说他们受到过网络欺凌，28%的12至15岁的孩子说他们受到过不受欢迎的朋友或陌生人的邀请。一项<a href="https://web.archive.org/web/20220929221933/https://techcrunch.com/2017/07/19/ditch-the-label-2017-cyberbullying-report/">抛弃标签的研究</a>发现，12至20岁曾在网上被欺负的年轻人中，42%在Instagram上被欺负。</p>
<p class="translated">不幸的是，威胁的巨大规模加上顶级应用程序的监管起步较晚，如果没有巨额支出，进展将很艰难。脸书将其内容审核和安全团队的人数增加了两倍，这明显影响了其利润，但毒性依然存在。YouTube和Twitter等其他主流网站尚未对安全支出或人员配备做出具体承诺，结果是儿童剥削和有针对性的骚扰丑闻层出不穷。像Snap或堡垒之夜制造商Epic Games这样的小公司可能没有钱在内部开发足够的安全措施。</p>
<p class="translated">“科技巨头一次又一次地证明，我们不能依赖他们。他们已经放弃了他们的责任。AntiToxin联合创始人兼首席执行官Zohar Levkovitz说:“父母需要认识到，这些公司无法解决这个问题。”他之前以3.21亿美元的价格将自己的移动广告公司Amobee出售给了新加坡电信。“你需要新玩家、新思维、新技术。一家“安全”是产品而非事后想法的公司。这就是我们的切入点。”这家初创公司最近从红树林资本合伙人那里筹集了数百万美元的种子资金，据称正在准备两位数的数百万美元的a轮融资。</p>
<p class="translated"><img loading="lazy" class="aligncenter size-large wp-image-1747501" src="../Images/a4b1d0e10bd74ae3b1e2442135996836.png" alt="" srcset="https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2018/11/stop-bullying-newsroom-header.png 1390w, https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2018/11/stop-bullying-newsroom-header.png?resize=150,84 150w, https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2018/11/stop-bullying-newsroom-header.png?resize=300,169 300w, https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2018/11/stop-bullying-newsroom-header.png?resize=768,432 768w, https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2018/11/stop-bullying-newsroom-header.png?resize=680,382 680w, https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2018/11/stop-bullying-newsroom-header.png?resize=1200,674 1200w, https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2018/11/stop-bullying-newsroom-header.png?resize=50,28 50w" sizes="(max-width: 680px) 100vw, 680px" data-original-src="https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2018/11/stop-bullying-newsroom-header.png?w=680"/></p>
<p class="translated">AntiToxin的技术插入到社交社区应用程序的后端，这些应用程序相互广播或发送信息，因此容易被滥用。AntiToxin的系统能够秘密、安全地处理关于用户行为和违反政策报告的所有可用信号，从文本到视频再到屏蔽。然后，它可以标记各种各样的有害行为，让客户决定是否删除该活动，暂停负责的用户，或者根据他们的条款和当地法律继续进行。</p>
<p class="translated">通过使用人工智能，包括自然语言处理，机器学习和计算机视觉，抗毒素可以识别行为的意图，以确定它是否是恶意的。例如，该公司告诉我，它可以区分已婚夫妇在信息应用程序上自愿交换裸照和成年人向儿童发送不当图像。它还可以确定两个青少年在玩视频游戏时是否在开玩笑地咒骂对方，或者一个人是否在口头上骚扰对方。该公司表示，这比使用静态字典黑名单中的禁语要好。</p>
<p class="translated"><img loading="lazy" class="aligncenter wp-image-1837039" src="../Images/54774ac3ddea3916eb7dec23bb00bb8f.png" alt="" srcset="https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2019/06/AntiToxin-Technologies-Dashboard.png 1400w, https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2019/06/AntiToxin-Technologies-Dashboard.png?resize=150,84 150w, https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2019/06/AntiToxin-Technologies-Dashboard.png?resize=300,169 300w, https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2019/06/AntiToxin-Technologies-Dashboard.png?resize=768,432 768w, https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2019/06/AntiToxin-Technologies-Dashboard.png?resize=680,383 680w, https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2019/06/AntiToxin-Technologies-Dashboard.png?resize=1200,675 1200w, https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2019/06/AntiToxin-Technologies-Dashboard.png?resize=50,28 50w" sizes="(max-width: 900px) 100vw, 900px" data-original-src="https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2019/06/AntiToxin-Technologies-Dashboard.png?w=680"/></p>
<p class="translated">AntiToxin隶属于NDA，所以它不能透露其客户名单，但声称最近媒体的关注和即将出台的关于网上滥用的法规已经增加了人们的兴趣。最终，该公司希望建立更好的预测软件，以识别那些表现出越来越令人担忧的行为迹象的用户，以便在他们攻击之前更密切地控制他们的活动。它正试图建立一个“安全图”，这将有助于它识别跨服务的不良行为者，以便他们可以广泛地被淘汰，就像脸书使用Instagram滥用数据来监管相关WhatsApp账户的方式一样。</p>
<p class="translated">“我们正在像一家网络安全公司一样处理这个非常人性化的问题，也就是说，对我们来说一切都是零日，”Levkowitz说，他讨论了抗毒素如何索引新的滥用模式，然后可以在客户中搜索。“<span>我们有情报部门的校友、博士和数据科学家在创造全世界都渴望的反毒性检测算法。”抗毒素已经有影响了。TechCrunch委托它调查微软必应搜索引擎上一条关于儿童色情图片的线索。我们发现<a href="https://web.archive.org/web/20220929221933/https://techcrunch.com/2019/01/10/unsafe-search/">必应实际上是在向那些进行过无辜搜索的人推荐虐童图片结果</a>，这导致必应<a href="https://web.archive.org/web/20220929221933/https://www.theguardian.com/uk-news/2019/may/13/tech-giants-to-give-secret-evidence-at-child-sexual-abuse-inquiry">做出改变</a>以清理其行为。</span></p>
<p/><div id="attachment_1836944" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-1836944" loading="lazy" class="wp-image-1836944 size-large" src="../Images/f100aaba0ecfc065f4b7f9d73046f8be.png" alt="" srcset="https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2019/06/AntiToxin-Identifies-Abuse.png 1506w, https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2019/06/AntiToxin-Identifies-Abuse.png?resize=150,66 150w, https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2019/06/AntiToxin-Identifies-Abuse.png?resize=300,131 300w, https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2019/06/AntiToxin-Identifies-Abuse.png?resize=768,337 768w, https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2019/06/AntiToxin-Identifies-Abuse.png?resize=680,298 680w, https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2019/06/AntiToxin-Identifies-Abuse.png?resize=1200,526 1200w, https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2019/06/AntiToxin-Identifies-Abuse.png?resize=50,22 50w" sizes="(max-width: 680px) 100vw, 680px" data-original-src="https://web.archive.org/web/20220929221933im_/https://techcrunch.com/wp-content/uploads/2019/06/AntiToxin-Identifies-Abuse.png?w=680"/><p id="caption-attachment-1836944" class="wp-caption-text translated">AntiToxin确定了公开上市的WhatsApp群组，其中交换了儿童性虐待图像</p></div>
<p class="translated">抗毒素业务面临的一个主要威胁是通常被视为提高网络安全的东西:端到端加密。AntiToxin声称，当像脸书这样的公司扩展加密时，他们有目的地向自己隐藏有问题的内容，这样他们就不必监管它。</p>
<p class="translated">脸书声称，它仍然可以在已经加密的WhatApp网络上使用关于连接的元数据，以暂停违反其政策的人。但是，AntiToxin向TechCrunch提供了一项调查，该调查发现，儿童性虐待图像共享群在WhatsApp上是公开可访问和可发现的——部分原因是加密使WhatsApp的自动系统很难找到它们。</p>
<p class="translated">AntiToxin认为，如果加密成为一种更广泛的趋势，滥用将会激增，它声称它造成的伤害超过了对公司或政府监控未加密传输的担忧。这是一个艰难的决定。持不同政见者、告密者，或许还有整个公民自由的概念都依赖于加密。但是父母可能会认为性侵犯者和欺凌者是一个更可怕的问题，因为平台不知道人们在聊天线程中说了什么。</p>
<p class="translated">似乎很清楚的是，现状必须改变。羞辱、排斥、性别歧视、修饰、模仿和暴力威胁开始变得司空见惯。残酷的文化滋生了更多的残酷。科技的成功故事正被用户的恐怖故事所破坏。花钱购买对抗毒性的新武器似乎是一项合理的投资。</p>

			</div>

			</div>    
</body>
</html>