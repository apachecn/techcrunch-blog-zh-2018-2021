<html>
<head>
<title>MIT develops a system to give robots more human senses </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">麻省理工学院开发了一个系统，赋予机器人更多人类的感官</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2019/06/17/mit-develops-a-system-to-give-robots-more-human-senses/">https://web.archive.org/web/https://techcrunch.com/2019/06/17/mit-develops-a-system-to-give-robots-more-human-senses/</a></blockquote><div><header class="article__header ">
	<p class="article__title-wrapper">
						</p><h1 class="article__title translated">麻省理工学院开发了一个系统，赋予机器人更多人类的感官</h1>
		

			
	
			
	</header>

			<div class="article-content">
				<p id="speakable-summary" class="translated">麻省理工学院计算机科学和人工智能实验室(CSAIL)的研究人员<a href="https://web.archive.org/web/20230404234925/https://news.mit.edu/2019/teaching-ai-to-connect-senses-vision-touch-0617">开发了一个新系统</a>，它可以为机器人配备一些我们认为理所当然的东西:连接多种感官的能力。</p>
<p class="translated">CSAIL 创建的新系统包括一个预测性的人工智能，它能够学习如何使用它的“触觉”来看，反之亦然。这听起来可能令人困惑，但它实际上是在模仿人们每天都在做的事情，即看着一个表面、物体或材料，并预测这个东西一旦被触摸后的感觉，即它是否会变软、变粗糙、变粘等等。</p>
<p class="translated">该系统还可以接受基于触觉的输入，并将其转化为对它看起来像什么的预测——有点像那些儿童探索博物馆，你把你的手放入随机的盒子中，并试图拿到你在里面找到的物品。</p>
<p class="translated">这些例子可能无助于阐明为什么这实际上对构建有用，但是 CSAIL 提供的一个例子应该使这一点更加明显。研究团队将他们的系统与机械臂一起使用，以帮助它在看不到对象的情况下预测对象的位置，然后根据触摸来识别它——你可以想象这对于机器人肢体来说是有用的，它可以伸手去拿开关、杠杆甚至是它想要拿起的部件，并验证它有正确的东西，而不是，例如，它正在与人类操作员一起工作。</p>
<p class="translated">例如，这种类型的人工智能还可以用来帮助机器人在弱光环境中更有效地操作，而不需要先进的传感器，并且当与其他感官模拟技术结合使用时，可以作为更通用系统的组件。</p>
			</div>

			</div>    
</body>
</html>