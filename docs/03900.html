<html>
<head>
<title>Europe should ban AI for mass surveillance and social credit scoring, says advisory group </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">咨询小组称，欧洲应禁止人工智能用于大规模监控和社会信用评分</h1>
<blockquote>原文：<a href="https://web.archive.org/web/http://techcrunch.com/2019/06/26/europe-should-ban-ai-for-mass-surveillance-and-social-credit-scoring-says-advisory-group/">https://web.archive.org/web/http://techcrunch.com/2019/06/26/europe-should-ban-ai-for-mass-surveillance-and-social-credit-scoring-says-advisory-group/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">一个独立专家组发布了政策和投资建议，该专家组的任务是向欧盟委员会(European Commission)提供咨询，以告知其对人工智能的监管回应——以支持欧盟立法者确保人工智能发展“以人为本”的既定目标。</p>
<p class="translated">这遵循了早期“可信人工智能”的道德准则，由人工智能高级专家组(HLEG)在 4 月<a href="https://web.archive.org/web/20230308103624/https://techcrunch.com/2019/04/08/europe-to-pilot-ai-ethics-rules-calls-for-participants/">日</a>发布，当时委员会也呼吁参与者测试规则草案。</p>
<p class="translated">该小组完整的政策建议包括一份非常详细的 50 页文件，可以从这个<a href="https://web.archive.org/web/20230308103624/https://ec.europa.eu/digital-single-market/en/news/policy-and-investment-recommendations-trustworthy-artificial-intelligence">网页</a>下载。成立于 2018 年 6 月的<a href="https://web.archive.org/web/20230308103624/https://techcrunch.com/2018/06/14/here-are-the-experts-who-will-help-shape-europes-ai-policy/">小组由</a>行业人工智能专家、公民社会代表、政治顾问和政策专家、学者和法律专家组成。</p>
<p class="translated">该文件包括对使用人工智能对欧盟公民进行大规模监控和评分的警告，如<a href="https://web.archive.org/web/20230308103624/https://techcrunch.com/2019/01/28/china-social-credit/">中国的社会信用体系</a>，该组织呼吁彻底禁止“<span>人工智能支持的大规模个人评分”。它还敦促各国政府承诺不出于国家安全目的对人口进行全面监控。(因此，鉴于英国在 2016 年底通过成为法律的<a href="https://web.archive.org/web/20230308103624/https://techcrunch.com/2016/11/29/yes-the-uk-now-has-a-law-to-log-web-users-browsing-behavior-hack-devices-and-limit-encryption/">强大的国家监控权力</a>，英国投票脱离欧盟或许是件好事。)</span></p>
<p class="translated">HLEG 写道:“虽然政府可能有强大的诱惑，通过建立基于人工智能系统的普遍监控系统来‘保护社会’，但如果被推到极端水平，这将是极其危险的。”。“政府应该承诺不参与对个人的大规模监控，只部署和采购值得信赖的人工智能系统，这些系统旨在尊重法律和基本权利，符合道德原则，并且在社会技术上是稳健的。”</p>
<p class="translated">该组织还呼吁“反击”对个人和社会的商业监控——建议欧盟对滥用人工智能技术的潜力和潜力的回应应该包括确保在线人员跟踪“<span>严格符合隐私等基本权利”，包括(该组织具体说明)当它涉及“免费”服务时(尽管需要考虑商业模式如何受到影响)。</span></p>
<p class="translated">上周，英国数据保护监管机构向在线行为广告行业发出了更为明确的警告——警告称，adtech 为定向广告<a href="https://web.archive.org/web/20230308103624/https://techcrunch.com/2019/06/20/behavioural-advertising-is-out-of-control-warns-uk-watchdog/">大规模处理网络用户个人数据不符合欧盟隐私标准</a>。该行业被告知，其侵权行为必须改变，即使信息专员办公室还不打算采取行动。但是改革的警告是明确的。</p>
<p class="translated">随着欧盟政策制定者致力于为人工智能制定一个尊重权利的监管框架，寻求引导该地区未来十年以上的尖端技术发展，对数字实践和商业模式的更广泛关注和审查似乎将推动清理有问题的数字实践，在此之前，这些实践在没有或非常宽松的监管下得以激增。</p>
<div class="page" title="Page 30">
<div class="layoutArea">
<div class="column">
<p class="translated">HLEG 还呼吁支持开发保护个人数据的机制，并支持个人“控制他们的数据并由其授权”——他们认为这将解决“可信人工智能要求的某些方面”。</p>
<p class="translated">“应该开发工具来提供 GDPR 的技术实现，并通过设计技术方法来解释人工智能系统(如联邦机器学习)的个人数据处理中的标准和因果关系，从而发展隐私保护/隐私，”他们写道。</p>
<p class="translated">“支持匿名化和加密技术的技术发展，并制定基于个人数据控制的安全数据交换标准。促进公众在个人数据管理方面的教育，包括个人对基于人工智能个人数据的决策过程的认识和授权。创建技术解决方案，为个人提供关于如何使用其数据的信息和控制，例如用于研究、跨欧洲边界的同意管理和透明度，以及由此产生的任何改进和成果，并制定基于个人数据控制的安全数据交换标准。"</p>
</div>
</div>
</div>
<p class="translated">在 HLEG 的报告中包括的许多政策建议中，其他政策建议是，与人类互动的人工智能系统应该包括强制性的自我识别。这意味着没有偷偷摸摸的谷歌双工人类语言模仿机器人。在这种情况下，机器人将不得不提前介绍自己——从而给打电话的人一个脱身的机会。</p>
<p class="translated">HLEG 还建议建立一个“<span>欧洲战略，为儿童提供更好更安全的人工授精”。对猖獗的</span> <a href="https://web.archive.org/web/20230308103624/https://techcrunch.com/2018/11/09/children-are-being-datafied-before-weve-understood-the-risks-report-warns/">儿童数据化</a>的担忧和厌恶，包括通过对他们使用在线服务的商业跟踪，已经在多个欧盟成员国提出。</p>
<div class="page" title="Page 15">
<div class="layoutArea">
<div class="column">
<p class="translated">该组织写道:“应该为欧洲儿童提供一个童年，让他们在不受未经请求的监控、特征描述和兴趣投资习惯化和操纵的影响下成长和学习，从而确保后代的完整性和能动性。”。“应该确保儿童有一个自由和不受监督的发展空间，并且在步入成年后，应该为他们提供一个‘干净的石板’,存储与他们有关的任何公共或私人数据。同样，儿童的正规教育应该不受商业和其他利益的影响。”</p>
<p class="translated">HLEG 建议，成员国和欧盟委员会还应该设计一些方法来持续“分析、测量和评估人工智能的社会影响”,以记录积极和消极的影响，从而使政策能够适应不断变化的影响。</p>
<p class="translated">“可以考虑各种指数来衡量和评分人工智能的社会影响，如联合国可持续发展目标和欧洲社会支柱的社会记分牌指标。欧盟统计局的欧盟统计方案以及其他相关欧盟机构应被纳入这一机制，以确保所产生的信息是可信的、高质量和可核实的、可持续的和持续可用的。"基于人工智能的解决方案可以帮助监测和衡量其社会影响."</p>
<p class="translated">该报告还大力推动委员会加强对人工智能的投资——特别呼吁为创业公司和中小企业获得资金和建议提供更多帮助，包括通过 InvestEU 计划。</p>
<p class="translated">另一个建议是创建一个人工智能企业孵化器的 EU-广泛网络，以连接学术界和工业界。 <span>“这可以与 EU-开放创新实验室的创建结合起来，后者可以进一步建立在数字创新中心网络的结构上，”它继续说道。</span></p>
<p class="translated">也有人呼吁鼓励公共部门采用人工智能，例如通过将公共数据转换成数字格式来实现数字化；向政府机构提供 <span>数据素养教育；c </span> <span>为“高质量人工智能”创建欧洲大型带注释的公共非个人数据库；以及资助</span> <span>和促进人工智能工具的开发，这些工具可以帮助检测政府决策中的偏见和不适当的偏见。</span></p>
</div>
</div>
</div>
<p class="translated">报告的另一大部分涵盖了试图支持欧洲人工智能研究的建议——例如加强和创建更多卓越中心，这些中心解决战略研究课题，并成为“特定人工智能课题的欧洲水平倍增器”。</p>
<p class="translated">投资人工智能基础设施，如<span>分布式集群和边缘计算，大内存和快速网络，以及</span>测试设施和沙箱网络也受到敦促；以及“通过通用注释和标准化”对 EU-范围内的数据存储库的支持，以应对数据孤岛，以及医疗保健、汽车和农业食品等特定行业的可信数据空间。</p>
<p class="translated">HLEG 加速人工智能应用的努力受到了一些批评，数字权利组织 Access Now 的欧洲政策经理 Fanny Hidvegi<a href="https://web.archive.org/web/20230308103624/https://www.accessnow.org/european-union-more-big-words-on-ai-but-where-are-the-actions/">写道</a>:“我们现在需要的不是欧洲所有部门更多地采用人工智能，而是明确保护措施、红线和执行机制，以确保欧洲开发和部署的自动决策系统——以及更广泛的人工智能——尊重人权。”</p>
<p class="translated">HLEG 报告中的其他想法包括开发和实施人工智能的欧洲课程；监控和限制自动致命武器的发展——包括网络攻击工具等技术，这些技术不是“真正的武器”,但该组织指出“如果部署，可能会产生致命的后果”。</p>
<p class="translated">HLEG 进一步建议欧盟政策制定者不要赋予人工智能系统或机器人法律人格，写道:“我们认为这从根本上不符合人类代理、问责和责任的原则，并构成重大的道德风险。”</p>
<p class="translated">此处可下载报告全文<a href="https://web.archive.org/web/20230308103624/https://ec.europa.eu/digital-single-market/en/news/policy-and-investment-recommendations-trustworthy-artificial-intelligence">。</a></p>
			</div>

			</div>    
</body>
</html>