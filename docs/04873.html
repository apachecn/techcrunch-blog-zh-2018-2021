<html>
<head>
<title>Facebook is making its own deepfakes and offering prizes for detecting them • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">脸书正在制造自己的深度赝品，并为发现它们的人提供奖励</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2019/09/05/facebook-is-making-its-own-deepfakes-and-offering-prizes-for-detecting-them/">https://web.archive.org/web/https://techcrunch.com/2019/09/05/facebook-is-making-its-own-deepfakes-and-offering-prizes-for-detecting-them/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">由深度学习或所谓的“deepfakes”驱动的图像和视频操作代表了一个充满希望的新领域的一个奇怪而可怕的方面。如果我们要打击这些令人毛骨悚然的作品，我们需要以毒攻毒；脸书、微软和许多其他公司正在联合起来，帮助机器学习能够检测深度假货——他们希望你能提供帮助。</p>
<p class="translated">虽然这种现象仍然是新的，但我们仍然处于一场军备竞赛中，探测的方法与创造的方法在竞争。越来越多令人信服的假相经常出现，尽管它们通常是良性的，但将你的脸完美嫁接到一个有损形象的位置上的可能性非常大——许多名人已经这样做过了。</p>
<p class="translated">作为与微软、人工智能伙伴关系以及包括牛津大学、伯克利大学和麻省理工学院在内的几所大学联盟的一部分，脸书正在努力用更好的检测技术来增强善的一面。</p>
<p class="translated">脸书首席技术官迈克·斯科洛普夫昨天在一次媒体电话会议上表示:“当一个数据集上有一个明确的基准可以用来写论文时，人工智能领域最有趣的进步就发生了。”。用于物体识别的数据集可能是数百万幅普通物体的图像，而用于声音转录的数据集可能是数小时不同种类的语音。但是deepfakes就没有这一套了。</p>
<p class="translated">我们在今年早些时候的机器人和人工智能活动中谈到了这一挑战，我认为这是一次非常有趣的讨论:</p>
<p> </p><p embedded-video-placeholder="5cbb8b49791cad57f73a4918" post-id="1815139"/> 
<p class="translated">幸运的是，脸书正计划投入约1000万美元的资源来实现这一深度造假检测挑战。</p>
<p class="translated">“创建这些数据集可能具有挑战性，因为你要确保参与其中的每个人都清楚并同意，这样他们就不会对它的使用感到惊讶，”Schroepfer继续说道。由于大部分deepfakes是在没有任何同意的情况下制作的，它们在学术环境中是不允许使用的。</p>
<p class="translated">因此，脸书及其合作伙伴正在凭空制造深度假内容，他说。“你需要一个源视频数据集，然后是一个可以映射到其上的人物数据集。然后，我们将花费工程时间实施最新最先进的deepfake技术，以生成经过修改的视频作为数据集的一部分。”</p>
<p class="translated">虽然你完全有理由怀疑，不，他们没有使用脸书的数据来做这件事。他们有付费演员。</p>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-1877869" title="dfdc" src="../Images/4dd24a3473480e22adb5675d58a12b28.png" alt="dfdc" srcset="https://web.archive.org/web/20221221041821im_/https://techcrunch.com/wp-content/uploads/2019/09/dfdc.jpg 1863w, https://web.archive.org/web/20221221041821im_/https://techcrunch.com/wp-content/uploads/2019/09/dfdc.jpg?resize=150,83 150w, https://web.archive.org/web/20221221041821im_/https://techcrunch.com/wp-content/uploads/2019/09/dfdc.jpg?resize=300,167 300w, https://web.archive.org/web/20221221041821im_/https://techcrunch.com/wp-content/uploads/2019/09/dfdc.jpg?resize=768,427 768w, https://web.archive.org/web/20221221041821im_/https://techcrunch.com/wp-content/uploads/2019/09/dfdc.jpg?resize=680,379 680w, https://web.archive.org/web/20221221041821im_/https://techcrunch.com/wp-content/uploads/2019/09/dfdc.jpg?resize=1536,855 1536w, https://web.archive.org/web/20221221041821im_/https://techcrunch.com/wp-content/uploads/2019/09/dfdc.jpg?resize=1200,668 1200w, https://web.archive.org/web/20221221041821im_/https://techcrunch.com/wp-content/uploads/2019/09/dfdc.jpg?resize=50,28 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20221221041821im_/https://techcrunch.com/wp-content/uploads/2019/09/dfdc.jpg"/></p>
<p class="translated">该数据集将提供给感兴趣的各方，他们将能够构建解决方案并进行测试，将结果放在排行榜上。在某个时候，将会有现金奖励，尽管细节还很遥远。幸运的话，这将刺激学术界和研究人员之间的激烈竞争。</p>
<p class="translated">“我们需要研究界在开放环境中的充分参与，以开发能够检测和减轻被操纵的多媒体的不良影响的方法和系统，”马里兰大学的Rama Chellappa在新闻发布会上说。“通过提供大量真实和被操纵的媒体，拟议的挑战将激发并使研究界能够共同应对这一迫在眉睫的危机。​"</p>
<p class="translated">该数据集的初步测试计划在10月份的国际计算机视觉会议上进行，12月份在NeurIPS上全面推出。</p>
			</div>

			</div>    
</body>
</html>