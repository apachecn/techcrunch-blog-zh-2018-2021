<html>
<head>
<title>An interview with Dr. Stuart Russell, author of 'Human Compatible, Artificial Intelligence and the Problem of Control' </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">对《人类相容性、人工智能和控制问题》一书作者斯图尔特·拉塞尔博士的采访</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2019/10/06/an-interview-with-dr-stuart-russell-author-of-human-compatible-artificial-intelligence-and-the-problem-of-control/">https://web.archive.org/web/https://techcrunch.com/2019/10/06/an-interview-with-dr-stuart-russell-author-of-human-compatible-artificial-intelligence-and-the-problem-of-control/</a></blockquote><div><header class="article__header ">
	<p class="article__title-wrapper">
						</p><h1 class="article__title translated">对《人类相容性、人工智能和控制问题》一书作者斯图尔特·拉塞尔博士的采访</h1>
		

			
	
			
	</header>

			<div class="article-content">
				<p id="speakable-summary" class="translated"><span class="featured__span-first-words">(加州大学伯克利分校的</span> Stuart Russell 博士的新书《<em> <a href="https://web.archive.org/web/20230307015728/https://www.amazon.com/Human-Compatible-Artificial-Intelligence-Problem-ebook/dp/B07N5J5FTS">人类兼容:人工智能与控制问题</a> </em>》，将于 10 月 8 日上市。我写了一篇评论，<em>“<a href="https://web.archive.org/web/20230307015728/https://techcrunch.com/2019/10/06/human-compatible-is-a-provocative-prescription-to-re-think-ai-before-its-too-late/">人类兼容”是一个挑衅性的处方，在为时已晚之前重新思考人工智能</a>，”以下是 2019 年 9 月 3 日我在拉塞尔博士加州大学伯克利分校办公室对他进行的采访。)</em></p>

<p class="translated"><b>奈德·德斯蒙德:</b>你为什么要写<i>人类兼容</i>？</p>
<p class="translated">拉塞尔博士:我一直在想这个问题——如果我们在人工智能上取得成功会怎样？从 90 年代初开始断断续续。我越想越觉得我们走的这条路不会有好结果。</p>
<p class="translated">(人工智能研究人员)大多只是在实验室做玩具或游戏，没有一个对任何人构成威胁。这有点像物理学家玩微小的铀。什么都没发生，对吗？所以我们只要好好利用它，一切都会好的。但事情不是这样的。当你开始转向更智能的系统，在全球范围内运作，并对现实世界产生影响，比如交易算法，或社交媒体内容选择，那么突然间，你对现实世界产生了巨大的影响，而且很难控制。很难撤销。这只会变得越来越糟。</p>
<p/><div id="attachment_1893486" class="wp-caption alignnone"><a href="https://web.archive.org/web/20230307015728/https://techcrunch.com/2019/10/06/human-compatible-is-a-provocative-prescription-to-re-think-ai-before-its-too-late/deans-society-october-23-2006-stuart-russell/" rel="attachment wp-att-1893486"><img aria-describedby="caption-attachment-1893486" decoding="async" class="breakout size-full wp-image-1893486" title="Dean's Society - October 23, 2006; Stuart Russell" src="../Images/09402494bd888e9aa9b6bfcb492da6b8.png" alt="Stuart Russell HUMAN COMPATIBLE Credit Peg Skorpinski" srcset="https://web.archive.org/web/20230307015728im_/https://techcrunch.com/wp-content/uploads/2019/10/Stuart-Russell-HUMAN-COMPATIBLE-Credit-Peg-Skorpinski.jpg 1678w, https://web.archive.org/web/20230307015728im_/https://techcrunch.com/wp-content/uploads/2019/10/Stuart-Russell-HUMAN-COMPATIBLE-Credit-Peg-Skorpinski.jpg?resize=132,150 132w, https://web.archive.org/web/20230307015728im_/https://techcrunch.com/wp-content/uploads/2019/10/Stuart-Russell-HUMAN-COMPATIBLE-Credit-Peg-Skorpinski.jpg?resize=263,300 263w, https://web.archive.org/web/20230307015728im_/https://techcrunch.com/wp-content/uploads/2019/10/Stuart-Russell-HUMAN-COMPATIBLE-Credit-Peg-Skorpinski.jpg?resize=768,876 768w, https://web.archive.org/web/20230307015728im_/https://techcrunch.com/wp-content/uploads/2019/10/Stuart-Russell-HUMAN-COMPATIBLE-Credit-Peg-Skorpinski.jpg?resize=596,680 596w, https://web.archive.org/web/20230307015728im_/https://techcrunch.com/wp-content/uploads/2019/10/Stuart-Russell-HUMAN-COMPATIBLE-Credit-Peg-Skorpinski.jpg?resize=1347,1536 1347w, https://web.archive.org/web/20230307015728im_/https://techcrunch.com/wp-content/uploads/2019/10/Stuart-Russell-HUMAN-COMPATIBLE-Credit-Peg-Skorpinski.jpg?resize=1053,1200 1053w, https://web.archive.org/web/20230307015728im_/https://techcrunch.com/wp-content/uploads/2019/10/Stuart-Russell-HUMAN-COMPATIBLE-Credit-Peg-Skorpinski.jpg?resize=44,50 44w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230307015728im_/https://techcrunch.com/wp-content/uploads/2019/10/Stuart-Russell-HUMAN-COMPATIBLE-Credit-Peg-Skorpinski.jpg"/></a><p id="caption-attachment-1893486" class="wp-caption-text translated">院长协会——2006 年 10 月 23 日；斯图尔特·罗素</p></div>
<p class="translated"><b> Desmond: </b>谁应该读<i>人类兼容</i>？</p>
<p class="translated">拉塞尔博士:我想每个人都是，因为每个人都会受到影响。随着人类水平(人工智能)的进步，每一大步都将把影响放大 10 倍或 100 倍。每个人的生活都将因此受到彻底的影响。人们需要理解它。更具体地说，应该是决策者，运营谷歌和亚马逊等大公司的人，以及人工智能和相关学科的人，如控制理论、认知科学等。</p>
<p class="translated">我的基本观点是，这么多的争论正在进行，却没有任何关于人工智能是什么的理解。就是这种神奇的药水会让东西变得聪明。在这些争论中，人们不理解积木，它是如何组合在一起的，它是如何工作的，你如何制造一个智能系统。所以第二章(与人类兼容的)有点庞大，有些人说，“哦，这太难了，其他人说，“不，你绝对必须保留它。“所以我妥协了，把教育学的东西放在附录里。</p>
<p class="translated"><b>德斯蒙德:</b>为什么计算机科学家倾向于忽略人工智能系统的<i>目标</i>函数中<i>不确定性</i>的问题？</p>
<p class="translated"><strong>拉塞尔博士:</strong>有趣的是，在人工智能领域，我们从 80 年代就开始关注(决策功能中的)不确定性。在此之前，大多数人工智能人员说，让我们只研究我们有明确知识的案例，我们可以提出有保证的计划。</p>
<p/>			</div>

			</div>    
</body>
</html>