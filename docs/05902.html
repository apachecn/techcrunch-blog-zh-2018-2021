<html>
<head>
<title>Twitter drafts a deepfake policy that would label and warn, but not always remove, manipulated media • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Twitter起草了一项深度造假政策，该政策将对被操纵的媒体进行标记和警告，但并不总是删除它们</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2019/11/11/twitter-drafts-a-deepfake-policy-that-would-label-and-warn-but-not-remove-manipulated-media/">https://web.archive.org/web/https://techcrunch.com/2019/11/11/twitter-drafts-a-deepfake-policy-that-would-label-and-warn-but-not-remove-manipulated-media/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">Twitter上个月<a href="https://web.archive.org/web/20221202170235/https://twitter.com/TwitterSafety/status/1186403736995807232">表示</a>将推出一项新政策，以帮助打击deepfakes和其他“被操纵的媒体”,这些媒体涉及照片、视频或音频，这些照片、视频或音频被显著修改以改变其原始含义或目的，或者那些看起来像发生了实际上并没有发生的事情。今天，推特<a href="https://web.archive.org/web/20221202170235/https://blog.twitter.com/en_us/topics/company/2019/synthetic_manipulated_media_policy_feedback.html">分享了其新政策的草案，并在上线前公开征求公众意见。</a></p>
<p class="translated">该政策旨在解决当今互联网上日益严重的deepfakes问题。</p>
<p class="translated">由于人工智能的进步，制作令人信服的虚假视频、音频和其他数字内容变得更加容易，Deepfakes已经激增。任何有电脑和互联网连接的人现在都可以创造这种假媒体。当被用作宣传或者让某人相信某样东西是真实的时候，<a href="https://web.archive.org/web/20221202170235/https://www.cnbc.com/2019/10/14/what-is-deepfake-and-how-it-might-be-dangerous.html">技术可能是危险的。在政治上，deepfakes可以用来破坏候选人的声誉，让他们说和做他们从来没有说过或做过的事情。</a></p>
<p class="translated">今年早些时候，在脸书拒绝撤下一段显示众议院议长南希·佩洛西说话结结巴巴的篡改过的视频后，脸书首席执行官马克·扎克伯格的一段深度模仿视频在网上疯传。</p>
<p class="translated">10月初，参议院情报委员会的两名成员，马克·华纳(D-VA)和马尔科·卢比奥(R-FL)，<a href="https://web.archive.org/web/20221202170235/https://www.cbsnews.com/news/deepfakes-mark-warner-marco-rubio-pressure-social-media-giants-to-crack-down/">呼吁主要的科技公司</a>制定一项计划来打击他们平台上的deepfakes。参议员们要求11家科技公司——包括脸书、Twitter、YouTube、Reddit和LinkedIn——提出一项计划，尽快为“分享、删除、存档和应对合成内容的分享”制定行业标准</p>
<p class="translated">本月晚些时候，Twitter宣布了其寻求公众对该政策反馈的计划。与此同时，亚马逊<a href="https://web.archive.org/web/20221202170235/https://aws.amazon.com/blogs/machine-learning/aws-supports-the-deepfake-detection-challenge-with-competition-data-and-aws-credits/">与脸书和微软</a>联手支持DeepFake检测挑战(DFDC)，旨在开发新的方法来检测被操纵的媒体。</p>
<p class="translated">今天，Twitter正在详细介绍其deepfakes政策的草案。该公司表示，当它看到合成或操纵的媒体故意试图误导或混淆人们时，它将:</p>
<blockquote>
 
<ul>
<li class="translated">在分享合成或操纵媒体的推文旁边放置一个通知；</li>
<li class="translated">在人们分享或喜欢合成或操纵媒体的推文之前警告他们；或者</li>
<li class="translated">添加一个链接——例如，一篇新闻文章或Twitter时刻——以便人们可以阅读更多关于为什么各种来源认为媒体是合成的或被操纵的。</li>
</ul>
</blockquote>
<p class="translated">Twitter表示，如果deepfake可能威胁到某人的人身安全或导致严重伤害，它也可能会将其删除。</p>
<p class="translated">该公司通过调查以及Twitter上的<a href="https://web.archive.org/web/20221202170235/https://twitter.com/search?q=%23twitterpolicyfeedback&amp;src=typed_query&amp;f=live"> #TwitterPolicyFeedback </a>标签接受反馈。</p>
<p class="translated"><a href="https://web.archive.org/web/20221202170235/https://survey.twitterfeedback.com/survey/selfserve/53b/191016?list=3&amp;co=BLOG#?">调查</a>提出了一些问题，比如修改过的照片和视频是应该完全删除，贴上警告标签，还是根本不删除。它还询问某些行为是否可以接受，比如隐藏推文或提醒人们是否要分享一个深度假消息。它还询问何时应该删除带有误导性媒体的推文。Twitter制定的政策称，如果推文威胁到某人的人身安全，将被删除，否则将被贴上标签。调查显示，有时一条推文可能会被删除——比如威胁到某人的精神健康、隐私、尊严、财产等等。</p>
<p class="translated">本调查需要五分钟完成，提供英语、日语、葡萄牙语、阿拉伯语、印地语和西班牙语版本。</p>
<p class="translated">然而，尚不清楚的是，Twitter将如何检测其平台上发布的deepfakes，因为检测技术并不完美，而且<a href="https://web.archive.org/web/20221202170235/https://www.brookings.edu/blog/techtank/2019/02/14/artificial-intelligence-deepfakes-and-the-uncertain-future-of-truth/">往往落后于</a>更新更先进的创作方法。在这方面，Twitter邀请那些希望与它合作开发检测解决方案的人填写一张<a href="https://web.archive.org/web/20221202170235/https://docs.google.com/forms/d/e/1FAIpQLSdfulxKBUmYfgLqK5p2BgtH01tBaSRD870YwfLeABMZW7deww/viewform">表格</a>。</p>
<p class="translated">Twitter从现在开始接受对其deepfakes政策的反馈，直到11月27日星期三晚上11:59 GMT。届时，它将审查收到的反馈，并根据需要对政策进行调整。该政策随后将被纳入Twitter的规则，并在变更生效前30天发出通知。</p>
<p> </p>
			</div>

			</div>    
</body>
</html>