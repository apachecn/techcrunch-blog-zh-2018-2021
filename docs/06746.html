<html>
<head>
<title>Study of YouTube comments finds evidence of radicalization effect • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">对YouTube评论的研究发现了激进化效应的证据</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2020/01/28/study-of-youtube-comments-finds-evidence-of-radicalization-effect/">https://web.archive.org/web/https://techcrunch.com/2020/01/28/study-of-youtube-comments-finds-evidence-of-radicalization-effect/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">今天在巴塞罗那举行的<a href="https://web.archive.org/web/20230220055219/https://fatconference.org/2020/"> ACM FAT 2020 </a>会议上展示的研究结果支持了这样一种观点，即YouTube的平台通过暴露极右意识形态在煽动用户方面发挥了作用。</p>
<p class="translated">这项由瑞士洛桑联邦理工学院和巴西米纳斯吉拉斯联邦大学的研究人员进行的研究发现，有证据表明，参与极右内容中间立场的用户会转而评论最边缘的极右内容。</p>
<p class="translated">2018年3月,《T2时报》、《纽约时报》和社会学家泽伊内普·图费克西的一篇文章阐述了一个现在被广泛报道的论点，即YouTube是一个激进化的引擎。记者凯文·罗斯的后续报道《T4》讲述了一个引人注目的个人经历，凯莱布·凯恩，他在YouTube上描述了自己掉进了一个“右兔子洞”。但是今天发表这篇论文的研究员马诺埃尔·霍塔·里贝罗说，研究小组想看看他们是否能找到可审计的证据来支持这些轶事。</p>
<p class="translated">他们的论文名为“审核YouTube上的激进化途径”，详细描述了一项针对YouTube的大规模研究，旨在寻找证据——在喜好、评论和观点中——证明某些右翼YouTube社区正在充当极端右翼意识形态的门户。</p>
<p class="translated">根据这篇论文，他们分析了349个频道上发布的330，925个视频——将视频大致分为四类:媒体、Alt-lite、intelligent black Web(IDW)和Alt-right——并将用户评论作为激进化的“足够好”的代理(他们的数据集包括7200万条评论)。</p>
<p class="translated">这些发现表明，随着时间的推移，最初评论alt-lite/IDW YouTube内容的用户逐渐转向评论平台上的极右内容，这是一种多年来的管道效应。</p>
<p class="translated">媒体内容消费者和alt-right消费者之间的重叠率被发现要低得多。</p>
<p class="translated">他们在论文中写道:“大量评论用户系统地从专门评论温和内容转向评论更极端的内容。”“我们认为，这一发现提供了重要的证据，表明YouTube上已经存在并将继续存在用户激进化，我们对这些社区活动的分析……与更极端的内容‘搭上’I . d . w .和Alt-lite内容受欢迎程度飙升的理论相一致……我们表明，这种迁移现象不仅多年来一直存在，而且在绝对数量上也很重要。”</p>
<p class="translated">研究人员无法确定YouTube用户从消费“alt lite”政治转向参与最边缘和极端极右意识形态的确切机制——列举了这方面的几个关键挑战:限制对推荐数据的访问；这项研究没有考虑个性化因素(这可能会影响用户在YouTube上的推荐)。</p>
<p class="translated">但是，即使没有个性化，他们说他们“仍然能够找到一条用户可以从大型媒体渠道找到极端内容的途径。”</p>
<p class="translated">在提交论文后的一次问答会议上，Horta Ribeiro被问及他们有什么证据表明该研究确定的激进化影响是通过YouTube而不是通过一些外部网站发生的——或者因为被讨论的人一开始就更激进(因此更容易被极端意识形态吸引)，而不是YouTube本身是一个活跃的激进化渠道。</p>
<p class="translated">他同意很难断言YouTube是罪魁祸首。但也认为，作为这些社区的东道主，该平台是有责任的。</p>
<p class="translated">“我们确实发现了用户激进化的明显痕迹，我猜这个问题问的是为什么YouTube要对此负责？我想答案是，因为这些社区中的许多人生活在YouTube上，他们在YouTube上有很多内容，这就是为什么YouTube与它有如此深的联系，”他说。</p>
<p class="translated">“从某种意义上说，我确实同意，很难断言这种激进化是由于YouTube或某些推荐系统，或者该平台对此负责。可能是其他原因导致了这种激进化，从这个意义上说，我认为我们所做的分析表明，用户从温和的渠道转向更极端的渠道是一个过程。这是走向激进化的确凿证据，因为没有接触过这些激进内容的人变得暴露了。但很难做出强有力的因果断言——就像YouTube应该对此负责一样。”</p>
<p class="translated">我们联系了YouTube寻求对这项研究的回应，但该公司没有回复我们的问题。</p>
<p class="translated">面对<a href="https://web.archive.org/web/20230220055219/https://techcrunch.com/2017/12/19/youtube-more-ai-can-fix-ai-generated-bubbles-of-hate/">在仇恨言论、有针对性的骚扰和激进化风险方面日益增长的政治</a>和公众<a href="https://web.archive.org/web/20230220055219/https://techcrunch.com/2019/03/07/youtube-under-pressure-to-ban-uk-far-right-activist-after-livestreamed-intimidation/">压力</a>，该公司近年来收紧了对某些极右翼和<a href="https://web.archive.org/web/20230220055219/https://techcrunch.com/2017/11/14/in-major-policy-change-youtube-is-now-taking-down-more-videos-of-known-extremists/">极端主义内容的态度</a>。</p>
<p class="translated">它也一直在尝试减少某些类型的潜在破坏性废话内容的算法放大，这些内容超出了它的一般内容指南，如恶意阴谋论和垃圾科学。</p>
			</div>

			</div>    
</body>
</html>