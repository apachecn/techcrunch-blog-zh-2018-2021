<html>
<head>
<title>Online targeting needs tighter controls, UK data ethics body suggests </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">英国数据伦理机构建议，网络目标需要更严格的控制</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2020/02/04/online-targeting-needs-tighter-controls-uk-data-ethics-body-suggests/">https://web.archive.org/web/https://techcrunch.com/2020/02/04/online-targeting-needs-tighter-controls-uk-data-ethics-body-suggests/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">一个关于人工智能和数据伦理的英国政府咨询机构建议对平台巨头如何使用广告定位和内容个性化进行更严格的控制。</p>
<p class="translated">对在线平台基本上不受监管的吸引眼球的定向策略的担忧——无论是通过向个人或用户群体提供“个性化内容”还是“微定向广告”——包括产生成瘾行为的风险；对弱势群体的剥削和/或歧视；错误信息的扩大；和干涉选举，等等。</p>
<p class="translated">在今天发布的一份报告中，数据伦理与创新中心(CDEI)为那些使用定位工具来决定向用户展示什么内容或广告的平台提出了许多建议。它认为这些建议将有助于建立公众对数字服务的信任，包括那些由公共部门提供的服务。</p>
<p class="translated">“大多数人不希望目标锁定停止。但是他们确实想知道这样做是安全的和合乎道德的。他们想要更多的控制权，”董事长罗杰·泰勒在一份执行摘要中写道。</p>
<p class="translated">“我们对监管环境的分析表明，他们的监管监督存在重大漏洞，”报告继续写道。“我们对公众态度的分析显示，人们对在大型平台上使用在线目标定位最为关注和感兴趣。</p>
<p class="translated">“我们的研究表明，社交媒体平台(如脸书和推特)、视频分享平台(如YouTube、Snapchat和抖音)和搜索引擎(如谷歌和必应)使用的在线定位系统在这些领域引起了最大的关注。”</p>
<p class="translated">该咨询机构由保守党领导的政府于2017年宣布，旨在帮助制定监管人工智能和数据驱动技术使用的政策，呼吁在线目标巨头在使用目标工具时遵守更高的问责标准。</p>
<p class="translated">根据其分析，目前的监管不足以涵盖在线目标，同时它认为自我监管和现状是“不可持续的”。</p>
<p class="translated">CDEI进行的一项调查的受访者压倒性地支持(61%)让独立监管机构监督在线目标系统的使用，而只有17%的人倾向于继续自我监管。</p>
<p class="translated"><span>英国政府在去年发布的</span> <a href="https://web.archive.org/web/20230323105047/https://techcrunch.com/2019/04/08/uk-sets-out-safety-focused-plan-to-regulate-internet-firms/">白皮书中制定了一项计划，以监管大量的在线伤害</a>——该白皮书建议在平台上设置注意义务，以保护用户免受一系列伤害，如年龄不适当的内容或鼓励自残或饮食失调等有害行为的材料。</p>
<p class="translated">何表示，这一提议的框架可能有助于填补其报告中指出的一些监管空白“如果在线定位在独立监管机构的职权范围内得到认可”(同时警告称，这仍将在政治广告监管方面留下一些空白)。</p>
<p class="translated">该报告还呼吁提高在线定位系统运作的透明度，“以便社会能够更好地了解这些系统的影响，政策应对能够建立在有力的证据基础上”。</p>
<p class="translated">另一个重要的建议是让互联网用户对他们被锁定的方式有更大的控制权，这样个性化可以更好地适应他们的偏好。</p>
<p class="translated">“在线瞄准帮助一些全球在线平台企业获得了预测和影响行为的巨大权力。然而，目前追究他们责任的机制是不够的，”CDEI写道。“我们已经审查了现有监管机构的权力，并得出结论，不能依靠执行现有立法和自我监管来满足公众对更大问责的期望。”</p>
<p class="translated">“行业和公众都认识到，自我监管是有限度的，现状是不可持续的。现在是时候采取监管行动，采取相称的步骤来加强问责制、透明度和用户授权，”它补充说。</p>
<p class="translated">CDEI本身并没有提议任何具体的限制，而是主张建立一种“有计划地促进责任和透明度并保障人权”的监管制度。</p>
<p class="translated">它还建议对使用在线目标系统的平台和服务适用行为守则，要求它们采用"风险管理、透明度和保护弱势人群的标准，以便它们对在线目标系统对用户的影响负责"。</p>
<p class="translated">未来的网络伤害监管机构应该有保护和尊重言论自由和隐私的法定义务，它还建议，写道:“应该制定在线目标的监管，以保障言论自由和在线隐私，并促进基于人权的国际规范。”</p>
<p class="translated">根据建议，监管机构还需要信息收集权，以评估对准则的遵守情况——包括要求独立专家获得安全访问平台数据的权力，以便对其准则进行进一步的合规性测试。</p>
<p class="translated">“在线定位系统可能对心理健康产生负面影响，例如可能导致‘网络成瘾’。它们可能导致社会问题，包括激进化和政治观点的两极化。报告警告说:“这些是公众非常关注的问题，人们对危害的风险知之甚少，但潜在的影响太大，不容忽视。”。</p>
<p class="translated">“我们建议监管机构促进对重大公共利益问题的独立学术研究，并有权要求在线平台让独立研究人员安全访问他们的数据。没有这一点，监管机构和其他政策制定者将无法制定基于证据的政策并确定最佳实践。”</p>
<p class="translated">另一项建议是，要求平台维护在线广告档案，“为政治广告等构成特定社会风险的个性化广告类型提供透明度”；可能存在非法歧视风险的就业和其他类似机会；对于有年龄限制的产品。</p>
<p class="translated">广告档案是包括脸书在内的广告平台近年来开发和实施的自律措施之一，因为在剑桥分析公司(Cambridge Analytica)利用脸书的广告工具和用户数据进行政治广告定位丑闻之后，对其系统的审查已经加强。</p>
<p class="translated">尽管这样的档案仍然倾向于向用户提供有限的可见性，而且脸书已经受到研究人员的严厉批评，因为没有提供足够的工具来支持对其平台的学术研究。</p>
<p class="translated">对于用户如何成为目标的“更有意义的控制”，该中心建议支持第三方“数据中介”的新市场，使用户的利益能够在多种服务和新的第三方安全应用中得到体现。</p>
<p class="translated">它还呼吁未来的在线危害监管机构与英国数据监管机构(ICO)和竞争与市场管理局(CMA)之间建立正式的协调机制。该报告指出了ICO和CMA正在开展的其他相关工作，包括<a href="https://web.archive.org/web/20230323105047/https://techcrunch.com/2020/01/22/uk-watchdog-sets-out-age-appropriate-design-code-for-online-services-to-keep-kids-privacy-safe/"> ICO的适龄设计规范</a>；CMA对在线平台和数字广告的市场研究。</p>
<p class="translated">后者在去年年底对科技巨头的市场力量表示担忧，在其中期报告中提出了一系列潜在的干预措施，包括征求对拆分平台巨头的意见。</p>

			</div>

			</div>    
</body>
</html>