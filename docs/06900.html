<html>
<head>
<title>Blackbox welfare fraud detection system breaches human rights, Dutch court rules </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">黑盒福利欺诈检测系统违反人权，荷兰法院规则</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2020/02/06/blackbox-welfare-fraud-detection-system-breaches-human-rights-dutch-court-rules/">https://web.archive.org/web/https://techcrunch.com/2020/02/06/blackbox-welfare-fraud-detection-system-breaches-human-rights-dutch-court-rules/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">荷兰一家法院裁定，荷兰政府部署的一个算法风险评分系统，试图预测社会保障申请人实施福利或税务欺诈的可能性，违反了人权法。</p>
<p class="translated">荷兰政府的系统风险指示(SyRI)立法使用一种非公开的算法风险模型来描述公民，并且专门针对主要是低收入和少数民族居民的社区。人权活动家称其为“福利监督国家”。</p>
<p class="translated">荷兰的一些民间社会组织和两名公民发起了针对SyRI的法律行动，试图阻止其使用。法庭今天下令立即停止使用该系统。</p>
<p class="translated">该<a href="https://web.archive.org/web/20230306043138/https://uitspraken.rechtspraak.nl/inziendocument?id=ECLI:NL:RBDHA:2020:865">裁决</a>(现为<a href="https://web.archive.org/web/20230306043138/https://uitspraken.rechtspraak.nl/inziendocument?id=ECLI:NL:RBDHA:2020:1878">英文</a>)被人权活动家誉为具有里程碑意义的判决，法院的推理基于欧洲人权法——特别是《欧洲人权公约》(ECHR)第8条规定的私人生活权——而不是欧盟数据保护框架(GDPR)中与自动处理相关的专门条款。</p>
<p class="translated">GDPR的第22条包括个人有权不受制于可产生重大法律效力的完全自动化的个人决策。但是，如果在循环中的某个地方有一个人，比如审查反对意见的决定，这是否适用就有些模糊了。</p>
<p class="translated">在这种情况下，法院回避了这些问题，认为叙利亚直接干涉了ECHR规定的权利。</p>
<p class="translated">具体而言，法院认为叙利亚的立法未能通过《ECHR》第8条的平衡测试，该条要求将任何社会利益与侵犯个人私生活的行为相权衡，需要公平合理的平衡。法院认为，自动风险评估系统没有通过这一测试。</p>
<p class="translated">法律专家建议，该决定对英国公共部门如何利用人工智能工具设置了一些明确的限制——法院尤其反对算法风险评分系统如何运作缺乏透明度。</p>
<p class="translated">在一份关于该判决的新闻稿中，法院写道，使用叙利亚语“不够清晰和可控”。而根据<a href="https://web.archive.org/web/20230306043138/https://www.hrw.org/news/2020/02/06/dutch-ruling-victory-rights-poor">人权观察</a>的说法，荷兰政府在听证会上拒绝透露关于叙利亚如何使用个人数据推断可能的欺诈的“有意义的信息”。</p>
<p class="translated">法院显然对国家试图通过指向一个算法“黑箱”和耸耸肩来规避人权风险审查持否定态度。</p>

<p class="translated">联合国极端贫困和人权问题特别报告员菲利普·奥尔斯顿(Philip Alston)通过向法院提供<a href="https://web.archive.org/web/20230306043138/https://www.ohchr.org/Documents/Issues/Poverty/Amicusfinalversionsigned.pdf">人权分析</a>介入了此案，他对判决表示欢迎，称其为“所有那些有理由关注数字福利系统对人权构成的严重威胁的人的明显胜利。”</p>
<p class="translated">“这一判决为其他法院树立了一个强有力的法律先例。这是世界上第一次有法院以人权为由阻止福利机构使用数字技术和大量数字信息，”他在一份新闻声明中补充道。</p>
<p class="translated">回到<a href="https://web.archive.org/web/20230306043138/https://techcrunch.com/2018/11/16/un-warns-over-human-rights-impact-of-a-digital-welfare-state/"> 2018 </a>，阿尔斯通警告说，英国政府急于应用数字技术和数据工具来大规模地从社会上重新设计公共服务的提供，这有可能对最弱势群体的人权产生巨大影响。</p>
<p class="translated">因此，荷兰法院的判决可能会对英国在这一领域的政策产生一些短期影响。</p>
<p class="translated"><span>该判决并没有完全禁止各国使用自动特征分析系统，但它明确指出，欧洲的人权法必须是设计和实施权利风险工具的核心。</span></p>
<p class="translated"><span>这也发生在一个关键时刻，欧盟政策制定者正在制定一个监管人工智能的框架<a href="https://web.archive.org/web/20230306043138/https://techcrunch.com/2020/01/17/eu-lawmakers-are-eyeing-risk-based-rules-for-ai-per-leaked-white-paper/">——欧盟委员会承诺制定规则，确保人工智能技术以道德和以人为本的方式得到应用。</a></span></p>
<p class="translated">委员会是否会推动泛欧盟限制人工智能在特定公共部门的使用(如社会安全评估)，还有待观察。 <span>一份<a href="https://web.archive.org/web/20230306043138/https://techcrunch.com/2020/01/17/eu-lawmakers-are-eyeing-risk-based-rules-for-ai-per-leaked-white-paper/">最近泄露的人工智能监管白皮书草案</a>表明其倾向于风险评估和基于风险的规则拼凑。</span></p>
			</div>

			</div>    
</body>
</html>