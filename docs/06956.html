<html>
<head>
<title>UK public sector failing to be open about its use of AI, review finds </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">审查发现，英国公共部门未能公开其人工智能的使用</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2020/02/10/uk-public-sector-failing-to-be-open-about-its-use-of-ai-review-finds/">https://web.archive.org/web/https://techcrunch.com/2020/02/10/uk-public-sector-failing-to-be-open-about-its-use-of-ai-review-finds/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">一份关于英国公共部门使用人工智能的报告警告说，政府未能公开自动化决策技术，这些技术有可能对公民的生活产生重大影响。</p>
<p class="translated">部长们尤其看好向纳税人资助的医疗保健服务注入新技术——卫生部长马特·汉考克(Matt Hancock)在 2018 年<a href="https://web.archive.org/web/20230306045856/https://techcrunch.com/2018/10/17/uk-health-minister-sets-out-tech-first-vision-for-future-care-provision/"/>提出了一个由技术推动的“预防性、预测性和个性化护理”的愿景，呼吁国民医疗服务体系(NHS)进行彻底的数字化转型，以支持将患者数据传输到新一代“健康技术”应用程序和服务。</p>
<p class="translated">他还<a href="https://web.archive.org/web/20230306045856/https://www.theguardian.com/politics/2018/nov/30/matt-hancock-accused-of-breaching-code-over-gp-app-endorsement">亲自支持了一家聊天机器人初创公司</a>，<a href="https://web.archive.org/web/20230306045856/https://techcrunch.com/2019/08/02/babylon-health-confirms-550m-raise-to-expand-its-ai-based-health-services-to-the-us-and-asia/"> Babylon Health </a>，该公司正在利用人工智能进行医疗保健分类——目前正在向英国国民医疗服务体系(NHS)出售一项服务。</p>
<p class="translated">警务是人工智能加速进入英国公共服务交付的另一个领域，许多警察部队正在测试面部识别技术——伦敦警察局上个月刚刚<a href="https://web.archive.org/web/20230306045856/https://techcrunch.com/2020/01/24/londons-met-police-switches-on-live-facial-recognition-flying-in-face-of-human-rights-concerns/">切换到人工智能技术的现场部署</a>。</p>
<p class="translated">然而，资金紧张的公共服务急于利用人工智能的“效率”，这有可能掩盖对这种自动化系统的设计和实施的一系列道德担忧，从担心在服务交付中嵌入偏见和歧视以及扩大有害结果，到访问用于建立人工智能模型的数据集的同意问题，以及人类对自动化结果的代理，等等，所有这些都需要人工智能的透明度，如果要对自动化结果负责的话。</p>
<p class="translated">商业公司在向公共部门提供人工智能服务方面的角色也提出了额外的道德和法律问题。</p>
<p class="translated">就在上周，荷兰一家法院强调了政府急于将人工智能纳入立法的风险，此前该法院裁定荷兰政府实施的一种算法风险评分系统侵犯了他们的人权，该系统旨在评估社会保障申请人实施福利或税务欺诈的可能性。</p>
<p class="translated">法院反对该系统如何运作缺乏透明度，以及相关的缺乏可控制性——命令立即停止使用。</p>
<p class="translated">审查公共生活标准的英国议会委员会今天发出了类似的警告——发布了一系列关于公共部门使用人工智能的建议，并警告说，这项技术挑战了服务提供的三个关键原则:公开性、问责制和客观性。</p>
<p class="translated">“在开放的原则下，目前缺乏政府使用人工智能的信息可能会破坏透明度，”它在一份执行摘要中写道。</p>
<p class="translated">“在问责制的原则下，有三种风险:人工智能可能会模糊组织问责制的链条；削弱对公职人员所作关键决定的责任归属；并阻止政府官员对人工智能作出的决定提供有意义的解释。根据客观性原则，数据偏见的盛行有可能在公共部门的日常实践中嵌入和放大歧视。”</p>
<p class="translated">“这项审查发现，政府在开放方面失败了，”它继续说道，“公共部门组织在使用人工智能方面不够透明，而且很难发现政府目前在哪里使用机器学习。”</p>
<p class="translated">在<a href="https://web.archive.org/web/20230306045856/https://techcrunch.com/2018/11/16/un-warns-over-human-rights-impact-of-a-digital-welfare-state/"> 2018 </a>中，联合国极端贫困和人权问题特别报告员对英国急于应用数字技术和数据工具来大规模地从社会上重新设计公共服务的提供表示担忧——<a href="https://web.archive.org/web/20230306045856/https://www.ohchr.org/EN/NewsEvents/Pages/DisplayNews.aspx?NewsID=23881&amp;LangID=E">当时警告说，数字福利国家对弱势人群的影响将是“巨大的”，并呼吁加强法律和执行以权利为基础的法律框架，以确保人工智能等技术在公共服务提供中的使用不会最终伤害到人们。</a></p>
<p class="translated">根据该委员会的评估，“现在判断公共部门机构是否成功地坚持了问责制还为时过早。”</p>
<p class="translated">议员们还表示，“对‘黑箱’人工智能的担忧……可能被夸大了”——而是将“可解释的人工智能”称为“公共部门的现实目标”。</p>
<p class="translated">在客观性方面，他们写道，数据偏差是“一个值得严重关注的问题，需要进一步的工作来衡量和减轻偏差的影响。”</p>
<p class="translated">根据该委员会的评估，人工智能在英国公共部门的使用现阶段仍然有限，医疗保健和警务部门目前拥有最发达的人工智能项目——例如，该技术被用于识别眼病和预测再次犯罪率。</p>
<p class="translated">“委员会在公共部门看到的大多数人工智能例子仍在开发中或处于概念验证阶段，”该委员会写道，并进一步指出，司法部门，运输部和内政部正在“研究人工智能如何提高服务交付的效率。”</p>
<p class="translated">它还听到了当地政府正在努力将人工智能系统纳入教育、福利和社会护理等领域的证据——注意到汉普郡议会在接受社会护理的成年人家中测试使用亚马逊 Echo 智能扬声器作为一种工具来弥合专业护理人员来访之间的差距的例子，并指出《卫报》的一篇文章报道说，三分之一的英国议会使用算法系统来做出福利决定。</p>
<p class="translated">但该委员会表示，在他们所描述的英国公共部门“广泛而成功地”采用人工智能系统方面，仍然存在“重大”障碍。</p>
<p class="translated">“公共政策专家经常告诉这篇评论，获得正确数量的干净、高质量的数据是有限的，试验系统尚未准备好投入运行，”它写道。“我们的印象是，许多公共机构仍专注于服务的早期数字化，而不是更雄心勃勃的人工智能项目。”</p>
<p class="translated">该报告还表明，缺乏明确的标准框架意味着许多组织可能对部署人工智能还没有信心。</p>
<p class="translated">“虽然标准和监管经常被视为创新的障碍，但该委员会认为，通过在公职人员和服务用户之间建立对新技术的信任，围绕人工智能实施明确的道德标准可能会加速而不是推迟采用，”它建议道。</p>
<p class="translated">该报告提出的 15 项建议之一是呼吁为公共部门使用人工智能制定明确的法律基础。该委员会写道:“所有公共部门组织都应该在将人工智能用于公共服务之前，发布一份声明，说明它们对人工智能的使用如何符合相关法律法规。”</p>
<p class="translated">另一项建议是澄清哪些道德原则和指导适用于公共部门对人工智能的使用——委员会注意到有三套原则可以适用于公共部门，这正在产生混乱。</p>
<p class="translated">“公众需要理解管理公共部门人工智能使用的高级道德原则。政府应确定、认可和推广这些原则，并概述目前使用的三套原则的目的、适用范围和各自的地位。</p>
<p class="translated">它还希望平等和人权委员会制定关于数据偏见和反歧视的指南，以确保公共部门机构对人工智能的使用符合英国 2010 年平等法案。</p>
<p class="translated">该委员会并不建议成立一个新的监管机构来监督人工智能——但呼吁现有的监督机构迅速采取行动，以跟上自动化驱动的变化步伐。</p>
<p class="translated">它还倡导建立一个监管保证机构，以确定监管领域的差距，并就与人工智能相关的问题向个别监管机构和政府提供建议——支持政府让 2017 年宣布成立的数据伦理与创新中心(CDEI)发挥这一作用的意图。CDEI 最近的一份报告建议对平台巨头如何使用广告定位和内容个性化进行更严格的控制。)</p>
<p class="translated">另一项建议是围绕采购，该委员会敦促政府利用其购买力设定要求，“确保为公共部门开发人工智能解决方案的私营公司适当地解决公共标准。”</p>
<p class="translated">“要实现这一点，应确保在采购过程的早期就考虑到道德标准的规定，并将其明确写入标书和合同安排，”报告建议道。</p>
<p class="translated">影子数字部长 Chi Onwurah MP 在一份声明中回应了这份报告，指责政府“盲目驾驶，无法控制人工智能驾驶座位上的人。”</p>
<p class="translated">“这份严肃的报告可悲地证实了我们所知道的情况——当涉及到在公共部门使用人工智能时，保守党政府在公开性和透明度方面失败了，”她说。“政府在盲目驾驶，无法控制谁坐在人工智能驾驶座上。政府迫切需要在潜在的意外后果失控之前控制住局面。</p>
<p class="translated">“去年，我在议会提出，在没有引入进一步监管的情况下，政府不应该在决策过程中接受更多的人工智能算法。我将继续推动政府进一步分享关于人工智能目前在各级政府如何使用的信息。正如这份报告所显示的，我们迫切需要切实可行的指导和可执行的监管。是行动的时候了。”</p>
			</div>

			</div>    
</body>
</html>