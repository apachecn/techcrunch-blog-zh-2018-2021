<html>
<head>
<title>DARPA snags Intel to lead its machine learning security tech</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">DARPA 困住英特尔，引领其机器学习安全技术</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2020/04/09/intel-darpa-machine-learning/">https://web.archive.org/web/https://techcrunch.com/2020/04/09/intel-darpa-machine-learning/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">芯片制造商英特尔被选中领导由美国军方研究部门 DARPA 领导的一项新计划，该计划旨在改善网络防御，防止对机器学习模型的欺骗攻击。</p>
<p class="translated">机器学习是一种人工智能，它允许系统随着时间的推移利用新的数据和经验进行改进。今天，它最常见的一个用例是对象识别，如拍摄照片并描述照片中的内容。例如，这可以帮助视力受损的人在看不到照片的情况下知道照片中有什么，但它也可以被其他计算机使用，如自动驾驶汽车，以识别道路上有什么。</p>
<p class="translated">但是，欺骗攻击虽然罕见，但可以干扰机器学习算法。在无人驾驶汽车的情况下，真实世界物体的细微变化可能会带来灾难性的后果。</p>
<p class="translated">就在几周前，McAfee 的研究人员通过在限速标志上添加一条两英寸长的胶带，骗过一辆特斯拉汽车，使其加速到比预定速度高出 50 英里。这项研究是操纵设备的机器学习算法的首批例子之一。</p>
<p class="translated">这就是 DARPA 希望发挥作用的地方。该研究机构今年早些时候<a href="https://web.archive.org/web/20230315095320/https://www.darpa.mil/news-events/2019-02-06">表示</a>正在开发一个名为 GARD 的项目，即保证人工智能对欺骗的鲁棒性。现有的针对机器学习攻击的缓解措施通常是基于规则的和预定义的，但 DARPA 希望它可以将 GARD 开发成一个系统，该系统将具有更广泛的防御能力，以应对许多不同类型的攻击。</p>
<p class="translated">英特尔公司今天表示，它将与佐治亚理工学院一起作为这项为期四年的项目的主承包商。</p>
<p class="translated">领导英特尔 GARD 团队的英特尔实验室首席工程师杰森·马丁(Jason Martin)表示，芯片制造商和佐治亚理工学院将合作“增强物体检测，并提高人工智能和机器学习应对恶意攻击的能力。”</p>
<p class="translated">在该计划的第一阶段，英特尔表示，其重点是利用静态图像和视频的空间、时间和语义一致性来增强其对象检测技术。</p>
<p class="translated">DARPA 表示，GARD 可以用于许多场合，比如生物学。</p>
<p class="translated">DARPA 信息创新办公室的项目经理哈瓦·西格尔曼(Hava Siegelmann)博士说:“我们希望建立的广泛的基于场景的防御可以在免疫系统中看到，例如，免疫系统可以识别攻击，赢得并记住攻击，以便在未来的战斗中做出更有效的反应。”。</p>
<p class="translated">“我们必须确保机器学习是安全的，不会被欺骗，”西格尔曼说。</p>

			</div>

			</div>    
</body>
</html>