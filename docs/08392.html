<html>
<head>
<title>OpenAI's new experiments in music generation create an uncanny valley Elvis • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">OpenAI 在音乐生成方面的新实验创造了一个恐怖谷猫王 TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2020/04/30/openais-new-experiments-in-music-generation-create-an-uncanny-valley-elvis/">https://web.archive.org/web/https://techcrunch.com/2020/04/30/openais-new-experiments-in-music-generation-create-an-uncanny-valley-elvis/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">人工智能生成的音乐是一个迷人的新领域，资金雄厚的研究机构 OpenAI 在这方面达到了新的高度，创造了猫王、2Pac 和其他风格的歌曲。结果是令人信服的，但正好落在令人不安的“恐怖谷”的音频中，听起来很像良好的，但喝醉了，通过药物的薄雾听到的卡拉 ok。</p>
<p class="translated">该组织的新音乐生成系统 Jukebox 在今天发表的一篇博文和论文中有详细介绍。OpenAI 几乎在一年前与<a href="https://web.archive.org/web/20230127180800/https://techcrunch.com/2019/04/25/musenet-generates-original-songs-in-seconds-from-bollywood-to-bach-or-both/"> MuseNet </a>一起制作了一些有趣的作品，这是一个机器学习系统，它已经摄取了大量基于 MIDI 的音乐，能够混合和匹配流派和乐器。</p>

<p class="translated">但 MIDI 是一种比现场乐器最终录制的音乐更简单的格式，因为前者由离散的音符和按键组成，而不是复杂的和声和声音。</p>
<p class="translated">如果你想让一个人工智能检查一首古典钢琴曲的结构，时间和按键可能只包含几千条信息。录制的音频要密集得多，每秒<em>秒</em>(通常)有 44100 个样本。</p>
<p class="translated">机器学习系统通过查看最近的单词或声音并预测接下来的几个单词或声音来学习和模仿乐器和声音等事物，但它们通常对几十或一百条数据进行操作——例如，最后 30 个单词或音符预测接下来的 30 个会是什么。那么，计算机如何才能知道一首歌曲中的一小部分波形 10 秒钟和 440，000 个样本与 90 秒钟和 400 万个样本相比呢？</p>
<p class="translated">OpenAI 的解决方案是将歌曲分解成更容易理解的部分——不完全是调与和弦，而是类似的东西，从 2048 个选项的“词汇表”中选择歌曲的 1/128 秒的机器可接受的摘要。老实说，很难进行类比，因为这与人类记忆或理解事物的方式非常不同——就我们对<em>和</em>的理解而言。</p>
<p/><div id="attachment_1982341" class="wp-caption aligncenter"><a href="https://web.archive.org/web/20230127180800/https://techcrunch.com/wp-content/uploads/2020/04/sample-sample.png"><img aria-describedby="caption-attachment-1982341" decoding="async" loading="lazy" class="wp-image-1982341 size-full" src="../Images/acaa58a966915f34ce400f2d45834b8a.png" alt="" srcset="https://web.archive.org/web/20230127180800im_/https://techcrunch.com/wp-content/uploads/2020/04/sample-sample.png 854w, https://web.archive.org/web/20230127180800im_/https://techcrunch.com/wp-content/uploads/2020/04/sample-sample.png?resize=150,68 150w, https://web.archive.org/web/20230127180800im_/https://techcrunch.com/wp-content/uploads/2020/04/sample-sample.png?resize=300,137 300w, https://web.archive.org/web/20230127180800im_/https://techcrunch.com/wp-content/uploads/2020/04/sample-sample.png?resize=768,350 768w, https://web.archive.org/web/20230127180800im_/https://techcrunch.com/wp-content/uploads/2020/04/sample-sample.png?resize=680,310 680w, https://web.archive.org/web/20230127180800im_/https://techcrunch.com/wp-content/uploads/2020/04/sample-sample.png?resize=50,23 50w" sizes="(max-width: 854px) 100vw, 854px" data-original-src="https://web.archive.org/web/20230127180800im_/https://techcrunch.com/wp-content/uploads/2020/04/sample-sample.png"/></a><p id="caption-attachment-1982341" class="wp-caption-text translated">它实际上并不使用颜色样本，这只是为了表明它正在将波形分解成片段。</p></div>
<p class="translated">最终结果是，人工智能代理有一种可靠的方法来将一首歌分解成可消化的片段，这些片段足够大，不会有太多需要跟踪，但又足够小，可以可靠地重建歌曲的声音。这个过程比听起来要复杂得多；可靠地将一首歌分解成一系列“词”，然后根据它们重建它是新研究的核心，但技术细节<a href="https://web.archive.org/web/20230127180800/https://cdn.openai.com/papers/jukebox.pdf">我会让 OpenAI 团队在他们的论文</a>中解释。</p>
<p class="translated">该系统还必须学习如何解析歌曲中的歌词，这和这个领域的大多数事情一样，比听起来要复杂。我们记忆和使用声音模式的能力部分是天生的，部分是后天习得的，我们倾向于想当然地认为它是多么强大。计算机没有这种能力，必须学会如何从混音中挑选出一个声音，理解它在说什么，并将其与歌词匹配，歌词只不过是一系列单词，没有音调、速度和所有其他信息。然而，OpenAI 系统在这方面做得令人满意。</p>
<p class="translated">Jukebox 能够完成各种各样的音乐任务，虽然结果不是你可能所说的唱歌材料，但必须记住，现在很少有像这样的作品，能够从头开始重建一首像目标艺术家一样可识别的歌曲。经过 120 万首歌曲的训练，该系统最终拥有一种多方面的能力来完成这些任务:本质上，根据给定的歌词和它从该艺术家吸收他人的风格来即兴创作一首歌曲。</p>
<p class="translated">因此，鉴于它对艾拉·费兹杰拉唱歌的方式以及乐器通常为她伴奏的方式的了解，它可以用一种听起来像她的方式演唱“最后的爱”,但肯定不是科尔·波特想要的。(这些例子以及更多例子的样本包含在 OpenAI 博客文章的<a href="https://web.archive.org/web/20230127180800/https://openai.com/blog/jukebox/">顶部附近。)</a></p>
<p class="translated">Jukebox 还可以以另一种风格演唱完全原创的歌词，就像这首真正奇怪的猫王歌曲“有丝分裂”，由另一个人工智能语言模型编写:</p>
<p class="embed breakout"/>
<p class="translated">如果你没听清楚:</p>
<blockquote><p class="translated">我们从尘土中卑微地起步；<br/>从污垢到脂质到细胞再到心脏。随着时间的推移，我们终于清醒了。在友好的帮助下，我们从尘埃中走来；<br/>从污垢到试管到芯片到试管架。我们终于带着灵魂醒来了。</p></blockquote>
<p class="translated">是的，这是“猫王”用细胞分裂来比喻生命，就像一个人工智能想象的那样。我们生活在一个多么美好的世界。</p>
<p class="translated">最后，还有“完成”任务，Jukebox 从一首歌曲的前 12 秒学习(除了从其库学习的基础学习之外),并使用它以类似的风格生成其余部分。从原始到人工智能生成的转换听起来有点像以太刚刚踢开。</p>
<p class="translated">虽然 MuseNet 由于复杂性较低，可以或多或少地实时播放，但 Jukebox 是计算密集型的，需要几个小时才能生成一秒钟的音乐。“我们与最初的 10 名来自不同流派的音乐家分享了 Jukebox 这些音乐家没有发现它可以立即应用到他们的创作过程中，”作者冷淡地指出。尽管如此，这仍然是有趣而迷人的研究，鉴于目前的节奏，我们可以期待明年 4 月 OpenAI music 工作的进一步改进版本。</p>
			</div>

			</div>    
</body>
</html>