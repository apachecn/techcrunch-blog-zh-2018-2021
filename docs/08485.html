<html>
<head>
<title>Twitter runs a test prompting users to revise 'harmful' replies • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Twitter 进行了一项测试，提示用户修改“有害”回复 TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2020/05/05/twitter-harmful-replies-prompt-harassment-test-feature/">https://web.archive.org/web/https://techcrunch.com/2020/05/05/twitter-harmful-replies-prompt-harassment-test-feature/</a></blockquote><div><header class="article__header ">
	<p class="article__title-wrapper">
						</p><h1 class="article__title translated">Twitter 进行了一项测试，提示用户修改“有害的”回复</h1>
		

			
	
			
	</header>

			<div class="article-content">
				<p id="speakable-summary" class="translated">在应对其平台上猖獗骚扰的最新努力中，Twitter 将考虑在用户发推特之前给他们第二次机会。在该公司正在测试的一项新功能中，使用“有害”语言的用户将会看到一个提示，建议他们在发布回复之前进行自我编辑。</p>

<p class="translated">这里的框架有点不真诚 Twitter 上的骚扰肯定不只是发生在原本善意的个人的“一时冲动”——但任何可以减少平台毒性的东西可能都比我们现在得到的要好。</p>
<p class="translated">在回应 TechCrunch 的问题时，Twitter 证实，测试功能目前仅限于回复。Twitter 还解释说，其系统将根据其他已报道的推文中使用的语言类型来检测有害语言。</p>
<p class="translated">去年在 F8，Instagram 为其用户推出了一项类似的测试，在他们发布潜在的冒犯性评论之前，会“提醒”他们一个警告。去年 12 月，该公司提供了其努力的最新进展。该公司在<a href="https://web.archive.org/web/20221007040804/https://about.fb.com/news/2019/12/our-progress-on-leading-the-fight-against-online-bullying/">的博客帖子</a>中写道:“结果令人鼓舞，我们发现，如果有机会，这种类型的轻推可以鼓励人们重新考虑他们的话。”。</p>
<p class="translated">这种事情现在尤其相关，因为公司在相对骨干的工作人员的情况下在他们的巨大平台上进行节制。所有主要的社交网络都宣布越来越依赖人工智能检测，因为疫情让技术人员远离办公室。在脸书的案例中，内容主持人是他们<a href="https://web.archive.org/web/20221007040804/https://techcrunch.com/2020/04/16/facebook-content-moderators-wfh-when-will-facebook-employees-return/">希望首先带回的员工</a>。</p><p class="piano-inline-promo"/>

			</div>

			</div>    
</body>
</html>