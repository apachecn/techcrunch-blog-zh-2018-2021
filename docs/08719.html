<html>
<head>
<title>Microsoft launches new tools for building fairer machine learning models • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">微软推出新工具构建更公平的机器学习模型 TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2020/05/19/microsoft-launches-new-tools-for-building-more-responsible-machine-learning-models/">https://web.archive.org/web/https://techcrunch.com/2020/05/19/microsoft-launches-new-tools-for-building-more-responsible-machine-learning-models/</a></blockquote><div><header class="article__header ">
	<p class="article__title-wrapper">
						</p><h1 class="article__title translated">微软推出新工具构建更公平的机器学习模型</h1>
		

			
	
			
	</header>

			<div class="article-content">
				<p id="speakable-summary" class="translated">在其 Build 开发者大会上，微软今天非常强调机器学习。但除了大量的新工具和功能，该公司还强调了其在建立更负责任和更公平的人工智能系统方面的工作——包括 Azure 云和微软的开源工具包。</p>
<p class="translated">这些工具包括不同隐私的新工具和确保模型在不同人群中良好工作的系统，以及使企业能够在满足严格监管要求的同时充分利用数据的新工具。</p>
<p class="translated">微软在今天的声明中指出，随着开发人员越来越多地学习如何构建人工智能模型，他们经常不得不问自己，这些系统是否“易于解释”，以及它们是否“遵守非歧视和隐私法规”。但要做到这一点，他们需要工具来帮助他们更好地解释他们的模型结果。其中之一是微软不久前推出的<a href="https://web.archive.org/web/20221209170112/https://interpret.ml/"> interpretML </a>，还有<a href="https://web.archive.org/web/20221209170112/https://fairlearn.github.io/"> Fairlearn toolkit </a>，可以用来评估 ML 模型的公平性，目前可以作为开源工具使用，下个月将内置到 Azure Machine Learning 中。</p>
<p class="translated">至于差分隐私，这使得在保护私人信息的同时从私人数据中获得洞察力成为可能，微软今天宣布了一个新的开源工具包 WhiteNoise，它在 GitHub 上和通过 Azure 机器学习都可以使用。WhiteNoise 是微软和哈佛定量社会科学研究所合作的成果。</p>
<p class="translated"><a href="https://web.archive.org/web/20221209170112/https://techcrunch.com/tag/microsoft-build-2020/"> <img decoding="async" src="../Images/a61c24aa1ca312bc400b4ecc9b58daf9.png" data-original-src="https://web.archive.org/web/20221209170112im_/https://techcrunch.com/wp-content/uploads/2020/05/msft-build-2020-banner.jpg"/> </a></p>
			</div>

			</div>    
</body>
</html>