<html>
<head>
<title>Snapchat boosts its AR platform with voice search, Local Lenses and SnapML </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Snapchat通过语音搜索、本地镜头和SnapML提升其AR平台</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2020/06/11/snapchat-boosts-its-ar-platform-with-voice-search-local-lenses-and-snapml/">https://web.archive.org/web/https://techcrunch.com/2020/06/11/snapchat-boosts-its-ar-platform-with-voice-search-local-lenses-and-snapml/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">Snapchat的增强现实梦想可能开始看起来更加现实了。</p>
<p class="translated">该公司每年都在微妙地改进其AR驱动的镜头，改进技术细节，并加强其开发平台。该公司表示，结果是今天有超过1.7亿人——超过Snap每日活跃用户的四分之三——每天都在使用该应用的增强现实功能。两年前，Snap分享了创作者在平台上设计了超10万个镜头；现在Snap说已经制造了超过100万个镜头。</p>
<p class="translated">愚蠢的过滤器将用户带到了应用程序上，该公司正在围绕增强现实慢慢建立一个更加互联互通的平台，这看起来越来越有前途。</p>
<p class="translated">今天，在Snap的年度开发者活动上，该公司宣布了一系列更新，包括Lens voice search，Lens Studio的自带机器学习模型更新，以及一个特定于地理的AR系统，该系统将公共快照转化为空间数据，该公司可以使用这些数据三维绘制巨大的物理空间。</p>
<p class="translated"><img decoding="async" class="alignnone size-full wp-image-2000978" src="../Images/f1fd90a254c9712b3f5c600586c9c15f.png" alt="" srcset="https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_Scan_Voice.png 1920w, https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_Scan_Voice.png?resize=150,84 150w, https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_Scan_Voice.png?resize=300,169 300w, https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_Scan_Voice.png?resize=768,432 768w, https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_Scan_Voice.png?resize=680,383 680w, https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_Scan_Voice.png?resize=1536,864 1536w, https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_Scan_Voice.png?resize=1200,675 1200w, https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_Scan_Voice.png?resize=50,28 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_Scan_Voice.png"/></p>
<p class="translated"><strong>一款用于AR的Alexa】</strong></p>
<p class="translated">Snapchat的镜头转盘足以在只有几十个镜头的时候在滤镜之间滑动，但有了100万个镜头并且还在增加，很明显Snapchat的ar雄心受到了可发现性问题的影响。</p><p class="piano-inline-promo"/>
<p class="translated">Snap正准备推出一种通过语音对镜头进行分类的新方法，如果他们能够实现这一点，该公司将有一条清晰的路径，从仅供娱乐的ar过渡到基于实用的平台。在目前的格式下，该应用的新语音搜索将允许Snapchat用户要求该应用帮助它筛选过滤器，使他们能够做一些独特的事情。</p>
<p class="translated">虽然很容易看出如果用户团结在它周围，这样的功能会走向何方，但新闻发布会前强调的例子并没有确切表明Snapchat希望这一功能一开始就像一个数字助理:</p>
<ul>
<li class="translated">“嘿Snapchat，把我的头发染成粉红色”</li>
<li class="translated">“嘿Snapchat，给我一个拥抱！</li>
<li class="translated">“嘿Snapchat，带我去月球”</li>
</ul>
<p class="translated">当Lenses的功能无处不在时，看看用户是否会在早期使用这一功能将是一件有趣的事情，但仅仅将这一基础设施构建到应用程序中似乎就很强大，特别是当你看到该公司与亚马逊的视觉搜索和Shazam扫描功能中的音频搜索合作时。不难想象，让应用程序让你试用某个特定公司的化妆品，或者让它向你展示一台55英寸的电视挂在你的墙上会是什么样子。</p>
<p class="translated"><img decoding="async" loading="lazy" class="alignnone wp-image-2000982" src="../Images/8d60512bb8603f0ae86710b7e5cb43d4.png" alt="" data-original-src="https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_Scan_Dog.png"/></p>
<p class="translated">该公司宣布了其视觉搜索的新合作伙伴关系，与PlantSnap合作，帮助Snapchat用户识别植物和树木，狗扫描仪，让Snap用户将相机对准狗并确定其品种，今年晚些时候与优香合作，在你扫描商品标签后，帮助给出食物的营养评级。</p>
<p class="translated">“今天，增强现实正在改变我们与朋友交谈的方式，”Snap联合创始人兼首席技术官鲍比·墨菲在新闻发布会上说。“但在未来，我们将利用它以全新的方式看待世界。”</p>
<p class="translated"><img decoding="async" loading="lazy" class="alignnone size-full wp-image-2000976" src="../Images/a0e9e76018c0c6b6b70dbe5dd4ceaef3.png" alt="" srcset="https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_SnapML_Prisma.png 1920w, https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_SnapML_Prisma.png?resize=150,84 150w, https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_SnapML_Prisma.png?resize=300,169 300w, https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_SnapML_Prisma.png?resize=768,432 768w, https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_SnapML_Prisma.png?resize=680,383 680w, https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_SnapML_Prisma.png?resize=1536,864 1536w, https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_SnapML_Prisma.png?resize=1200,675 1200w, https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_SnapML_Prisma.png?resize=50,28 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_SnapML_Prisma.png"/></p>
<p class="translated"><strong> BYO【艾】</strong></p>
<p class="translated">Snap希望开发人员将自己的神经网络模型带到他们的平台上，以实现更具创造性和机器学习密集型的镜片。SnapML允许用户引入经过训练的模型，让用户增强他们的环境，创建视觉过滤器，以更复杂的方式转换场景。</p>
<p class="translated">创作者上传到Lens Studio的数据集将允许他们的镜头用一套新的眼睛来看，并搜索出新的对象。Snap正在与AR初创公司<a href="https://web.archive.org/web/20230403120532/https://wanna.by/"> Wannaby </a>合作，让开发人员获得他们的足部跟踪技术，以实现允许用户虚拟试穿运动鞋的镜片。与Prisma 的另一项合作允许镜头相机以熟悉的艺术风格过滤世界。</p>
<p class="translated">Snap希望通过将机器学习社区和创意社区结合起来，用户将能够获得全新的东西。“我们希望看到一种我们从未见过的全新类型的镜头，”Snap AR高管Eitan Pilipski告诉TechCrunch。</p>

<p class="translated"><img decoding="async" loading="lazy" class="alignnone size-full wp-image-2000974" src="../Images/51fec93d8f3d09a1b3e0ea0817e9488e.png" alt="" srcset="https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_Local-Lenses-Yellow-Frame.png 1920w, https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_Local-Lenses-Yellow-Frame.png?resize=150,84 150w, https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_Local-Lenses-Yellow-Frame.png?resize=300,169 300w, https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_Local-Lenses-Yellow-Frame.png?resize=768,432 768w, https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_Local-Lenses-Yellow-Frame.png?resize=680,383 680w, https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_Local-Lenses-Yellow-Frame.png?resize=1536,864 1536w, https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_Local-Lenses-Yellow-Frame.png?resize=1200,675 1200w, https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_Local-Lenses-Yellow-Frame.png?resize=50,28 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230403120532im_/https://techcrunch.com/wp-content/uploads/2020/06/Lens_Local-Lenses-Yellow-Frame.png"/></p>
<p class="translated"><strong> Snapchat开始绘制世界地图</strong></p>
<p class="translated">Snap去年在ar领域的一项重大宣布是一项名为<a href="https://web.archive.org/web/20230403120532/https://lensstudio.snapchat.com/templates/landmarker/guide/"> Landmarkers </a>的功能，该功能允许开发人员创建更复杂的镜头，利用巴黎艾菲尔铁塔或纽约熨斗大厦等受欢迎的大型地标建筑的几何模型来制作与现实世界互动的地理特定镜头。</p>
<p class="translated">这项技术相对容易实现，如果仅仅是因为他们选择的结构无处不在，而且他们外部的3D文件很容易获得。该公司的下一个AR努力有点更雄心勃勃。名为Local Lenses的新功能将允许Snapchat开发者创建特定于地理位置的镜头，与更广泛的物理位置样本进行交互。</p>
<p class="translated">墨菲说:“我们更进一步，通过在更大的区域实现共享和持久的增强现实，这样你就可以与你的朋友同时在整个城市街区体验增强现实。”</p>
<p class="translated">Snapchat如何首先获得所有这些3D数据？他们正在分析用户分享到该公司公共Our Story feed的公共快照，提取照片中建筑物和结构的视觉数据，并使用它们来创建更准确的3D位置地图。</p>
<p class="translated">对增强现实感兴趣的公司越来越多地竞相收集3D数据。上个月，Pokémon GO制造商Niantic宣布，他们将开始在选择加入的基础上收集用户的3D数据。</p>

			</div>

			</div>    
</body>
</html>