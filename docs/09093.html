<html>
<head>
<title>Facebook's 'Deepfake Detection Challenge' yields promising early results </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">脸书的“深度伪造检测挑战”产生了有希望的早期结果</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2020/06/12/facebooks-deepfake-detection-challenge-yields-promising-early-results/">https://web.archive.org/web/https://techcrunch.com/2020/06/12/facebooks-deepfake-detection-challenge-yields-promising-early-results/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">被称为deepfakes的数字面部交换视频不会去任何地方，但如果平台希望能够关注它们，他们需要首先找到它们。这样做是脸书去年发起的“深度造假检测挑战”的目标。经过几个月的竞争，获胜者已经出现了，他们…比猜测要好。这是一个开始！</p>
<p class="translated">自从最近一两年出现以来，deepfakes已经从为人工智能会议创建的小众玩具发展到任何人都可以用来创建令人信服的公众人物假视频的容易下载的软件。</p>
<p class="translated">“我已经下载了deepfake生成器，你只需双击它们，它们就可以在Windows系统上运行——没有任何东西可以用来检测，”脸书首席技术官迈克·斯科洛普夫在接受媒体采访时说。</p>
<p class="translated">这可能是第一个恶意行为者试图利用以这种方式生成的候选人虚假视频来影响政治对话的选举年。鉴于脸书在公众舆论中岌岌可危的地位，在这件事面前站出来非常符合他们的利益。</p>

<p class="translated">比赛始于去年，一个全新的deepfake镜头数据库首次亮相。在那之前，研究人员几乎没有什么可玩的——少数中等规模的操纵视频集，但没有像用于评估和改进计算机视觉算法等事物的大规模数据集那样的东西。</p>
<p class="translated">脸书支付了费用，让3500名演员录制了数千个视频，每个视频都是原版和伪造的。还对其他一些“干扰物”进行了修改，以迫使任何希望识别假货的算法关注重要的部分:显然是面部。</p>
<p class="translated">来自各地的研究人员参与其中，提交了数千个模型，试图判断一个视频是否是深度伪造的。下面是六个视频，其中三个是deepfakes。你能分辨出哪个是哪个吗？(答案在帖子底部。)</p>
<p/><div id="attachment_2001730" class="wp-caption aligncenter"><a href="https://web.archive.org/web/20230315095314/https://techcrunch.com/wp-content/uploads/2020/06/deepfake-detect.gif"><img aria-describedby="caption-attachment-2001730" decoding="async" class="wp-image-2001730 size-full" src="../Images/6a04336069395fbc1c7058e9da30cffd.png" alt="" data-original-src="https://web.archive.org/web/20230315095314im_/https://techcrunch.com/wp-content/uploads/2020/06/deepfake-detect.gif"/></a><p id="caption-attachment-2001730" class="wp-caption-text translated">图片来源:脸书</p></div>
<p class="translated">起初，这些算法比运气好不了多少。但经过多次迭代和一些巧妙的调整，他们在识别假货方面的准确率达到了80%以上。不幸的是，当部署在研究人员没有提供的保留视频集上时，最高准确率约为65%。</p>
<p class="translated">这比抛硬币要好，但差不了多少。幸运的是，这是意料之中的事，结果也很有希望。在人工智能研究中，最难的一步是从无到有——之后就是越来越好。但是发现这个问题是否可以被人工智能解决是一个很大的进步。竞争似乎表明它可以。</p>
<p/><div id="attachment_2001781" class="wp-caption aligncenter"><a href="https://web.archive.org/web/20230315095314/https://techcrunch.com/wp-content/uploads/2020/06/deepfake-purturb.jpg"><img aria-describedby="caption-attachment-2001781" decoding="async" loading="lazy" class="wp-image-2001781 size-full" src="../Images/606176a0a97ddaa6a15d5cd8c65c51d1.png" alt="" srcset="https://web.archive.org/web/20230315095314im_/https://techcrunch.com/wp-content/uploads/2020/06/deepfake-purturb.jpg 2500w, https://web.archive.org/web/20230315095314im_/https://techcrunch.com/wp-content/uploads/2020/06/deepfake-purturb.jpg?resize=150,84 150w, https://web.archive.org/web/20230315095314im_/https://techcrunch.com/wp-content/uploads/2020/06/deepfake-purturb.jpg?resize=300,169 300w, https://web.archive.org/web/20230315095314im_/https://techcrunch.com/wp-content/uploads/2020/06/deepfake-purturb.jpg?resize=768,432 768w, https://web.archive.org/web/20230315095314im_/https://techcrunch.com/wp-content/uploads/2020/06/deepfake-purturb.jpg?resize=680,382 680w, https://web.archive.org/web/20230315095314im_/https://techcrunch.com/wp-content/uploads/2020/06/deepfake-purturb.jpg?resize=1536,864 1536w, https://web.archive.org/web/20230315095314im_/https://techcrunch.com/wp-content/uploads/2020/06/deepfake-purturb.jpg?resize=2048,1152 2048w, https://web.archive.org/web/20230315095314im_/https://techcrunch.com/wp-content/uploads/2020/06/deepfake-purturb.jpg?resize=1200,675 1200w, https://web.archive.org/web/20230315095314im_/https://techcrunch.com/wp-content/uploads/2020/06/deepfake-purturb.jpg?resize=50,28 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230315095314im_/https://techcrunch.com/wp-content/uploads/2020/06/deepfake-purturb.jpg"/></a><p id="caption-attachment-2001781" class="wp-caption-text translated">源视频和多个干扰项版本的示例。<strong>图片来源:</strong>脸书</p></div>
<p class="translated">一个重要的注意事项是，脸书创建的数据集被故意做得比其他人更具代表性和包容性，而不仅仅是更大。毕竟，人工智能只取决于输入其中的数据，人工智能中发现的偏差通常可以追溯到数据集中的偏差。</p>
<p class="translated">“如果你的训练集在真人的外表上没有适当的差异，那么你的模型就不会对此有代表性的理解。我认为我们煞费苦心，以确保这个数据集具有相当的代表性，”Schroepfer说。</p>
<p class="translated">我问是否有任何群体或类型的面孔或情况不太可能被识别为假或真，但Schroepfer不确定。在回答我关于数据集中表示的问题时，该团队的声明如下:</p>
<blockquote><p class="translated">在创建DFDC数据集时，我们考虑了许多因素，重要的是我们要有几个维度的代表性，包括自我认同的年龄、性别和种族。检测技术需要为每个人服务，因此我们的数据必须能够代表这一挑战。</p></blockquote>
<p class="translated">获胜的模型将被开源，以激励该行业的其他人采取行动，但脸书正在开发自己的deepfake检测产品，Schropfer表示不会共享。这个问题的对抗性本质——基本上，坏人从好人的做法中学习并调整他们的方法——意味着告诉每个人正在采取什么措施来防止深度欺诈可能会适得其反。</p>
<p class="translated">(deepfake检测图像的答案:1、4、6是真实的；2，3，5是deepfakes。)</p>
<p> </p><p embedded-video-placeholder="5cbb8b49791cad57f73a4918" post-id="1815139"/> 
			</div>

			</div>    
</body>
</html>