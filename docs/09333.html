<html>
<head>
<title>Privacy not a blocker for 'meaningful' research access to platform data, says report • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">报告 TechCrunch 称，隐私不是“有意义的”研究访问平台数据的障碍</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2020/06/25/privacy-not-a-blocker-for-meaningful-research-access-to-platform-data-says-report/">https://web.archive.org/web/https://techcrunch.com/2020/06/25/privacy-not-a-blocker-for-meaningful-research-access-to-platform-data-says-report/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">欧洲立法者正着眼于今年年底起草的 T2 数字服务法案(DSA)中对互联网平台的约束性透明度要求。但如何创建治理结构，为监管者和研究人员提供有意义的数据访问，从而让平台对它们放大的内容负责，这是一个复杂的问题。</p>
<p class="translated">至少可以说，平台自己向外界开放数据宝库的努力受到了阻碍。早在 2018 年，脸书宣布了<a href="https://web.archive.org/web/20221206162526/https://techcrunch.com/2018/07/11/facebook-independent-research-commission-social-science-one-will-share-a-petabyte-of-user-data/">社会科学一号计划</a>，称它将为一组精选的学者提供大约 1pb 的共享数据和元数据。但是研究人员花了将近两年时间才获得任何数据。</p>
<p class="translated">“这是我一生中遇到的最令人沮丧的事情，”今年早些时候，一位参与其中的研究人员告诉<a href="https://web.archive.org/web/20221206162526/https://www.protocol.com/facebook-data-sharing-researchers"> Protocol </a>，此前他花了大约 20 个月的时间与脸书就它将发布的内容进行谈判。</p>
<p class="translated">脸书的政治广告档案 API 也有同样沮丧的研究人员。Mozilla 去年指责这家科技巨头淡化透明度，称“脸书让我们无法获得他们平台上所有广告的完整图片(这与他们声称正在做的事情完全相反)”。</p>
<p class="translated"><span>与此同时，在美国联邦贸易委员会(FTC)进行干预后，脸书提到了欧洲数据保护法规和附加于其业务的隐私要求，以证明围绕数据访问取得的艰苦进展。但是批评家认为这只是反对透明度和问责制的一个愤世嫉俗的挡箭牌。</span> <span>加当然 n </span> <span>这些规定中有一条一开始就阻止了脸书<a href="https://web.archive.org/web/20221206162526/https://techcrunch.com/2018/04/10/a-brief-history-of-facebooks-privacy-hostility-ahead-of-zuckerbergs-testimony/">抢人数据</a>。</span></p>
<p class="translated">1 月 1 日，欧洲领先的数据保护监管机构写了一份关于数据保护和研究的初步意见，对这种屏蔽提出了警告。</p>
<p class="translated">EDPS·沃伊切赫·维沃罗夫斯基写道:“数据保护义务不应该被滥用，成为强大的参与者逃避透明和问责的手段。”。“因此，在伦理治理框架内运作的研究人员应该能够访问必要的 API 和其他数据，具有有效的法律基础，并遵循相称性原则和适当的保障措施。”</p><p class="piano-inline-promo"/>
<p class="translated">当然，脸书也不是唯一的罪犯。谷歌标榜自己是“隐私冠军”，因为它对用户数据的访问控制得非常严格，<a href="https://web.archive.org/web/20221206162526/https://techcrunch.com/2015/05/14/call-for-google-to-show-its-right-to-be-forgotten-workings/">在它声称“透明”的领域大力调解它发布的数据</a>。然而，多年来，Twitter 经常贬低试图了解内容如何在其平台上流动的第三方研究——称其 API 不提供对所有平台数据和元数据的全面访问，因此该研究无法展示全貌。逃避责任的另一个方便的挡箭牌。</p>
<p class="translated">最近，该公司向研究人员发出了一些<a href="https://web.archive.org/web/20221206162526/https://techcrunch.com/2020/01/06/twitter-offers-more-support-to-researchers-to-keep-us-accountable/">鼓励的声音</a>，更新了其开发政策以澄清规则，以及<a href="https://web.archive.org/web/20221206162526/https://techcrunch.com/2020/04/29/twitter-launches-a-covid-19-dataset-of-tweets-for-approved-developers-and-researchers/">提供了一个与 COVID 相关的数据集</a>——尽管所包含的推文仍然是自选的。所以 Twitter 的调解之手仍然在研究的舵柄上。</p>
<p class="translated">AlgorithmWatch 的一份新的<a href="https://web.archive.org/web/20221206162526/https://algorithmwatch.org/wp-content/uploads/2020/06/GoverningPlatforms_IViR_study_June2020-AlgorithmWatch-2020-06-24.pdf">报告</a>试图解决平台通过调解数据访问来逃避责任的棘手问题——建议采取一些具体步骤来实现透明度和支持研究，包括从医疗数据访问的调解方式以及其他讨论的治理结构中获得灵感。</p>
<p class="translated"><span>目标:对平台数据进行“有意义”的研究访问。(或者如报告标题所言:<i>在平台治理中实施研究准入:向其他行业学习什么？</i> ) </span></p>
<p class="translated">“我们有严格的透明度规则，以便在许多其他领域(食品、交通、消费品、金融等)实现问责制和公共利益。合著者 Jef Ausloos 告诉 TechCrunch:“我们肯定需要它用于在线平台，尤其是在《新冠肺炎时报》上，我们在工作、教育、社交、新闻和媒体消费方面更加依赖它们。”。</p>
<p class="translated">这份报告的作者针对的是欧盟委员会(European Commission)的立法者，他们正在思考如何建立一个有效的平台治理框架。报告提出了强制性的数据共享框架，由一个独立的 EU-机构作为披露公司和数据接收方之间的中介。</p>
<p class="translated">当然，这并不是第一次讨论在线监管机构，但是这里提出的实体在目的上比欧洲提出的其他一些互联网监管机构更加严格。</p>
<p class="translated">“这样一个机构将维护相关的接入基础设施，包括虚拟安全操作环境、公共数据库、网站和论坛。他们<a href="https://web.archive.org/web/20221206162526/https://algorithmwatch.org/en/governing-platforms-ivir-study-june-2020/">在一份报告摘要中写道</a>，它还将在核实和预处理公司数据以确保其适合披露方面发挥重要作用。</p>
<p class="translated">在进一步讨论这种方法时，Ausloos 认为摆脱“二元思维”以打破当前的“数据访问”信任僵局非常重要。“我们需要一种更加细致入微、更加分层的方法，拥有不同程度的数据访问/透明度，而不是这种公开与不透明/模糊的二元思维，”他说。"这种分层的方法取决于请求数据的参与者的类型和他们的目的."</p>
<p class="translated">他表示，市场研究目的可能只能获得非常高水平的数据。而学术机构的医学研究可以被给予更细粒度的访问——当然，要服从严格的要求(如研究计划、伦理委员会审查批准等)。</p>
<p class="translated">“为了促进这一点并产生必要的信任，一个独立的中介机构可能至关重要。Ausloos 说:“我们认为，监管机构的授权脱离具体的政策议程是至关重要的。“它应该专注于成为透明度/披露促进者——为数据交换创造必要的技术和法律环境。媒体/竞争/数据保护/etc 机构可以利用这些信息采取潜在的执法行动。”</p>
<p class="translated">Ausloos 表示，许多关于为在线平台设立独立监管机构的讨论提出了太多的要求或权限，这使得达成政治共识成为不可能。理论上，一个透明度/披露范围较窄的精简实体应该能够避开嘈杂的反对意见。</p>
<p class="translated">臭名昭著的剑桥分析公司(Cambridge Analytica)的例子确实对“研究数据”领域产生了重大影响——这家声名狼藉的数据公司付钱给剑桥大学的一名学者，让他使用一款应用程序来收集和处理脸书用户数据，用于政治广告定位。脸书毫不在意将这一大规模平台数据滥用丑闻变成一根棍子，以击退旨在破解其数据宝库的监管提案。</p>
<p class="translated">但剑桥分析公司是缺乏透明度、问责制和平台监管的直接后果。当然，这也是一个巨大的道德失败——因为政治目标的设定没有征得被获取数据的人的同意。因此，这似乎不是一个反对监管平台数据访问的好理由。恰恰相反。</p>
<p class="translated">在自私的平台巨头将这种“钝器”技术话题游说到治理辩论中的情况下，AlgorithmWatch 报告就如何为现代数据巨头创建有效的治理结构提出了令人欢迎的细微差别和坚实的建议。</p>
<p class="translated">在分层访问点上，该报告建议对平台数据的最细粒度的访问将是最高度受控的，与医疗数据模型一致。Ausloos 指出:“粒度访问也只能在由独立机构控制的封闭虚拟环境中实现，就像目前由 Findata[芬兰医疗数据机构]所做的那样。”。</p>
<p class="translated">报告中讨论的另一个治理结构是欧洲污染物排放和转移登记册(E-PRTR ),作为一个案例研究，从中可以吸取如何激励透明度并从而实现问责制的经验。这规范了整个欧盟的污染物排放报告，并通过专用的网络平台和独立的数据集向公众免费提供排放数据。</p>
<p class="translated">“由于报告的一致性，通过确保报告的数据真实、透明、可靠和可比较，实现了可信度。报告在电子 PRTR 上写道:“建议运营商使用现有的最佳报告技术，以达到完整性、一致性和可信度的标准。”。</p>
<p class="translated">“通过这种形式的透明度，电子 PRTR 旨在向公众、非政府组织、科学家、政治家、政府和监管机构追究欧洲工业设施运营商的责任。”</p>
<p class="translated">虽然欧盟立法者<a href="https://web.archive.org/web/20221206162526/https://techcrunch.com/2020/06/10/tech-giants-must-open-up-about-the-coronavirus-infodemic-say-eu-lawmakers/">表示有意</a>在平台上设置具有法律约束力的透明度要求——至少在一些争议较小的领域，如非法仇恨言论，作为在一些具体内容问题上获得问责的手段——但他们同时制定了一项<a href="https://web.archive.org/web/20221206162526/https://techcrunch.com/2020/02/19/europe-sets-out-plan-to-boost-data-reuse-and-regulate-high-risk-ais/">全面计划，通过促进(非个人)数据的再利用来刺激欧洲的数字经济</a>。</p>
<p class="translated">作为雄心勃勃的数字化转型议程的一部分，利用工业数据支持 R&amp;D 和创新是欧盟委员会未来五年技术驱动型政策优先事项的关键内容。</p>
<p class="translated">这表明，任何开放平台数据的区域性举措都可能超越问责制——鉴于欧盟立法者正在推动建立一个基础数字支持结构的更广泛目标，以通过数据重用实现研究。因此，如果尊重隐私的数据共享框架可以被纳入，那么一个旨在几乎默认实现受监管数据交换的平台治理结构在欧洲背景下开始变得非常可能。</p>
<p class="translated">“实施问责制很重要，我们在污染案例研究中探讨了这一点；但支持研究至少同样重要，”在阿姆斯特丹大学信息法律研究所做博士后研究的 Ausloos 说。“特别是考虑到这些平台构成了现代社会的基础设施，我们需要数据披露来了解社会。”</p>
<p class="translated">“当我们考虑 DSA 的透明度措施时，我们不需要重新发明轮子，”算法观察的<a href="https://web.archive.org/web/20221206162526/https://algorithmwatch.org/en/project/governing-platforms/">治理平台项目</a>的项目负责人 Mackenzie Nelson 在一份声明中补充道。“该报告就委员会如何设计保护用户隐私的框架，同时仍然允许对主流平台的数据进行关键研究提供了具体建议。"</p>
<p class="translated">你可以点击阅读<a href="https://web.archive.org/web/20221206162526/https://algorithmwatch.org/wp-content/uploads/2020/06/GoverningPlatforms_IViR_study_June2020-AlgorithmWatch-2020-06-24.pdf">完整报告。</a></p>
			</div>

			</div>    
</body>
</html>