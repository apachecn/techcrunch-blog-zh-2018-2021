<html>
<head>
<title>We need a new field of AI to combat racial bias • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我们需要一个新的人工智能领域来对抗种族偏见TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2020/07/03/we-need-a-new-field-of-ai-to-combat-racial-bias/">https://web.archive.org/web/https://techcrunch.com/2020/07/03/we-need-a-new-field-of-ai-to-combat-racial-bias/</a></blockquote><div><div class="article-content">
				<div class="article__contributor-byline-wrapper">
<div class="article__contributor-byline">
	<div class="contributor-byline__contributor">
		<p class="byline__author translated"><span class="byline__author-name">加里·m·希夫曼</span><span class="byline__author-title">撰稿人</span></p>

				
			</div>

		
	
		<div class="contributor-byline__more-articles">
		<span class="more-articles-title">More posts by this contributor</span>
		
	</div>
	</div>
</div><p id="speakable-summary" class="translated">自从对种族不平等的广泛抗议开始，IBM宣布将<a href="https://web.archive.org/web/20230117070150/https://techcrunch.com/2020/06/08/ibm-ends-all-facial-recognition-work-as-ceo-calls-out-bias-and-inequality/">取消其面部识别程序</a>，以促进执法中的种族平等。<a href="https://web.archive.org/web/20230117070150/https://techcrunch.com/2020/06/10/amazon-rekognition-moratorium/">亚马逊暂停警方使用其Rekognition软件</a>一年，以“制定更强有力的法规来管理面部识别技术的道德使用。”</p>
<p class="translated">但我们需要的不仅仅是监管改革；人工智能(AI)的整个领域必须在计算机科学实验室之外成熟，并接受整个社区的拥抱。</p>
<p class="translated">我们可以开发出惊人的人工智能，它可以在很大程度上以公正的方式在世界上工作。但要实现这一点，人工智能不能像现在这样只是计算机科学(CS)和计算机工程(ce)的一个子领域。我们必须创建一个考虑到人类行为复杂性的人工智能学科。我们需要从计算机科学拥有的人工智能转移到计算机科学支持的人工智能。人工智能的问题不会发生在实验室里；当科学家将技术应用到现实生活中时，它们就会出现。CS实验室中的训练数据往往缺乏你我所处世界的背景和复杂性。这一缺陷延续了偏见。</p>
<p class="translated">人工智能驱动的算法被发现对有色人种和女性有偏见。例如，2014年，亚马逊发现<a href="https://web.archive.org/web/20230117070150/https://slate.com/business/2018/10/amazon-artificial-intelligence-hiring-discrimination-women.html">它开发的自动猎头人工智能算法</a>教会了自己对女性候选人抱有偏见。麻省理工学院的研究人员在2019年1月报告说，面部识别软件在识别色素沉着较暗的人类时准确性较低。最近，在国家标准和技术研究所(NIST)去年年底的一项研究中，研究人员在近200种面部识别算法中发现了种族偏见的证据。</p>
<p class="translated">尽管人工智能错误的例子数不胜数，但热情仍在继续。这就是为什么IBM和亚马逊的公告产生了如此多的正面新闻报道。从2015年到2019年，全球人工智能的使用量<a href="https://web.archive.org/web/20230117070150/https://venturebeat.com/2019/01/21/gartner-enterprise-ai-implementation-grew-270-over-the-past-four-years/">增长了270% </a>，预计到2025年，该市场将产生<a href="https://web.archive.org/web/20230117070150/https://tractica.omdia.com/newsroom/press-releases/artificial-intelligence-software-market-to-reach-118-6-billion-in-annual-worldwide-revenue-by-2025/">1186亿美元</a>的收入。<a href="https://web.archive.org/web/20230117070150/https://news.gallup.com/poll/228497/americans-already-using-artificial-intelligence-products.aspx">根据盖洛普</a>的数据，近<a href="https://web.archive.org/web/20230117070150/https://news.gallup.com/poll/228497/americans-already-using-artificial-intelligence-products.aspx"> 90%的美国人已经在日常生活中使用人工智能产品</a>——通常甚至没有意识到这一点。</p>
<p class="translated">在12个月的中断之后，我们必须承认，尽管构建人工智能是一项技术挑战，但使用人工智能需要非软件开发的重型学科，如社会科学、法律和政治。但是，尽管我们越来越普遍地使用人工智能，人工智能作为一个研究领域仍然被归入CS和CE领域。例如，在北卡罗来纳州立大学，算法和人工智能在CS项目中教授。麻省理工学院在计算机科学和计算机工程两个学科中都有人工智能的研究。人工智能必须进入人文学科、种族和性别研究课程以及商学院。让我们在政治科学部门开发一个人工智能轨道。在我自己在乔治敦大学的项目中，我们向安全研究学生教授人工智能和机器学习概念。这需要成为惯例。</p>
<p class="translated">如果没有一个更广泛的方法来实现人工智能的专业化，我们几乎肯定会延续今天存在的偏见和歧视性做法。我们可能会以更低的成本进行歧视——这对技术来说不是一个高尚的目标。我们需要有意识地建立一个人工智能领域，其目的是理解神经网络的发展以及该技术将被部署到的社会背景。</p><p class="piano-inline-promo"/>
<p class="translated">在计算机工程中，学生学习编程和计算机基础。在计算机科学中，他们学习计算和编程理论，包括算法学习的基础。这些是人工智能研究的坚实基础——但它们只应被视为组件。这些基础对于理解人工智能领域是必要的，但它们本身是不够的。</p>
<p class="translated">为了让人们对人工智能的广泛部署感到舒适，以便亚马逊和IBM等科技公司以及无数其他公司可以部署这些创新，整个学科需要超越CS实验室。需要那些在心理学、社会学、人类学和神经科学领域工作的人。理解人类行为模式，需要数据生成过程中的偏差。如果没有我的行为科学背景，我不可能开发出<a href="https://web.archive.org/web/20230117070150/https://www.giantoak.com/product">这个软件来识别人口贩卖、洗钱和其他非法行为。</a></p>
<p class="translated">负责任地管理机器学习过程不再仅仅是进步的理想组成部分，而是必要的组成部分。我们必须认识到人类偏见的陷阱和在明天的机器中复制这些偏见的错误，社会科学和人文科学提供了答案。只有创造出一个包含所有这些学科的人工智能新领域，我们才能实现这一目标。</p>
			</div>

			</div>    
</body>
</html>