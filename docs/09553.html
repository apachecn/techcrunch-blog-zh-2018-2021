<html>
<head>
<title>Societal upheaval during the COVID-19 pandemic underscores need for new AI data regulations • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">新冠肺炎疫情期间的社会动荡凸显了对新的人工智能数据法规的需求 TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2020/07/10/societal-upheaval-during-the-covid-19-pandemic-underscores-need-for-new-ai-data-regulations/">https://web.archive.org/web/https://techcrunch.com/2020/07/10/societal-upheaval-during-the-covid-19-pandemic-underscores-need-for-new-ai-data-regulations/</a></blockquote><div><div class="article-content">
				<div class="article__contributor-byline-wrapper">
<div class="article__contributor-byline">
	<div class="contributor-byline__contributor">
		<p class="byline__author translated"><span class="byline__author-name">布拉德福德·k·纽曼</span><span class="byline__author-title">撰稿人</span></p>

			</div>

		<p class="contributor-byline__bio translated">纽曼先生是贝克·麦坚时北美商业秘密事务所的主席。这里表达的观点和意见是他自己的。</p>
	
		<div class="contributor-byline__more-articles">
		<span class="more-articles-title">More posts by this contributor</span>
		
	</div>
	</div>
</div><p id="speakable-summary" class="translated">作为人工智能监管的长期支持者，人工智能监管旨在保护公共健康和安全，同时促进创新，我认为国会必须在两党合作的基础上，立即颁布《人工智能数据保护法》第 102(b)条，这是我提议的立法，现在是众议院讨论的法案草案。以 102(b)节的道德人工智能立法形式的护栏对于维护个人的尊严是必要的。</p>
<p class="translated">《人工智能数据保护法》第 102(b)条规定了什么，为什么联邦政府现在迫切需要制定它？</p>
<p class="translated">要回答这些问题，首先需要了解在这个历史时刻，当我们的民主社会面临两个同时存在的威胁时，人工智能(AI)是如何被使用的。只有到那时，人工智能对我们个人尊严构成的风险才能得到承认，而第 102(b)条可以被理解为保护美国人珍视的自由的最重要的补救措施之一，这些自由是我们社会的基石。</p>
<p class="translated">美国现在正经历大规模的抗议活动，要求结束种族主义和警察暴行，并看到在试图平息致命的新冠肺炎·疫情的过程中，民间动乱的展开。无论我们是否意识到或认可它，在这两种情况下——以及我们生活的每个其他方面——人工智能技术正在被政府和私人行为者部署，以做出关于我们的关键决定。在许多情况下，人工智能被用来帮助社会，让我们尽快进入下一个正常状态。</p>
<p class="translated">但到目前为止，政策制定者在很大程度上忽略了一个关键的人工智能驱动的公共健康和安全问题。当谈到人工智能时，大多数焦点都集中在用于训练算法的数据集的公平性、偏见和透明度问题上。毫无疑问，算法已经产生了偏差；人们只需要看看雇员招聘和贷款担保中不公平排斥妇女和少数民族的例子。</p>
<p class="translated">我们也看到人工智能从数据中产生意想不到的，有时无法解释的结果。考虑一下最近的一个例子，一种算法被认为可以帮助法官对非暴力罪犯做出公正的判决。出于尚未解释的原因，该算法给 23 岁以下的被告分配了更高的风险分数，导致他们的刑期比他们被监禁更频繁的年长同龄人长 12%，而这既没有减少监禁，也没有减少累犯。</p>
<p class="translated">但当前的双重危机暴露了另一个更令人烦恼的问题，这个问题在很大程度上被忽视了——如果人工智能算法做对了，但从伦理的角度来看，社会对结果感到不安，社会应该如何应对这种情况？由于人工智能的基本目的是产生人类可以做出决策的准确预测数据，立法者解决的不是人工智能的可能性，而是应该禁止什么的时候到了。</p><p class="piano-inline-promo"/>
<p class="translated">政府和私营企业对我们的个人数据有着永无止境的需求。现在，包括美国在内的世界各地都在利用人工智能算法来准确收集和分析关于我们所有人的各种数据。我们有面部识别来监视人群中的抗议者，或者确定公众是否遵守适当的社交距离。有用于接触追踪的手机数据，以及公共社交媒体帖子，以模拟冠状病毒向特定邮政编码的传播，并预测与示威游行相关的位置、规模和潜在暴力。我们不要忘记无人机数据正被用来分析口罩使用和发烧，或个人健康数据被用来预测哪些因 COVID 住院的患者病情恶化的可能性最大。</p>
<p class="translated">只有通过使用人工智能，才能在如此大的规模上汇编和分析如此大量的个人数据。</p>
<p class="translated">这种通过算法创建我们的手机数据、社会行为、健康记录、旅行模式和社交媒体内容——以及许多其他个人数据集——的个性化配置文件的访问，以维护和平和遏制毁灭性的疫情的名义，能够并将导致各种政府行为者和公司创建我们最私人的属性、政治倾向、社交圈和行为的惊人准确的预测配置文件。</p>
<p class="translated">如果不受监管，社会就会面临这些人工智能生成的分析被执法部门、雇主、房东、医生、保险公司——以及其他所有能够收集或购买这些分析的私人、商业和政府企业——用来做出预测性决策的风险，无论这些决策准确与否，都会影响我们的生活，并对自由民主的最基本理念造成打击。人工智能继续在就业领域发挥越来越大的作用，决定谁应该面试、聘用、晋升和解雇。在刑事司法的背景下，它被用来决定谁应该被监禁和判处何种刑罚。在其他场景中，人工智能限制人们呆在家里，限制在医院的某些治疗，拒绝贷款，并惩罚那些违反社会距离规定的人。</p>
<p class="translated">很多时候，那些回避任何人工智能监管的人试图将这些担忧视为假设和杞人忧天。但就在几周前，密歇根州的黑人居民罗伯特·威廉斯因为一次错误的人脸识别匹配而被错误逮捕。根据新闻报道和美国公民自由联盟的新闻稿，底特律警方当着他妻子和两个吓坏了的女孩(一个两岁，一个五岁)的面，在他家前的草坪上给威廉姆斯戴上了手铐。警察把他带到大约 40 分钟路程的拘留中心，在那里他被关了一夜。在第二天下午的审讯中，一名警官承认“电脑肯定弄错了”，威廉姆斯最终被释放——在他被捕近 30 个小时后。</p>
<p class="translated">虽然人们普遍认为这是首例确认的人工智能面部识别错误导致无辜市民被捕的案件，但显然这不会是最后一例。在这里，人工智能作为一个关键决定的主要依据，影响到公民个人——被执法部门逮捕。但我们不能只关注人工智能失败的事实，因为它识别了错误的人，剥夺了他的自由。我们必须识别并禁止那些人工智能不应该被用作特定关键决策的基础的情况——即使它得到了“正确”的结果。</p>
<p class="translated">作为一个民主社会，我们不应该对因我们计划但没有犯下的罪行而被逮捕，或被剥夺对一种疾病的治疗感到更舒服，这种疾病随着时间的推移无疑会导致死亡，就像我们对威廉姆斯先生的错误逮捕一样。我们必须建立人工智能“禁飞区”来保护我们的个人自由。我们不能让某些关键决策完全依赖人工智能算法的预测输出。</p>
<p class="translated">明确地说，这意味着即使在每个专家都同意进出数据完全公正、透明和准确的情况下，也必须有法律禁止将其用于任何类型的预测或实质性决策。诚然，在我们渴望数学确定性的世界里，这是违背直觉的，但却是必要的。</p>
<p class="translated">《人工智能数据保护法案》第 102(b)条在两种情况下都正确合理地实现了这一点——人工智能产生正确和/或不正确的结果。它以两种主要方式做到这一点。</p>
<p class="translated">首先，第一百零二条第(二)款明确地指出了那些永远不能由人工智能全部或部分作出的决定。例如，它列举了人工智能的具体滥用，这些滥用将禁止所涵盖的实体完全依赖人工智能来做出某些决定。这些包括个人的招募、雇用和纪律，拒绝或限制医疗，或医疗保险发行人就医疗保险做出决定。鉴于社会最近目睹的情况，禁区可能会扩大，以进一步减少人工智能被用作种族歧视和骚扰受保护少数群体的工具的风险。</p>
<p class="translated">第二，对于基于人工智能分析的某些其他特定决策，没有被直接禁止，第 102(b)节定义了人类必须参与决策过程的那些情况。</p>
<p class="translated">通过毫不拖延地颁布第 102(b)条，立法者可以通过不允许影响个人的最关键的决定完全由人工智能算法的预测输出来维护个人的尊严。</p>
			</div>

			</div>    
</body>
</html>