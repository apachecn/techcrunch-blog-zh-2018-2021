<html>
<head>
<title>AI is struggling to adjust to 2020 </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能正在努力适应2020年</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2020/08/02/ai-is-struggling-to-adjust-to-2020/">https://web.archive.org/web/https://techcrunch.com/2020/08/02/ai-is-struggling-to-adjust-to-2020/</a></blockquote><div><div class="article-content">
				<div class="article__contributor-byline-wrapper">
<div class="article__contributor-byline">
	<div class="contributor-byline__contributor">
		<p class="byline__author translated"><span class="byline__author-name">安德里亚·加利亚诺</span><span class="byline__author-title">撰稿人</span></p>

				
			</div>

		
	
		<div class="contributor-byline__more-articles">
		<span class="more-articles-title">More posts by this contributor</span>
		
	</div>
	</div>
</div><p id="speakable-summary" class="translated">2020年已经让每个行业重新想象如何根据新冠肺炎向前发展:民权运动，选举年和无数其他重大新闻时刻。从人类的角度来看，我们必须适应新的生活方式。我们已经开始接受这些变化，并想出如何在这些新的疫情规则下生活。当人类安顿下来时，人工智能正在努力跟上。</p>
<p class="translated">2020年人工智能训练的问题是，突然间，我们改变了我们的社会和文化规范。我们教给这些算法的真理往往不再真实。特别是对于视觉人工智能，我们要求它立即解释我们生活的新方式，以及它还没有的更新的上下文。</p>
<p class="translated">算法仍在适应新的视觉队列，并试图理解如何准确识别它们。随着视觉人工智能的发展，我们也需要重新重视人工智能训练过程中的例行更新，以便纠正不准确的训练数据集和预先存在的开源模型。</p>
<p class="translated">计算机视觉模型正在努力为我们在新冠肺炎时代发现自己所处的新场景或新情况添加合适的标签。类别已经改变。例如，假设有一幅画面，父亲在家工作，而他的儿子在玩耍。艾仍将其归类为“休闲”或“放松”它并没有把这看作是“工作”或“办公室”，尽管在这段时间里，和你的孩子一起工作是许多家庭非常普遍的现实。</p>
<p/><div id="attachment_2025145" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2025145" decoding="async" class="size-full wp-image-2025145" src="../Images/df448f30dbfd638bf47bc6926f7c4a45.png" alt="" srcset="https://web.archive.org/web/20230223082503im_/https://techcrunch.com/wp-content/uploads/2020/07/gettyimages-1134461939-170667a.jpg 510w, https://web.archive.org/web/20230223082503im_/https://techcrunch.com/wp-content/uploads/2020/07/gettyimages-1134461939-170667a.jpg?resize=150,100 150w, https://web.archive.org/web/20230223082503im_/https://techcrunch.com/wp-content/uploads/2020/07/gettyimages-1134461939-170667a.jpg?resize=300,199 300w, https://web.archive.org/web/20230223082503im_/https://techcrunch.com/wp-content/uploads/2020/07/gettyimages-1134461939-170667a.jpg?resize=50,33 50w" sizes="(max-width: 510px) 100vw, 510px" data-original-src="https://web.archive.org/web/20230223082503im_/https://techcrunch.com/wp-content/uploads/2020/07/gettyimages-1134461939-170667a.jpg"/><p id="caption-attachment-2025145" class="wp-caption-text translated"><strong>图片来源:</strong> Westend61/Getty Images</p></div>
<p class="translated">在一个更技术性的层面上，我们对我们的世界有不同的像素描述。在Getty Images，我们一直在训练人工智能“看”。这意味着算法可以识别图像，并根据图像的像素构成对其进行分类，并决定图像包含的内容。快速改变我们的日常生活意味着我们也在改变一个类别或标签(如“清洁”)所包含的内容。</p>
<p class="translated">可以这样想——清洁现在可能包括擦拭看起来已经很干净的表面。算法以前被教导过，要描绘清洁，需要有一片混乱。现在，这看起来非常不同。我们的系统必须重新训练，以考虑这些重新定义的类别参数。</p><p class="piano-inline-promo"/>
<p class="translated">这在较小的范围内也有关系。有人可能坐在车里用小抹布抓门把手或擦方向盘。当人们试图保持安全时，曾经是微不足道的细节现在变得很重要。我们需要捕捉这些细微的差别，以便恰当地标记。那么AI就可以在2020年开始理解我们的世界，并产生准确的输出。</p>
<p/><div id="attachment_2025147" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2025147" decoding="async" loading="lazy" class="size-full wp-image-2025147" src="../Images/4f21b44af618bfd28ccbfb2e149e13ab.png" alt="" srcset="https://web.archive.org/web/20230223082503im_/https://techcrunch.com/wp-content/uploads/2020/07/gettyimages-1219727445-170667a.jpg 509w, https://web.archive.org/web/20230223082503im_/https://techcrunch.com/wp-content/uploads/2020/07/gettyimages-1219727445-170667a.jpg?resize=150,100 150w, https://web.archive.org/web/20230223082503im_/https://techcrunch.com/wp-content/uploads/2020/07/gettyimages-1219727445-170667a.jpg?resize=300,200 300w, https://web.archive.org/web/20230223082503im_/https://techcrunch.com/wp-content/uploads/2020/07/gettyimages-1219727445-170667a.jpg?resize=50,33 50w" sizes="(max-width: 509px) 100vw, 509px" data-original-src="https://web.archive.org/web/20230223082503im_/https://techcrunch.com/wp-content/uploads/2020/07/gettyimages-1219727445-170667a.jpg"/><p id="caption-attachment-2025147" class="wp-caption-text translated"><strong>图片来源:</strong>陈子敬/Getty Images</p></div>
<p class="translated">人工智能目前面临的另一个问题是，机器学习算法仍在试图理解如何识别和分类带面具的人脸。面部被检测为仅仅是面部的上半部分，或者是两个面部——一个有面具，另一个只有眼睛。这造成了不一致性，并抑制了面部检测模型的准确使用。</p>
<p class="translated">一条前进的道路是重新训练算法，以便在只给出面部的顶部(面具上方)时表现得更好。面具问题类似于经典的面部检测挑战，例如某人戴着太阳镜或检测某人侧面的面部。现在面具也很普遍。</p>
<p/><div id="attachment_2025148" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2025148" decoding="async" loading="lazy" class="size-full wp-image-2025148" src="../Images/b4095ad04d909a5284312d3e467d4c3e.png" alt="" srcset="https://web.archive.org/web/20230223082503im_/https://techcrunch.com/wp-content/uploads/2020/07/gettyimages-1223070989-170667a.jpg 485w, https://web.archive.org/web/20230223082503im_/https://techcrunch.com/wp-content/uploads/2020/07/gettyimages-1223070989-170667a.jpg?resize=150,110 150w, https://web.archive.org/web/20230223082503im_/https://techcrunch.com/wp-content/uploads/2020/07/gettyimages-1223070989-170667a.jpg?resize=300,220 300w, https://web.archive.org/web/20230223082503im_/https://techcrunch.com/wp-content/uploads/2020/07/gettyimages-1223070989-170667a.jpg?resize=50,37 50w" sizes="(max-width: 485px) 100vw, 485px" data-original-src="https://web.archive.org/web/20230223082503im_/https://techcrunch.com/wp-content/uploads/2020/07/gettyimages-1223070989-170667a.jpg"/><p id="caption-attachment-2025148" class="wp-caption-text translated"><strong>图片来源:</strong>Rodger Shija/EyeEm/Getty Images</p></div>
<p class="translated">这向我们表明，在真正能够“看到”我们不断发展的社会景观之前，计算机视觉模型还有很长的路要走。解决这个问题的方法是建立强大的数据集。然后，我们可以训练计算机视觉模型来解释一张脸可能被遮挡或覆盖的无数不同方式。</p>
<p class="translated">在这一点上，我们正在扩展算法所看到的人脸的参数——无论是在杂货店戴口罩的人，戴口罩作为日常工作一部分的护士，还是出于宗教原因遮住脸的人。</p>
<p class="translated">当我们创建构建这些强大数据集所需的内容时，我们应该意识到潜在的无意偏差的增加。虽然人工智能中总会存在一些偏见，但我们现在看到不平衡的数据集描绘了我们的新常态。例如，我们看到的白人戴面具的形象比其他种族的人多。</p>
<p class="translated">这可能是严格的居家命令的结果，在这种情况下，摄影师除了自己的社区之外，很难进入其他社区，也无法多样化他们的主题。这可能是由于选择拍摄这个主题的摄影师的种族。或者，由于新冠肺炎对不同地区的影响程度。不管是什么原因，拥有这种不平衡将导致算法能够比任何其他种族或族裔更准确地检测到戴面具的白人。</p>
<p class="translated">数据科学家和那些用模型构建产品的人有更大的责任根据社会规范的变化来检查模型的准确性。对训练数据和模型的常规检查和更新是确保模型质量和稳健性的关键，现在比以往任何时候都重要。如果输出不准确，数据科学家可以快速识别并纠正。</p>
<p class="translated">同样值得一提的是，在可预见的未来，我们目前的生活方式将会一直保持下去。正因为如此，我们必须谨慎对待我们用于训练目的的开源数据集。可以更改的数据集应该。不能改变的开源模型需要有一个免责声明，这样就很清楚过时的训练数据可能会对哪些项目产生负面影响。</p>
<p class="translated">识别我们要求系统理解的新环境是推动视觉人工智能向前发展的第一步。那么我们需要更多的内容。对我们周围世界的更多描述——以及对它的不同视角。当我们积累这些新内容时，请评估新的潜在偏见和重新训练现有开源数据集的方法。我们都必须监控不一致和不准确的地方。坚持不懈地致力于重新训练计算机视觉模型，是我们将人工智能带入2020年的方式。</p>
			</div>

			</div>    
</body>
</html>