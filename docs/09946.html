<html>
<head>
<title>UK commits to redesign visa streaming algorithm after challenge to 'racist' tool </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在挑战“种族主义”工具后，英国承诺重新设计签证流算法</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2020/08/04/uk-commits-to-redesign-visa-streaming-algorithm-after-challenge-to-racist-tool/">https://web.archive.org/web/https://techcrunch.com/2020/08/04/uk-commits-to-redesign-visa-streaming-algorithm-after-challenge-to-racist-tool/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">英国政府暂停使用一种用于处理签证申请的算法，因为有人担心这种技术存在无意识的偏见和种族主义。</p>
<p class="translated">该工具曾是一起法律诉讼的目标。移民福利联合委员会(JCWI)和律师事务所 foglogol 要求法院宣布签证申请流算法非法，并下令停止使用，等待司法审查。</p>
<p class="translated">这场法律诉讼尚未结束，但似乎已经迫使内政部出手，因为它已承诺重新设计该系统。</p>
<p class="translated">内政部发言人向我们证实，从 8 月 7 日起，该算法的使用将被暂停，并通过电子邮件向我们发送了以下声明:“我们一直在审查签证申请流工具的运作方式，并将重新设计我们的流程，使其更加简化和安全。”</p>
<p class="translated">尽管政府没有接受偏见的指控，但在给律师事务所的一封信中写道:“重新设计的事实并不意味着(国务卿)接受你索赔表中的指控(即围绕无意识偏见和在分流过程中使用国籍作为标准)。”</p>
<p class="translated">内政部的信还声称，该部门已经“在许多应用程序类型中”不再使用流媒体工具但它补充说，它将“以开放的态度考虑你提出的问题”，来进行重新设计</p>
<p class="translated">重新设计定于秋季完成，内政部表示，与此同时，将推出一个临时程序，排除使用国籍作为分类标准。</p><p class="piano-inline-promo"/>

<p class="translated">JCWI 声称战胜了它所描述的“影子的、计算机驱动的”人员筛选系统——在其<a href="https://web.archive.org/web/20230306042906/https://www.jcwi.org.uk/news/we-won-home-office-to-stop-using-racist-visa-algorithm">网站</a>上写道:“今天的胜利代表了英国首次成功挑战算法决策系统。我们已经要求法院宣布分流算法非法，并下令停止使用它来评估签证申请，等待审查。内政部的决定实际上承认了这一主张。</p>
<p class="translated">该部门没有回答我们就算法及其设计过程向其提出的许多问题，包括它在实施该技术之前是否寻求了法律建议，以确定它是否符合英国的平等法案。</p>
<p class="translated">内政部声明补充说:“我们不接受移民福利联合委员会在司法审查索赔中的指控，虽然诉讼仍在进行，但司法部不适合进一步评论。”</p>
<p class="translated">JCWI 的投诉集中在自 2015 年以来使用一种带有“交通灯系统”的算法来对每一份英国入境签证申请进行评级</p>
<p class="translated">“这个被内政部描述为数字‘流工具’的工具，给申请者分配一个红色、琥珀色或绿色的风险等级。一旦由算法分配，这种评级在决定签证申请的结果方面发挥着重要作用，”它<a href="https://web.archive.org/web/20230306042906/https://www.jcwi.org.uk/news/we-won-home-office-to-stop-using-racist-visa-algorithm">写道</a>，鉴于其对某些国籍的待遇，将这种技术称为“种族主义”和歧视性的设计。</p>
<p class="translated">“签证算法是基于国籍的歧视——这是有意为之。持有“可疑”国籍的人提出的申请获得了更高的风险分数。他们的申请受到了内政部官员的严格审查，受到了更多的质疑，需要更长的时间来决定，更有可能被拒绝。</p>
<p class="translated">“我们认为这是种族歧视，违反了 2010 年平等法案，”它补充说。“流媒体工具不透明。除了承认存在可疑国籍的秘密名单，内政部拒绝提供关于算法的有意义的信息。目前还不清楚还有哪些其他因素被用来给申请打分。</p>
<p class="translated">自 2012 年以来，内政部公开实施了一项被称为“敌对环境”的移民政策——应用行政和立法程序，旨在尽可能地让人们难以留在英国</p>
<p class="translated">这项政策导致了一系列的<a href="https://web.archive.org/web/20230306042906/https://en.wikipedia.org/wiki/Windrush_scandal">人权丑闻。(我们还通过讲述一家英国初创公司去年在</a>遭遇签证噩梦的故事，报道了签证对当地科技行业的影响。)因此，在一个已经非常有问题的政策上应用自动化看起来确实像是一个被送上法庭的公式。</p>
<p class="translated">JCWI 对流媒体工具的担忧正是它被用来自动化种族主义和歧视，许多人认为这是内政部“敌对环境”政策的基础。换句话说，如果政策本身是种族主义的，任何算法都会发现并反映出来。</p>
<p class="translated">JCWI 法律政策主任柴·帕特尔(Chai Patel)在一份声明中说，“内政部对 Windrush 丑闻的独立审查发现，它无视其运作的种族主义假设和系统。”“这个流媒体工具采用了几十年的制度化种族主义做法，例如针对特定国籍进行移民突袭，并将它们转化为软件。移民系统需要从头开始重建，以监控并根除这种偏见。”</p>
<p class="translated">“我们很高兴内政部已经认识到这一点，并放弃了流媒体工具。种族主义反馈循环意味着，本应公平的移民过程实际上只是“白人快速登机”“我们需要的是民主，而不是算法政府，”毛地黄创始人兼董事柯里·克里德补充道在推出任何进一步的系统之前，让我们问问专家和公众，自动化到底是否合适，以及如何才能发现历史偏见并从根源上挖掘出来。"</p>
<p class="translated">在给 Foxglove 的<a href="https://web.archive.org/web/20230306042906/https://www.foxglove.org.uk/news/home-office-says-it-will-abandon-its-racist-visa-algorithm-nbsp-after-we-sued-them">信中，政府承诺对从 8 月 7 日开始的过渡进程进行平等影响评估和数据保护影响评估，政府写道，它将使用“以人为中心的属性(如以前旅行的证据)”来帮助筛选一些签证申请，进一步承诺“不会使用国籍。”</a></p>
<p class="translated">在此期间，某些类型的申请将从筛选过程中完全删除。</p>
<p class="translated">“目的是重新设计将尽快完成，最迟在 2020 年 10 月 30 日，”它补充说。</p>
<p class="translated">当被问及法律上可接受的签证流算法看起来会是什么样时，互联网法律专家<a href="https://web.archive.org/web/20230306042906/https://twitter.com/lilianedwards"> Lilian Edwards </a>告诉 TechCrunch:“这是一个艰难的问题……我不是一名移民律师，无法知道根据司法审查标准，最初适用的怀疑国籍的标准是否是非法的，即使在排序算法中实施的是<em>而不是</em>。如果答案是肯定的，那么很明显，下一代算法应该只在法律允许的基础上进行歧视。</p>
<p class="translated">“我们都知道的问题是，机器学习可以重建非法标准——尽管现在有一些众所周知的技术可以规避这一点。”</p>

<p class="translated">“你可以说，算法系统帮了我们一个忙，它对抗了被使用的非法标准，这些标准可能一直隐藏在个别移民官的非正式层面。事实上，这种系统的一个论点曾经是“一致性和非任意性”的性质。这很难，”她补充道。</p>
<p class="translated">今年早些时候，荷兰政府被命令停止使用一种算法风险评分系统来预测社会保障申请人进行福利或税务欺诈的可能性——在当地法院发现这违反了人权法之后。</p>
<p class="translated">在另一个<a href="https://web.archive.org/web/20230306042906/https://techcrunch.com/2020/07/20/uk-uber-drivers-are-taking-its-algorithm-to-court/">有趣的案例</a>中，一群英国优步硬盘正在挑战 gig 平台在欧洲数据保护框架下对它们进行算法管理的合法性——该框架烘烤数据访问权，包括与具有法律意义的自动决策相关的条款。</p>
			</div>

			</div>    
</body>
</html>