<html>
<head>
<title>Here are a few ways GPT-3 can go wrong </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">以下是 GPT 3 号可能出错的几个方面</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2020/08/07/here-are-a-few-ways-gpt-3-can-go-wrong/">https://web.archive.org/web/https://techcrunch.com/2020/08/07/here-are-a-few-ways-gpt-3-can-go-wrong/</a></blockquote><div><div class="article-content">
				<div class="article__contributor-byline-wrapper">
<div class="article__contributor-byline">
	<div class="contributor-byline__contributor">
		<p class="byline__author translated"><span class="byline__author-name">莉兹·奥沙利文</span><span class="byline__author-title">撰稿人</span></p>

				
			</div>

		<div class="contributor-byline__bio"><p class="translated">利兹·奥沙利文是</p><a href="https://web.archive.org/web/20230326025808/http://www.getparity.ai/">Parity</a><p class="translated">，一个为企业自动化模型风险和算法治理的平台。她还建议监督技术监督项目和运动，以停止所有人工智能的黑仔机器人。</p></div>
	
		<div class="contributor-byline__more-articles">
		<span class="more-articles-title">More posts by this contributor</span>
		
	</div>
	</div>

<div class="article__contributor-byline">
	<div class="contributor-byline__contributor">
		<p class="byline__author translated"><span class="byline__author-name">约翰·p·迪克森</span><span class="byline__author-title">撰稿人</span></p>

				
			</div>

		<div class="contributor-byline__bio"><p class="translated">约翰·p·迪克森是哈佛大学的首席科学家</p><a href="https://web.archive.org/web/20230326025808/http://www.arthur.ai/">Arthur</a><p class="translated">以及马里兰大学的计算机科学系；他在经济学和计算机科学的交叉领域广泛工作，专注于使用机器学习来平衡市场中的公平和效率。</p></div>
	
	</div>
</div><p id="speakable-summary" class="translated">OpenAI 的最新语言生成模型 GPT-3 在人工智能界引起了轩然大波，令记者们震惊不已，甚至 OpenAI 的领导者山姆·奥特曼<a href="https://web.archive.org/web/20230326025808/https://twitter.com/sama/status/1284922296348454913?lang=en">在 Twitter </a>上提到它可能被夸大了。尽管如此，毫无疑问，GPT-3 是强大的。那些早期接触 OpenAI 的 GPT-3 API 的人已经展示了如何将自然语言翻译成用于网站的<a href="https://web.archive.org/web/20230326025808/https://twitter.com/jsngr/status/1287026808429383680">代码</a>，解决复杂的<a href="https://web.archive.org/web/20230326025808/https://twitter.com/QasimMunye/status/1278750809094750211">医学问答</a>问题，创建<a href="https://web.archive.org/web/20230326025808/https://twitter.com/itsyashdani/status/1285695850300219392">基本的表格财务报告</a>，甚至编写<a href="https://web.archive.org/web/20230326025808/https://twitter.com/mattshumer_/status/1287125015528341506">代码来训练机器学习模型</a>——所有这些都只需要几个精心制作的示例作为输入(即通过<a href="https://web.archive.org/web/20230326025808/https://medium.com/quick-code/understanding-few-shot-learning-in-machine-learning-bede251a0f67">少量学习</a>)。</p>
<p class="translated">很快，任何人都将能够购买 GPT-3 的生成能力来利用语言模型，为构建工具打开大门，这些工具将悄悄地(但显著地)塑造我们的世界。旨在利用 GPT-3 的企业，以及必将随之而来的日益强大的迭代，必须非常小心，以确保在使用该模型时安装广泛的护栏，因为它可能会以多种方式使公司面临法律风险和声誉风险。在我们讨论这个模型如何在实践中可能出错的一些例子之前，让我们先看看<a href="https://web.archive.org/web/20230326025808/https://arxiv.org/pdf/2005.14165.pdf">GPT-3 是如何制造的</a>。</p>
<p class="translated">机器学习模型的好坏取决于训练期间输入其中的数据。在 GPT 3 号的例子中，数据是巨大的。 GPT-3 在通用抓取数据集<a href="https://web.archive.org/web/20230326025808/https://commoncrawl.org/the-data/">上接受训练，数据集</a>是互联网上 6000 万个域名以及它们所链接的网站的一个大的子集。这意味着 GPT-3 吸纳了许多互联网上更有声望的媒体——比如 BBC 或《纽约时报》——以及不太有声望的媒体——比如 Reddit。然而，普通爬行只占 GPT 3 号训练数据的 60%;OpenAI 的研究人员还提供了其他精选资源，如维基百科和历史相关书籍的全文。</p>
<p class="translated">语言模型学习对于任何给定的输入单词或短语，接下来可能出现哪些后续单词、短语和句子。通过在训练期间“阅读”主要由我们编写的文本，像 GPT-3 这样的语言模型也学习如何像我们一样“写作”，包括人类所有最好和最差的品质。藏在 GPT-3 论文的补充材料中，研究人员让我们对隐藏在其中的一小部分有问题的偏见有了一些了解。正如你对任何一个在未经过滤的互联网快照上训练出来的模型的期望一样，这些发现可能是相当有害的。</p>
<p class="translated">因为网络上有太多的内容将女性性感化，研究人员指出，GPT-3 更有可能将“淘气”或“吮吸”这样的词放在女性代词旁边，而男性代词最糟糕的情况下会收到“懒惰”或“快乐”这样的定型形容词。当涉及到宗教时，“伊斯兰教”更常出现在“恐怖主义”等词的旁边，而“无神论”一词的提示更有可能产生包含“酷”或“正确”等词的文本而且，也许最危险的是，当暴露于包含黑人种族内容的文本种子时，GPT-3 给出的输出往往比相应的白人或亚裔声音提示更消极。</p>
<p/>
<p class="translated">这在 GPT-3 的真实使用案例中会如何表现呢？假设你经营一家媒体公司，处理来自世界各地的大量数据。你可能想使用像 GPT-3 这样的语言模型来<a href="https://web.archive.org/web/20230326025808/https://venturebeat.com/2018/11/06/microsoft-researchers-develop-ai-system-that-can-generate-articles-summaries/">总结这些信息</a>，今天许多新闻机构已经这样做了。有些甚至走得更远，实现了故事创作的自动化，这意味着 GPT-3 的输出可以直接登陆你的主页<a href="https://web.archive.org/web/20230326025808/https://www.theguardian.com/technology/2020/jun/09/microsofts-robot-journalist-confused-by-mixed-race-little-mix-singers">，而无需任何人工监督</a>。如果这个模型对黑人有负面的偏见——就像 GPT-3 的情况一样——你网站上的标题也会收到这种负面的偏见。人工智能生成的关于黑人的命也是命的中立新闻摘要很可能会让<a href="https://web.archive.org/web/20230326025808/https://arstechnica.com/information-technology/2019/02/twenty-minutes-into-the-future-with-openais-deep-fake-text-ai/">在辩论中选择一方</a>。这很可能会谴责这场运动，因为该模型会将负面语言与“黑人”等种族术语联系在一起。这反过来可能会疏远你的部分观众，加深全国的种族紧张局势。充其量，你会失去很多读者。最坏的情况是，这个标题可能会引发更多的抗议和警察暴力，进一步加剧国家动荡的恶性循环。</p><p class="piano-inline-promo"/>
<p class="translated">OpenAI 的网站还详细介绍了一项医学应用，即使建模者的意图是好的，偏见问题也足以促使 T2 联邦调查。全国各地的医院已经开始尝试主动检测 T4 精神疾病或值得干预的罕见潜在疾病。很容易想象一家医疗保健公司使用 GPT-3 来驱动聊天机器人——甚至像搜索引擎一样“简单”的东西——从患者那里获取症状，并输出护理建议。想象一下，如果你愿意，一个患有妇科疾病的女性患者。模型对患者意图的解释可能与其他不那么医学的关联结合在一起，促使人工智能做出攻击性或<a href="https://web.archive.org/web/20230326025808/https://qz.com/1766418/how-using-babylon-healths-ai-symptom-checker-could-go-wrong/">轻蔑的评论</a>，同时将她的健康置于风险之中。该论文没有提到该模型如何对待处于危险中的少数群体，例如那些被认为是跨性别者或非双生子的人，但是如果 Reddit <a href="https://web.archive.org/web/20230326025808/https://www.motherjones.com/politics/2019/08/reddit-hate-content-moderation/">评论部分</a>是我们很快就会看到的反应的任何迹象，那么担忧的原因是真实的。</p>
<p class="translated">但由于算法偏差很少是直截了当的，许多 GPT-3 应用程序将在日益增长的人工智能驱动的应用程序中充当金丝雀。随着新冠肺炎肆虐我们的国家，学校正在寻找新的方法来管理远程评分要求，私营部门提供了解决方案，以接受学校作业并输出教学建议。一个负责给论文或学生报告评分的算法很可能会对来自不同文化的语言区别对待。不同的文化和性别之间，写作风格和用词会有很大的不同。一个没有护栏的 GPT-3 动力纸平地机可能会认为白纸黑字的报告更值得表扬，或者它可能会根据暗示英语为第二语言的微妙线索惩罚学生，而这反过来又与种族密切相关。结果，移民和少数民族的孩子不太可能高中毕业，尽管这不是他们自己的错。</p>
<p class="translated">GPT-3 的创造者计划继续研究该模型的偏差，但目前，他们只是将这些担忧浮出水面，将风险转嫁给任何愿意冒险的公司或个人。正如我们所知，所有的模型都是有偏见的，这不应该成为取缔所有人工智能的理由，因为从长远来看，它的好处肯定会超过风险。但为了享受这些好处，我们必须确保在我们匆忙将像 GPT-3 这样的强大人工智能部署到企业时，我们采取足够的预防措施来了解、监控并迅速采取行动来缓解其故障点。只有通过人类和<a href="https://web.archive.org/web/20230326025808/https://www.arthur.ai/blog/2019/7/19/never-deploy-ai-without-doing-these-3-things">自动化监督</a>的负责任的结合，人工智能应用才能被信任来提供社会价值，同时保护公共利益。</p>
<p class="translated"><em>这篇文章是人类写的</em>。</p>
			</div>

			</div>    
</body>
</html>