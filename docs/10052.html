<html>
<head>
<title>Court finds some fault with UK police force's use of facial recognition tech • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">法院发现英国警方使用面部识别技术TechCrunch存在一些问题</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2020/08/11/court-finds-some-fault-with-uk-police-forces-use-of-facial-recognition-tech/">https://web.archive.org/web/https://techcrunch.com/2020/08/11/court-finds-some-fault-with-uk-police-forces-use-of-facial-recognition-tech/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">英国民权活动家赢得了对南威尔斯警方(SWP)使用面部识别技术的法律挑战。正如人权组织<a href="https://web.archive.org/web/20221117192732/https://www.libertyhumanrights.org.uk/issue/liberty-wins-ground-breaking-victory-against-facial-recognition-tech/"> Liberty </a>所说，上诉的胜利被誉为反对使用“压迫性监控工具”的“世界第一”胜利。</p>
<p class="translated">然而，警方不打算对该裁决提出上诉，并表示仍将致力于“谨慎”使用该技术。</p>
<p class="translated">这里的背景故事是，SWP自2017年以来一直在测试自动面部识别(AFR)技术，在2017年5月至2019年4月期间，在威尔士的各种公共活动中，部署了一个名为AFR定位的系统约50次。</p>
<p class="translated">该部队将这项技术与400-800人的监视名单结合使用，其中包括通缉犯；从拘留所逃脱的人；涉嫌犯罪的人；可能需要保护的人；弱势群体；出于情报目的可能与其有关的人员；根据上诉法院发布的<a href="https://web.archive.org/web/20221117192732/https://www.judiciary.uk/wp-content/uploads/2020/08/R-Bridges-v-CC-South-Wales-ors-Press-Summary.pdf">新闻摘要</a>，出席特定活动的人引起特别关注。</p>
<p class="translated">在Liberty的支持下，一位名叫Edward Bridges的加的夫公民自由活动家对SWP使用AFR提出了挑战。布里奇斯在AFR定位的两个部署附近——第一个是2017年12月21日在加的夫市中心，第二个是2018年3月27日在该市举行的国防采购，研究，技术和出口展览——虽然他本人没有被列入部队观察名单，但他声称，由于他靠近摄像头，他的图像被系统记录下来，即使在那之后几乎立即被删除。</p>
<p class="translated">警察未经授权处理敏感个人数据的人权影响是本案的核心问题。自动化身份决策可能带来的偏见风险是另一个需要考虑的关键问题。</p>
<p class="translated">Bridges最初提出司法审查请求，理由是AFR不符合《欧洲人权公约》第8条、数据保护立法和2010年《平等法》第149条规定的公共部门平等义务(" PSED ")规定的尊重私人生活的权利。</p><p class="piano-inline-promo"/>
<p class="translated">去年9月，地方法院以所有理由驳回了他的上诉。然后他以五个理由上诉——根据今天T4上诉法院的一致决定，其中三个上诉成功。</p>
<p class="translated">法院裁定，SWP使用的法律框架和政策没有提供明确的指导，说明可以在哪里使用AFR定位系统，以及谁可以被列入观察名单——认为给予警察的酌处权过于广泛，不符合《欧洲人权公约》第8(2)条要求的标准。(因此，这一裁决加大了政府的压力，要求政府为警方使用面部识别技术制定一套规范。)</p>
<p class="translated">它还发现，鉴于SWP在不违反第8条的基础上撰写了该文件，进行了不充分的数据保护影响评估，这意味着该部队未能遵守英国的2018年数据保护法。</p>
<p class="translated">法院还判定警察部队错误地认为它遵守了PSED——因为它没有采取合理的措施来调查AFR定位软件是否包含基于种族或性别的偏见。(尽管法院指出，没有明确的证据表明该工具存在如此大的偏见。)</p>

<p class="translated">自从布里奇斯带来挑战以来，伦敦警察厅已经先行一步，开启了面部识别技术的实际应用——在今年年初打开了开关。尽管该系统是由一家私营公司(NEC)运营的。</p>
<p class="translated">在大都会警察局宣布的时候，<a href="https://web.archive.org/web/20221117192732/https://www.libertyhumanrights.org.uk/issue/mets-facial-recognition-rollout-is-dangerous-oppressive-and-completely-unjustified/"> Liberty </a>称此举是“危险的、压迫性的和完全不公正的”。在今天的一份新闻稿中，它表示，出于与SWP使用该技术类似的原因，气象局的部署可能是非法的——引用了该部队进行的一项审查。公民自由活动家、人工智能伦理学家和隐私专家都指责大都会博物馆忽视了一份<a href="https://web.archive.org/web/20221117192732/https://48ba3m4eh2bf2sksp43rq8kk-wpengine.netdna-ssl.com/wp-content/uploads/2019/07/London-Met-Police-Trial-of-Facial-Recognition-Tech-Report.pdf">独立报告</a>的调查结果，该报告认为大都会博物馆没有考虑人权影响。</p>
<p class="translated">自由律师梅根·古尔丁在一份声明中评论今天的上诉法院裁决时说:“这一判决是反对歧视性和压迫性面部识别的一次重大胜利。法院已经同意，这种反乌托邦式的监控工具侵犯了我们的权利，威胁了我们的自由。面部识别歧视有色人种，法院认为南威尔士警方没有尽到调查和避免歧视的责任，这是绝对正确的。</p>
<p class="translated">“政府是时候认识到这种侵入性技术的严重危险了。面部识别是对我们自由的威胁——它需要被禁止。”</p>
<p class="translated">在另一份支持声明中，布里奇斯补充道:“我很高兴法院已经同意面部识别明显威胁到我们的权利。这种技术是一种侵入性和歧视性的大规模监控工具。三年来，南威尔士警方一直在未经我们同意，通常在我们不知情的情况下，用它来对付成千上万的我们。我们都应该能够使用我们的公共空间，而不会受到压迫性的监视。”</p>
<p class="translated">然而，重要的是要注意，他没有赢得他的上诉的所有理由。</p>
<p class="translated">值得注意的是，法院认为，早先的法院进行了正确的权衡，以确定警察部队使用AFR是否是对人权法的适度干涉，当时它考虑了AFR定位的“实际和预期利益”与AFR部署对桥梁的影响——并决定利益可能很大，而个人影响很小，因此认为根据第8(2)条使用AFR是适度的。</p>
<p class="translated">因此，英国法院似乎没有完全关闭警方使用面部识别技术的大门。</p>
<p class="translated">事实上，这标志着个人权利的影响可以与“更好的”潜在利益相平衡——所以这项裁决看起来更像是在定义如何合法使用这种侵入性技术。(值得注意的是，SWP通过英国广播公司(BBC)表示，它“完全致力于”AFR的“谨慎发展和部署”。)</p>
<p class="translated">该裁决明确表示，任何此类部署都需要比SWP申请受到更严格的限制，以符合人权法。但它并没有说警方使用面部识别本质上是非法的。</p>
<p class="translated">部队也不能通过使用这种技术来忽视平等要求——根据裁决，他们有义务采取措施评估自动面部识别是否有偏见的风险。</p>
<p class="translated">鉴于<a href="https://web.archive.org/web/20221117192732/https://www.bbc.com/news/technology-52978191">已经发现这种系统存在偏见问题</a>，这可能会成为警方继续使用这种人工智能的更大障碍。</p>

			</div>

			</div>    
</body>
</html>