<html>
<head>
<title>Microsoft launches a deepfake detector tool ahead of US election • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">微软在美国大选前推出deepfake检测工具TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2020/09/02/microsoft-launches-a-deepfake-detector-tool-ahead-of-us-election/">https://web.archive.org/web/https://techcrunch.com/2020/09/02/microsoft-launches-a-deepfake-detector-tool-ahead-of-us-election/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">微软(Microsoft)推出了一款分析视频和静态照片以生成操纵分数的工具，从而为旨在识别合成媒体(又名deepfakes)的缓慢增长的技术增加了一员。</p>
<p class="translated">该工具名为Video Authenticator，提供了微软所说的媒体被人为操纵的“百分比机会或置信度”。</p>
<p class="translated">“在视频的情况下，它可以在视频播放时实时提供每一帧的百分比，”它在宣布该技术的<a href="https://web.archive.org/web/20230109085856/https://blogs.microsoft.com/on-the-issues/2020/09/01/disinformation-deepfakes-newsguard-video-authenticator/">博客帖子</a>中写道。“它的工作原理是检测深假和微妙的褪色或灰度元素的混合边界，人眼可能无法检测到这些元素。”</p>
<p class="translated">如果一条在线内容看起来是真实的，但“闻起来”是错误的，那么这很可能是一种试图冒充真实的高科技操纵——也许是出于恶意误导人们。</p>
<p class="translated">尽管许多深度假货是出于非常不同的目的——成为<a href="https://web.archive.org/web/20230109085856/https://techcrunch.com/2020/08/17/deepfake-video-app-reface-is-just-getting-started-on-shapeshifting-selfie-culture/">滑稽或娱乐</a>——脱离了上下文，这种合成媒体仍然可以在传播时呈现出自己的生命，这意味着它也可能最终欺骗不知情的观众。</p>
<p class="translated">虽然人工智能技术被用于生成逼真的深度假货，但利用技术识别视觉虚假信息仍然是一个难题——批判性思维仍然是识别高科技谎言的最佳工具。</p>
<p class="translated">尽管如此，技术人员仍在继续研究deep fake spotters——包括微软的最新产品。</p><p class="piano-inline-promo"/>
<p class="translated">尽管其博客帖子警告称，在人工智能推动的虚假信息军备竞赛中，该技术可能只会提供短暂的效用:“(deepfakes)是由能够继续学习的人工智能生成的，这一事实使得它们不可避免地会击败传统的检测技术。然而，从短期来看，比如即将到来的美国大选，先进的检测技术可以成为一个有用的工具，帮助有眼光的用户识别deepfakes。”</p>
<p class="translated"><a href="https://web.archive.org/web/20230109085856/https://techcrunch.com/2020/06/12/facebooks-deepfake-detection-challenge-yields-promising-early-results/">今年夏天</a>由脸书发起的一项开发deepfake探测器的竞赛提供了比猜测更好的结果——但只是在研究人员没有事先访问过的数据集的情况下。</p>
<p class="translated">与此同时，微软表示，其视频认证工具是使用来自<a href="https://web.archive.org/web/20230109085856/https://www.arxiv-vanity.com/papers/1901.08971/"> Face Forensic++的公共数据集创建的，并在</a><a href="https://web.archive.org/web/20230109085856/https://www.arxiv-vanity.com/papers/2006.07397/"> DeepFake检测挑战数据集</a>上进行测试，它指出，这是“训练和测试DeepFake检测技术的领先模型”。</p>
<p class="translated">它与旧金山的<a href="https://web.archive.org/web/20230109085856/https://rd2020.org/">人工智能基金会</a>合作，为今年参与民主进程的组织提供这一工具——包括新闻媒体和政治活动。</p>
<p class="translated">“视频认证器最初将仅通过RD2020 [Reality Defender 2020]提供，它将指导组织克服任何deepfake检测技术固有的限制和道德考虑。微软补充说:“有兴趣了解更多信息的活动和记者可以联系RD2020 <a href="https://web.archive.org/web/20230109085856/https://rd2020.org/#involved">这里</a>。</p>
<p class="translated">该工具是由其R&amp;D分部微软研究院(Microsoft Research)与其负责的人工智能团队和工程与研究委员会(Engineering and Research Committee)的人工智能、伦理和效果内部咨询机构合作开发的——作为微软正在实施的一项更广泛计划的一部分，该计划旨在捍卫民主免受虚假信息的威胁。</p>
<p class="translated">“我们预计生成合成媒体的方法将会越来越复杂，”它继续说道。“由于所有的人工智能检测方法都有失败率，我们必须了解并准备好应对通过检测方法的deepfakes。因此，从长远来看，我们必须寻求更强有力的方法来维护和认证新闻文章和其他媒体的真实性。如今，几乎没有什么工具可以帮助读者确信他们在网上看到的媒体来自可信的来源，并且没有被篡改。”</p>
<p class="translated">在后一方面，微软还宣布了一个系统，该系统将使内容制作者能够在内容在线传播时向保留在其元数据中的媒体添加数字哈希和证书，从而提供真实性的参考点。</p>
<p class="translated">该系统的第二个组件是一个阅读器工具，可以作为浏览器扩展来部署，用于检查证书和匹配哈希，以向查看者提供微软所谓的“高度准确性”，即特定内容是真实的/没有被更改。</p>
<p class="translated">认证还将向观众提供关于谁制作媒体的细节。</p>
<p class="translated">微软希望这个数字水印真实性系统将最终支持英国公共资助的广播公司BBC去年宣布的一项可信新闻倡议,特别是一个名为Project Origin的验证组件，该组件由BBC、CBC/Radio-Canada、微软和纽约时报组成的联盟领导。</p>
<p class="translated">它说，数字水印技术将由Project Origin测试，目的是将其发展成为一个可以广泛采用的标准。</p>
<p class="translated">“<a href="https://web.archive.org/web/20230109085856/https://www.bbc.co.uk/mediacentre/latestnews/2020/trusted-news-initiative">可信新闻倡议</a>，包括一系列出版商和社交媒体公司，也同意使用这项技术。在未来的几个月里，我们希望将这一领域的工作扩展到更多的技术公司、新闻出版商和社交媒体公司，”微软补充道。</p>
<p class="translated">虽然识别deepfakes的技术工作仍在继续，但其博客文章也强调了媒体素养的重要性——标志着与华盛顿大学、<a href="https://web.archive.org/web/20230109085856/https://sensity.ai/"> Sensity </a>和《今日美国》的合作，旨在促进美国大选前的批判性思维。</p>
<p class="translated">这一伙伴关系为美国选民推出了一个名为Deepfake的测验,用它的话说就是“了解合成媒体，发展关键的媒体素养技能，并了解合成媒体对民主的影响”。</p>
<p class="translated">根据博客帖子，互动测试将通过《今日美国》、微软和华盛顿大学拥有的网络和社交媒体资产进行分发，并通过社交媒体广告进行分发。</p>
<p class="translated">这家科技巨头还指出，它正在支持美国的一项公共服务公告(PSA)活动，鼓励人们在即将到来的选举之前，在社交媒体上分享或推广信息之前，进行“反思暂停”，并检查以确保信息来自一家声誉良好的新闻机构。</p>
<p class="translated">“PSA活动将帮助人们更好地理解错误信息和虚假信息对我们民主的危害，以及花时间识别、分享和消费可靠信息的重要性。该广告将于9月和10月在美国的广播电台播出。</p>
			</div>

			</div>    
</body>
</html>