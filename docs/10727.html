<html>
<head>
<title>Twitter and Zoom's algorithmic bias issues </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Twitter和Zoom的算法偏差问题</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2020/09/21/twitter-and-zoom-algorithmic-bias-issues/">https://web.archive.org/web/https://techcrunch.com/2020/09/21/twitter-and-zoom-algorithmic-bias-issues/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">Zoom和Twitter都发现自己在本周末因各自的算法偏见问题而受到抨击。在Zoom上，这是视频会议服务的虚拟背景的问题，在Twitter上，这是该网站的照片裁剪工具的问题。</p>
<p class="translated">事情开始于<a href="https://web.archive.org/web/20230311112312/https://twitter.com/colinmadland/status/1307111818981146626?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1307111822772842496%7Ctwgr%5Eshare_3&amp;ref_url=https%3A%2F%2Ftechcrunch.com%2Fwp-admin%2Fpost.php%3Fpost%3D2049660action%3Dedit">博士生科林·马德兰在</a>推特上发布了一名黑人教员对Zoom的问题。根据Madland的说法，每当该教员使用虚拟背景时，Zoom就会移除他的头部。</p>
<p class="translated">“我们已经直接联系用户调查这个问题，”Zoom发言人告诉TechCrunch。“我们致力于提供一个包容所有人的平台。”</p>

<p> </p>
<p class="translated">然而，在Twitter上讨论这个问题时，当Twitter的移动应用程序默认只在预览中显示白人男子马德兰的图像时，算法偏见的问题变得更加复杂。</p><p class="piano-inline-promo"/>
<p class="translated">Twitter的一位发言人在给TechCrunch的一份声明中说:“我们的团队在发货前确实测试了偏见，在我们的测试中没有发现种族或性别偏见的证据。”“但从这些例子中可以明显看出，我们需要做更多的分析。我们将继续分享我们学到的东西，我们采取的行动，并将开源我们的分析，以便其他人可以审查和复制。”</p>
<p class="translated">Twitter提到了首席设计官丹特利·戴维斯(Dantley Davis)的一条推文，他自己进行了一些实验。<a href="https://web.archive.org/web/20230311112312/https://twitter.com/dantley/status/1307414443580485632"> Davis断定Madland的胡须</a>影响了结果，所以他去除了他的胡须，黑人教员出现在裁剪后的预览中。<a href="https://web.archive.org/web/20230311112312/https://twitter.com/dantley/status/1307465700865241088">在后来的一条推文中，戴维斯说他“和其他人一样对此感到愤怒。不过，我有能力解决这个问题，我会解决的。”</a></p>
<p class="translated">Twitter还指出了卡内基梅隆大学首席科学家Vinay Prabhu的一项独立分析。在他的实验中，他试图了解“种植偏见是否真实”</p>

<p class="translated">作为对实验的回应，<a href="https://web.archive.org/web/20230311112312/https://twitter.com/paraga/status/1307491463639388160"> Twitter首席技术官帕拉格·阿格拉瓦尔说，解决裁剪偏见是否真实的问题是“一个非常重要的问题</a>”简而言之，Twitter有时会冒出黑人，有时不会。但Twitter这么做的事实，哪怕只有一次，也足以证明它有问题。</p>

<p class="translated">这也说明了糟糕算法盛行的更大问题。这些相同类型的算法导致了对黑人有偏见的逮捕和监禁。它们也是谷歌用来<a href="https://web.archive.org/web/20230311112312/https://www.theguardian.com/technology/2018/jan/12/google-racism-ban-gorilla-black-people">将黑人照片标记为大猩猩</a>和<a href="https://web.archive.org/web/20230311112312/https://www.vice.com/en_us/article/kb7zdw/microsoft-suspends-ai-chatbot-after-it-veers-into-white-supremacy-tay-and-you">微软的Tay bot用来成为白人至上主义者</a>的同一种算法。</p>

<p> </p>
			</div>

			</div>    
</body>
</html>