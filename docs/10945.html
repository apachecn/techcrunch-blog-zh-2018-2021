<html>
<head>
<title>Twitter may let users choose how to crop image previews after bias scrutiny • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Twitter 可能会让用户在偏见审查后选择如何裁剪图片预览</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2020/10/02/twitter-may-let-users-choose-how-to-crop-image-previews-after-bias-scrutiny/">https://web.archive.org/web/https://techcrunch.com/2020/10/02/twitter-may-let-users-choose-how-to-crop-image-previews-after-bias-scrutiny/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">在围绕其裁剪算法的<a href="https://web.archive.org/web/20221004202454/https://techcrunch.com/2020/09/21/twitter-and-zoom-algorithmic-bias-issues/">偏见争议之后，一个有趣的发展是，Twitter 表示正在考虑给予用户对推文预览外观的决策权，称其希望减少对基于机器学习的图像裁剪的依赖。</a></p>
<p class="translated">是的，你没看错。一家科技公司肯定地表示，自动化某些决策实际上可能不是明智之举——默认移除人类代理可能会产生伤害。</p>
<p class="translated">正如我们<a href="https://web.archive.org/web/20221004202454/https://techcrunch.com/2020/09/21/twitter-and-zoom-algorithmic-bias-issues/">上个月</a>报道的，在<a href="https://web.archive.org/web/20221004202454/https://twitter.com/colinmadland/status/1307111818981146626?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1307111822772842496%7Ctwgr%5Eshare_3&amp;ref_url=https%3A%2F%2Ftechcrunch.com%2Fwp-admin%2Fpost.php%3Fpost%3D2049660action%3Dedit">博士生科林·马德兰</a>注意到该算法在预览中只显示了他自己(白人男性)的图像——反复裁剪出一名黑人教员的图像后，微博平台发现其图像裁剪算法获得了批评性的关注。</p>
<p class="translated">具有讽刺意味的是，他一直在讨论 Zoom 的虚拟背景的类似偏见问题。</p>

<p class="translated">Twitter 当时对批评的回应是，它在发布机器学习模型之前测试了偏见，并“没有发现种族或性别偏见的证据”。但它补充道:“从这些例子中可以明显看出，我们需要做更多的分析。我们将继续分享我们学到的东西，我们采取的行动，并将开源我们的分析，以便其他人可以审查和复制。”</p><p class="piano-inline-promo"/>

<p class="translated">它现在已经在一篇博客文章<a href="https://web.archive.org/web/20221004202454/https://blog.twitter.com/official/en_us/topics/product/2020/transparency-image-cropping.html">中跟进了更多关于其测试过程的细节，并暗示未来可能不再使用预览作物的算法。</a></p>
<p class="translated">Twitter 也承认，它应该在推出算法裁剪工具之前公布其偏见测试过程的细节——以便其过程可以受到外部质疑。“这是一个疏忽，”它承认。</p>

<p class="translated">在解释该模型如何工作时，Twitter 写道:“图像裁剪系统依赖于显著性，它预测人们可能首先看哪里。对于我们的初始偏差分析，我们测试了两个人口统计组(白人-黑人、白人-印度人、白人-亚洲人和男性-女性)之间的成对偏好。在每次试验中，我们将两张人脸合成到同一张图像中，并对它们的顺序进行随机化，然后计算合成图像上的显著性图。然后，我们定位显著图的最大值，并记录它落在哪个人口统计类别上。我们对每一对人口统计类别重复了 200 次，并评估了偏好其中一个的频率。”</p>
<p class="translated">“虽然我们迄今为止的分析没有显示出种族或性别偏见，但我们认识到，我们自动裁剪照片的方式意味着存在潜在的伤害。当我们第一次设计和制造这个产品时，我们应该更好地预测这种可能性。它补充说:“我们目前正在进行额外的分析，以进一步加强我们的测试，致力于分享我们的发现，并探索开源我们的分析的方法，以便其他人可以帮助我们保持问责。”</p>
<p class="translated">关于放弃算法图像裁剪，让人类有发言权的可能性，Twitter 表示，它已经“开始探索不同的选择，看看在人们每天发推的广泛图像中，什么最有效”。</p>
<p class="translated">“我们希望给人们更多选择来裁剪图像，并预览他们在 tweet composer 中的样子，这可能有助于降低伤害的风险，”它补充说，这表明 tweet 预览未来可能包括用户的视觉控制。</p>
<p class="translated">这样的举动，而不是给平台注入“摩擦”(这可能是典型的技术人员对推文流程增加另一个步骤的担忧)，可以通过提供另一层围绕推文的细微差别，为 Twitter 用户开辟新的创意/音调可能性。比如让用户创建“复活节彩蛋”预览，故意隐藏一个关键的视觉细节，直到有人点击进入；或者关注某个特定元素来强调推文中的某个观点。</p>
<p class="translated">鉴于用消息应用 WhatsApp 的预览裁剪格式播放的笑话“一半一半”图像的流行程度——这需要点击以可预测地扩展视图——如果它为用户提供正确的工具，很容易看到类似的视觉笑话和迷因在 Twitter 上被激发起来。</p>
<p class="translated">底线是给人类更多的代理意味着你在邀请创造力— <em>和</em>让多样性超越偏见。这应该是双赢的。所以很高兴看到 Twitter 考虑暂停它的一个算法。(我们敢不敢建议，该平台还会密切关注和批判性地看待围绕“热门推文”、“趋势推文”的<a href="https://web.archive.org/web/20221004202454/https://help.twitter.com/en/using-twitter/twitter-timeline">算法工作，以及其算法有时选择未经请求就注入用户时间表的“流行/相关”内容，所有这些都可能产生有害的自助餐。)</a></p>
<p class="translated">回到图像裁剪，Twitter 表示，作为一项通用规则，它将致力于“‘所见即所得’的设计原则”——也就是，“你在 tweet composer 中看到的照片在 tweet 中的样子”——同时警告称，可能仍会有一些例外，比如非标准大小的图像。</p>
<p class="translated">在这种情况下，它表示将对如何呈现这些图像进行实验，旨在“不失去创作者预期的焦点或损害照片的完整性”。再说一次，公开展示任何算法工作都是有好处的。</p>

			</div>

			</div>    
</body>
</html>