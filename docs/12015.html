<html>
<head>
<title>WaveOne aims to make video AI-native and turn streaming upside down </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">WaveOne 的目标是让视频人工智能化，颠覆流媒体</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2020/12/01/waveone-aims-to-make-video-ai-native-and-turn-streaming-upside-down/">https://web.archive.org/web/https://techcrunch.com/2020/12/01/waveone-aims-to-make-video-ai-native-and-turn-streaming-upside-down/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">很久很久以来，视频都是以同样的方式工作的。由于其独特的品质，视频在很大程度上不受颠覆一个又一个行业的机器学习爆炸的影响。WaveOne 希望通过采用几十年的视频编解码器范式并使它们由人工智能驱动来改变这种情况，同时以某种方式避免潜在编解码器革命家和“人工智能驱动”初创公司经常陷入的陷阱。</p>
<p class="translated">这家初创公司直到最近还局限于在论文和演示中展示其成果，但随着最近筹集到 650 万美元的种子资金，他们准备开始测试和部署他们的实际产品。这不是一个小众领域:视频压缩对某些人来说可能有点陌生，但毫无疑问，它已经成为现代互联网最重要的过程之一。</p>
<p class="translated">从数字视频首次成为可能的旧时代开始，它就是这样工作的。开发人员创建了一个压缩和解压缩视频的标准算法，一个编解码器，它可以很容易地在常见的计算平台上分发和运行。这是 MPEG-2、H.264 之类的东西。压缩视频的繁重工作可以由内容提供商和服务器完成，而相对较轻的解压缩工作则在最终用户的机器上完成。</p>
<p class="translated">这种方法非常有效，对编解码器(允许更有效的压缩)的改进导致了像 YouTube 这样的网站的出现。如果视频比现在大 10 倍，YouTube 永远也不能启动。另一个重大变化是开始依赖于所述编解码器的硬件加速——你的计算机或 GPU 可能有一个内置编解码器的实际芯片，准备以比电话中普通通用 CPU 快得多的速度执行解压缩任务。只有一个问题:当你得到一个新的编解码器，你需要新的硬件。</p>

<p class="translated">但考虑一下这个:许多新手机都装有一个为运行机器学习模型而设计的芯片，像编解码器一样可以加速，但与它们不同的是，硬件不是为模型定制的。那么，我们为什么不使用这种 ML 优化的视频芯片呢？嗯，这正是 WaveOne 打算做的。</p>
<p class="translated">我应该说，我最初与 WaveOne 的联合创始人、首席执行官卢博米尔·布尔德夫和首席技术官柳文欢·里佩尔进行了交谈，尽管他们的背景令人印象深刻，但他们的态度非常怀疑。我们已经看到编解码器公司来来去去，但技术行业已经围绕少数格式和标准联合起来，以令人痛苦的缓慢方式进行修订。例如，H.265 于 2013 年推出，但多年后，它的前身 H.264 才刚刚开始普及。它更像 3G、4G、5G 系统，而不是 7、7.1 等版本。因此，更小的选择，甚至是免费和开源的更好的选择，往往会被行业标准所压制。</p><p class="piano-inline-promo"/>
<p class="translated">编解码器的这一记录，加上初创公司喜欢描述几乎所有东西都是“人工智能驱动的”这一事实，让我期待一些最好的误导，最坏的欺骗。但我不仅仅是惊喜:事实上，WaveOne 是一种在回顾中似乎显而易见的东西，似乎具有先发优势。</p>
<p class="translated">Rippel 和 Bourdev 澄清的第一件事是<a href="https://web.archive.org/web/20230407163500/http://www.wave.one/vision-of-video">人工智能实际上在这里发挥了作用</a>。虽然像 H.265 这样的编解码器并不愚蠢——它们在许多方面都非常先进——但它们也并不完全智能。一般来说，他们可以告诉在编码颜色或细节时在哪里放更多的比特，但他们不能，例如，告诉他们在镜头中哪里有一张脸应该得到额外的爱，或者一个标志或树木可以用特殊的方式来节省时间。</p>
<p class="translated">但是人脸和场景检测是计算机视觉中实际解决的问题。为什么视频编解码器不应该理解有一张脸，然后对它投入相应数量的资源？这是一个非常好的问题。答案是编解码器不够灵活。他们不接受这种输入。也许它们会在 H.266 中出现，几年后它会在高端设备上得到支持。</p>
<p class="translated">那么你现在会怎么做呢？嗯，通过编写一个运行在人工智能加速器上的视频压缩和解压缩算法，许多手机和计算机已经或即将拥有，并从一开始就在其中集成场景和对象检测。就像<a href="https://web.archive.org/web/20230407163500/https://techcrunch.com/2020/08/05/krisp-snags-5m-a-round-as-demand-grows-for-its-voice-isolating-algorithm/"> Krisp.ai 在没有超复杂频谱分析的情况下理解什么是声音并将其分离出来</a>一样，ai 可以用视觉数据以令人难以置信的速度做出这样的决定，并将其传递到实际的视频压缩部分。</p>
<p/><div id="attachment_2080732" class="wp-caption aligncenter"><a href="https://web.archive.org/web/20230407163500/https://techcrunch.com/wp-content/uploads/2020/11/waveone-faces.jpg"><img aria-describedby="caption-attachment-2080732" decoding="async" class="size-full wp-image-2080732" src="../Images/403bdb6b1ed4d7f1ce7e36343b583ac1.png" alt="" srcset="https://web.archive.org/web/20230407163500im_/https://techcrunch.com/wp-content/uploads/2020/11/waveone-faces.jpg 1281w, https://web.archive.org/web/20230407163500im_/https://techcrunch.com/wp-content/uploads/2020/11/waveone-faces.jpg?resize=150,124 150w, https://web.archive.org/web/20230407163500im_/https://techcrunch.com/wp-content/uploads/2020/11/waveone-faces.jpg?resize=300,248 300w, https://web.archive.org/web/20230407163500im_/https://techcrunch.com/wp-content/uploads/2020/11/waveone-faces.jpg?resize=768,635 768w, https://web.archive.org/web/20230407163500im_/https://techcrunch.com/wp-content/uploads/2020/11/waveone-faces.jpg?resize=680,562 680w, https://web.archive.org/web/20230407163500im_/https://techcrunch.com/wp-content/uploads/2020/11/waveone-faces.jpg?resize=1200,992 1200w, https://web.archive.org/web/20230407163500im_/https://techcrunch.com/wp-content/uploads/2020/11/waveone-faces.jpg?resize=50,41 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230407163500im_/https://techcrunch.com/wp-content/uploads/2020/11/waveone-faces.jpg"/></a><p id="caption-attachment-2080732" class="wp-caption-text translated"><strong>形象学分:</strong> WaveOne</p></div>
<p class="translated">可变和智能的数据分配意味着压缩过程可以非常有效，而不会牺牲图像质量。WaveOne 声称可以将文件大小减少一半，并在更复杂的场景中获得更好的增益。当你提供几亿次视频时(或者同时提供给一百万人)，即使是百分之一的分数也会增加，更不用说这么大的收益了。带宽不像以前那么贵了，但仍然不是免费的。</p>
<p class="translated">理解图像(或被告知)也让编解码器看到它是什么样的内容；当然，如果可能的话，视频通话应该优先考虑面部，但游戏流可能希望优先考虑小细节，而动画则需要另一种方法来最大限度地减少其大型单色区域中的伪像。这一切都可以通过人工智能驱动的压缩方案来完成。</p>
<p class="translated">除了消费技术之外，还有其他含义:在组件之间或向中央服务器发送视频的自动驾驶汽车，可以节省时间，提高视频质量，因为它可以专注于自主系统指定的重要事物——车辆、行人、动物——而不是在毫无特色的天空、远处的树木等等上浪费时间和比特。</p>
<p class="translated">内容感知编码和解码可能是 WaveOne 声称提供的最通用和最容易掌握的优势，但 Bourdev 也指出，这种方法对带宽问题的干扰更具抵抗力。这是传统视频编解码器的另一个缺点，丢失几个比特会影响整个操作，这就是为什么会出现冻结帧和故障。但是基于 ML 的解码可以很容易地根据它拥有的任何比特做出“最佳猜测”，所以当你的带宽突然受到限制时，你不会冻结，只是在持续时间内变得不那么详细。</p>
<p/><div id="attachment_2080733" class="wp-caption alignright"><a href="https://web.archive.org/web/20230407163500/https://techcrunch.com/wp-content/uploads/2020/11/waveone-comparison.jpg"><img aria-describedby="caption-attachment-2080733" decoding="async" loading="lazy" class="wp-image-2080733" src="../Images/9d684495fe0209c6d362d3d4f8ee304c.png" alt="" srcset="https://web.archive.org/web/20230407163500im_/https://techcrunch.com/wp-content/uploads/2020/11/waveone-comparison.jpg 1000w, https://web.archive.org/web/20230407163500im_/https://techcrunch.com/wp-content/uploads/2020/11/waveone-comparison.jpg?resize=133,150 133w, https://web.archive.org/web/20230407163500im_/https://techcrunch.com/wp-content/uploads/2020/11/waveone-comparison.jpg?resize=267,300 267w, https://web.archive.org/web/20230407163500im_/https://techcrunch.com/wp-content/uploads/2020/11/waveone-comparison.jpg?resize=768,863 768w, https://web.archive.org/web/20230407163500im_/https://techcrunch.com/wp-content/uploads/2020/11/waveone-comparison.jpg?resize=605,680 605w, https://web.archive.org/web/20230407163500im_/https://techcrunch.com/wp-content/uploads/2020/11/waveone-comparison.jpg?resize=44,50 44w" sizes="(max-width: 450px) 100vw, 450px" data-original-src="https://web.archive.org/web/20230407163500im_/https://techcrunch.com/wp-content/uploads/2020/11/waveone-comparison.jpg"/></a><p id="caption-attachment-2080733" class="wp-caption-text translated">不同编解码器压缩同一帧的示例。</p></div>
<p class="translated">这些好处听起来很棒，但和以前一样，问题不是“我们能改善现状吗？”(显然我们可以)但是“我们可以扩展这些改进吗？”</p>
<p class="translated">Bourdev 承认:“这条路上到处都是创建酷的新编解码器的失败尝试。“部分原因是硬件加速；即使你想出了世界上最好的编解码器，如果你没有运行它的硬件加速器，祝你好运。你不仅需要更好的算法，还需要能够在边缘和云中的各种设备上以可扩展的方式运行它们。”</p>
<p class="translated">这就是为什么最新一代设备上的特殊人工智能核心如此重要。这是可以在几毫秒内适应新用途的硬件加速。WaveOne 碰巧多年来一直致力于在这些内核上运行的以视频为重点的机器学习，做 H.26X 加速器多年来一直在做的工作，但速度更快，灵活性更大。</p>
<p class="translated">当然，还有“标准”的问题。很有可能有人会签署一家公司的专有视频压缩方法吗？好吧，总得有人去做！毕竟，标准不会铭刻在石碑上。正如 Bourdev 和 Rippel 解释的那样，他们实际上是在使用标准——只是不是我们所认为的方式。</p>
<p class="translated">以前，视频中的“标准”意味着遵循严格定义的软件方法，以便您的应用程序或设备能够高效、正确地处理兼容标准的视频。但这不是唯一的标准。WaveOne 不是一个简单的方法，而是一个符合 ML 和部署标准的实现。</p>
<p class="translated">他们正在构建一个平台，以兼容所有主要的 ML 发行和开发发行商，如 TensorFlow、ONNX、苹果的 CoreML 等。与此同时，实际上为编码和解码视频开发的模型将像任何其他加速软件一样在边缘或云设备上运行:在 AWS 或 Azure 上部署它，用 ARM 或英特尔计算模块在本地运行它，等等。</p>
<p class="translated">这感觉像是 WaveOne 可能正在做一件符合所有大型 b2b 事件的事情:它无形中为客户改善了事情，无需修改就可以在现有或即将推出的硬件上运行，立即节省成本(无论如何都是潜在的)，但可以投资以增加价值。</p>
<p class="translated">也许这就是为什么他们设法吸引了这么大一轮种子资金:650 万美元，由科斯拉风险投资公司(Khosla Ventures)牵头，Vela Partners 和孵化基金各 100 万美元，加上 Omega Venture Partners 的 65 万美元和 Blue Ivy 的 35 万美元。</p>
<p class="translated">目前，WaveOne 处于预 alpha 阶段，已经令人满意地展示了这项技术，但还没有制造出全面的产品。Rippel 说，种子期是为了降低技术风险，虽然还有许多 R&amp;D 有待完成，但他们已经证明核心产品是可行的——接下来是构建基础设施和 API 层，这相当于公司的一个完全不同的阶段。他说，即便如此，他们希望在筹集更多资金之前完成测试，并争取一些客户。</p>
<p class="translated">视频行业的未来可能不会像过去几十年那样，这可能是一件非常好的事情。毫无疑问，随着 WaveOne 从实验室走向产品，我们将会听到更多关于它的消息。</p>
			</div>

			</div>    
</body>
</html>