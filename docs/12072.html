<html>
<head>
<title>MLCommons debuts with public 86,000-hour speech data set for AI researchers </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">MLCommons 首次为人工智能研究人员提供 86，000 小时的公共语音数据集</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2020/12/03/mlcommons-debuts-first-public-database-for-ai-researchers-with-86000-hours-of-speech/">https://web.archive.org/web/https://techcrunch.com/2020/12/03/mlcommons-debuts-first-public-database-for-ai-researchers-with-86000-hours-of-speech/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">如果你想制造一个机器学习系统，你需要它的数据，但这些数据并不总是容易得到的。MLCommons 旨在联合不同的公司和组织，为人工智能训练创建大型公共数据库，以便世界各地的研究人员可以在更高的水平上合作，并通过这样做来推动这个新兴领域的整体发展。它的第一项努力，人民的语音数据集，是其他同类数据集的许多倍，并且旨在更加多样化。</p>
<p class="translated">MLCommons 是一个与<a href="https://web.archive.org/web/20230224073640/https://www.mlperf.org/"> MLPerf </a>相关的新非营利组织，它已经收集了数十家公司和学术机构的投入，以创建机器学习性能的行业标准基准。这一努力已经取得了成功，但在这个过程中，团队遇到了每个人都可以使用的开放数据集的匮乏。</p>
<p class="translated">如果你想对谷歌模型和亚马逊模型，或者加州大学伯克利分校模型进行比较，它们真的应该使用相同的测试数据。对于计算机视觉，最广泛的数据集之一是 ImageNet，它被所有最有影响力的论文和专家使用和引用。但是，没有这样的数据集，比如说，语音到文本的准确性。</p>
<p class="translated">“基准让人们以明智、可衡量的方式谈论进展。事实证明，如果目标是推动行业向前发展，我们需要可以使用的数据集——但由于许可原因，其中许多数据集很难使用，或者不是最先进的，”MLCommons 联合创始人兼执行董事大卫·坎特说。</p>

<p class="translated">当然，大公司也有自己庞大的语音数据集，但它们是专有的，可能受到法律限制，不能被他人使用。也有公共数据集，但只有几千个小时，它们的效用是有限的——为了在今天具有竞争力，人们需要更多。</p>
<p class="translated">“构建大型数据集很棒，因为我们可以创建基准，但它也为每个人向前推进了一步。坎特说:“我们无法与内部可用的产品竞争，但我们可以在弥合这一差距方面大有作为。”。MLCommons 是他们成立的组织，旨在创建和争论所需的数据和连接。</p><p class="piano-inline-promo"/>
<p class="translated">人们的语音数据集是从各种来源收集的，其中约 65，000 小时来自英语有声读物，文本与音频保持一致。此外，还有大约 15000 个小时来自网络，使用不同的声学、扬声器和演讲风格(例如对话式而非叙述式)。此外，1500 小时的英语音频来自维基百科，然后混合了 GPT-2 生成的 5000 小时的文本合成语音(“有点像蛇在吃自己的尾巴，”坎特开玩笑说)。总共有 59 种语言以某种方式被表达出来，尽管你可以看出大部分是英语。</p>
<p class="translated">虽然多元化是我们的目标——你不能从英语数据中构建一个葡萄牙语的虚拟助手——但为当前目的建立一个基线也很重要。一万个小时足够建立一个像样的语音转文本模型吗？或者有了 20，000 个可用资源，开发会变得更容易、更快或更有效吗？如果你既想精通美式英语，又想得体地使用印度和英国口音，该怎么办？那些你需要多少<em>？</em></p>

<p class="translated">对数据集的普遍共识是“越大越好”，谷歌和苹果等公司的工作时间远远超过几千小时。因此数据集的第一次迭代中的 86，000 小时。这绝对是许多版本中的第一个，以后的版本会扩展到更多的语言和口音。</p>
<p class="translated">“一旦我们证实我们可以提供价值，我们就会发布并诚实地对待它的状态，”MLCommons 的另一位联合创始人彼得·马特森解释道，他目前是谷歌机器学习度量小组的负责人。“我们还需要学习如何量化多样性的概念。业界希望如此；我们需要更多的数据集构建专业知识——支持这样一个组织对每个人来说都有巨大的投资回报。”</p>
<p class="translated">该组织还希望通过 MLCube 刺激该领域的共享和创新，ml cube 是一种来回传递模型的新标准，它消除了这一过程中的一些猜测和劳动。尽管机器学习是科技领域最活跃的研发领域之一，但将你的人工智能模型交给其他人来测试、运行或修改并不像它应该的那样简单。</p>
<p class="translated">他们关于 MLCube 的想法是模型的包装器，描述和标准化一些事情，如依赖性、输入和输出格式、托管等。人工智能可能从根本上来说是复杂的，但它以及创建和测试它的工具仍处于起步阶段。</p>
<p class="translated">该数据集现在或很快就可以从<a href="https://web.archive.org/web/20230224073640/https://mlcommons.org/"> MLCommons 的网站</a>获得，在 CC-BY 许可下，允许商业使用；还将发布一些在布景上训练的参考模型。</p>

			</div>

			</div>    
</body>
</html>