<html>
<head>
<title>Battling algorithmic bias at TC Sessions: Justice </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在TC会议上对抗算法偏见:公正</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2021/01/27/battling-algorithmic-bias-at-tc-sessions-justice/">https://web.archive.org/web/https://techcrunch.com/2021/01/27/battling-algorithmic-bias-at-tc-sessions-justice/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">在3月3日举行的<a href="https://web.archive.org/web/20230306232921/https://techcrunch.com/events/tc-sessions-justice-2021/?utm_medium=editpost&amp;utm_campaign=justice2021&amp;utm_content=algorithmbias&amp;utm_source=tc&amp;promo=algorithmbiaspost&amp;display=TRUE"> TC Sessions: Justice </a>上，我们将深入探讨数据歧视、算法偏见以及如何确保一个更加公正的未来，因为科技公司更加依赖自动化流程来做出决策。</p>
<p id="speakable-summary" class="translated">算法是计算机为了解决问题并对特定的行动过程做出决策而遵循的一套规则。但算法有一个固有的问题，它从最基础的层面开始，并在整个适应过程中持续存在:这些基于机器的决策者中存在人类偏见。</p>
<p class="translated">由不良数据驱动的算法导致了对黑人有偏见的逮捕和监禁。它们也是谷歌用来<a href="https://web.archive.org/web/20230306232921/https://www.theguardian.com/technology/2018/jan/12/google-racism-ban-gorilla-black-people">将黑人照片标记为大猩猩</a>和<a href="https://web.archive.org/web/20230306232921/https://www.vice.com/en_us/article/kb7zdw/microsoft-suspends-ai-chatbot-after-it-veers-into-white-supremacy-tay-and-you">微软的Tay bot用来成为白人至上主义者</a>的同一种算法。</p>
<p class="translated">在<a href="https://web.archive.org/web/20230306232921/https://techcrunch.com/events/tc-sessions-justice-2021/?utm_medium=editpost&amp;utm_campaign=justice2021&amp;utm_content=algorithmbias&amp;utm_source=tc&amp;promo=algorithmbiaspost&amp;display=TRUE"> TC Sessions: Justice </a>中，我们将听取该领域三位专家的观点。让我们见见他们。</p>
<p class="translated"><strong>萨菲亚·团结博士诺贝尔</strong></p>
<p/>
<p class="translated">加州大学洛杉矶分校副教授、南加州大学教授、《压迫算法:搜索引擎如何强化种族主义》一书的作者诺布尔因其对种族和技术交叉的分析而闻名。</p><p class="piano-inline-promo"/>
<p class="translated">在她前面提到的书中，Noble讨论了算法产生偏见和延续种族主义的方式。她称之为数据歧视。</p>
<p class="translated">“我认为人们被编码的方式，尤其是在搜索引擎中被编码的方式，可能会带来不可思议的伤害，”<a href="https://web.archive.org/web/20230306232921/https://techcrunch.com/2018/01/27/ctrlt-podcast-artificial-intelligence-may-become-a-human-rights-issue/">诺布尔在2018年TC Mixtape的一集上告诉我，该节目以前被称为CTRL+T </a>。“这就是我所说的数据歧视的部分含义。”</p>
<p class="translated"><strong>穆塔莱·恩孔德</strong></p>
<p/><div id="attachment_2100148" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2100148" decoding="async" loading="lazy" class="size-large wp-image-2100148" src="../Images/8b7e61e5695ed4735b0eea1a139d9429.png" alt="" srcset="https://web.archive.org/web/20230306232921im_/https://techcrunch.com/wp-content/uploads/2021/01/76719636.jpeg 1800w, https://web.archive.org/web/20230306232921im_/https://techcrunch.com/wp-content/uploads/2021/01/76719636.jpeg?resize=150,150 150w, https://web.archive.org/web/20230306232921im_/https://techcrunch.com/wp-content/uploads/2021/01/76719636.jpeg?resize=300,300 300w, https://web.archive.org/web/20230306232921im_/https://techcrunch.com/wp-content/uploads/2021/01/76719636.jpeg?resize=768,768 768w, https://web.archive.org/web/20230306232921im_/https://techcrunch.com/wp-content/uploads/2021/01/76719636.jpeg?resize=680,680 680w, https://web.archive.org/web/20230306232921im_/https://techcrunch.com/wp-content/uploads/2021/01/76719636.jpeg?resize=1536,1536 1536w, https://web.archive.org/web/20230306232921im_/https://techcrunch.com/wp-content/uploads/2021/01/76719636.jpeg?resize=1200,1200 1200w, https://web.archive.org/web/20230306232921im_/https://techcrunch.com/wp-content/uploads/2021/01/76719636.jpeg?resize=32,32 32w, https://web.archive.org/web/20230306232921im_/https://techcrunch.com/wp-content/uploads/2021/01/76719636.jpeg?resize=50,50 50w, https://web.archive.org/web/20230306232921im_/https://techcrunch.com/wp-content/uploads/2021/01/76719636.jpeg?resize=64,64 64w, https://web.archive.org/web/20230306232921im_/https://techcrunch.com/wp-content/uploads/2021/01/76719636.jpeg?resize=96,96 96w, https://web.archive.org/web/20230306232921im_/https://techcrunch.com/wp-content/uploads/2021/01/76719636.jpeg?resize=128,128 128w" sizes="(max-width: 680px) 100vw, 680px" data-original-src="https://web.archive.org/web/20230306232921im_/https://techcrunch.com/wp-content/uploads/2021/01/76719636.jpeg?w=680"/><p id="caption-attachment-2100148" class="wp-caption-text translated"><strong>图片来源:</strong>通过穆塔莱·恩孔德</p></div>
<p class="translated">Nkonde认为，为了创造公正的技术未来，明确地说出种族是很重要的。在她的研究论文“自动化反黑人:纽约布鲁克林的面部识别”中，Nkonde研究了面部识别的使用，纽约黑人监视的历史，并提出了未来监管面部识别的潜在方法。</p>
<p class="translated">Nkonde也是联合国种族和人工智能顾问，目前正在与大赦国际合作，推动全球禁止面部识别技术。</p>
<p class="translated"><strong>哈本·吉尔马</strong></p>
<p/><div id="attachment_1912589" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-1912589" decoding="async" loading="lazy" class="size-large wp-image-1912589" src="../Images/4a48babc8cfd5c72fa25f01455276b38.png" alt="Woman walking with guide dog." srcset="https://web.archive.org/web/20230306232921im_/https://techcrunch.com/wp-content/uploads/2019/11/Mylo-Haben-Walking-e1573846286198.jpg 2000w, https://web.archive.org/web/20230306232921im_/https://techcrunch.com/wp-content/uploads/2019/11/Mylo-Haben-Walking-e1573846286198.jpg?resize=150,113 150w, https://web.archive.org/web/20230306232921im_/https://techcrunch.com/wp-content/uploads/2019/11/Mylo-Haben-Walking-e1573846286198.jpg?resize=300,225 300w, https://web.archive.org/web/20230306232921im_/https://techcrunch.com/wp-content/uploads/2019/11/Mylo-Haben-Walking-e1573846286198.jpg?resize=768,576 768w, https://web.archive.org/web/20230306232921im_/https://techcrunch.com/wp-content/uploads/2019/11/Mylo-Haben-Walking-e1573846286198.jpg?resize=680,510 680w, https://web.archive.org/web/20230306232921im_/https://techcrunch.com/wp-content/uploads/2019/11/Mylo-Haben-Walking-e1573846286198.jpg?resize=1536,1152 1536w, https://web.archive.org/web/20230306232921im_/https://techcrunch.com/wp-content/uploads/2019/11/Mylo-Haben-Walking-e1573846286198.jpg?resize=1200,900 1200w, https://web.archive.org/web/20230306232921im_/https://techcrunch.com/wp-content/uploads/2019/11/Mylo-Haben-Walking-e1573846286198.jpg?resize=50,38 50w" sizes="(max-width: 680px) 100vw, 680px" data-original-src="https://web.archive.org/web/20230306232921im_/https://techcrunch.com/wp-content/uploads/2019/11/Mylo-Haben-Walking-e1573846286198.jpg?w=680"/><p id="caption-attachment-1912589" class="wp-caption-text translated"><strong>图片来源:</strong>哈本·吉尔马提供</p></div>
<p class="translated">作为回忆录《哈本:征服哈佛法学院的盲女》的作者和人权律师，吉尔马专注于推进残疾人司法。</p>
<p class="translated">在上个月的Sight Tech Global 上，Girma谈到了围绕算法偏见的讨论如何变得有些正常化，因为它与种族有关，但这些对话经常排除算法对残疾人的影响。Girma告诉我，当谈到机器人时，例如，开发者和设计师之间缺乏算法偏见的话题。</p>
<p class="translated">“不要责怪机器人，”她说。“正是制造机器人的人植入了他们的偏见，导致了能干主义和种族主义在我们的社会中继续存在。如果设计师与使用我们人行道的残疾人和使用这些送货应用程序的盲人合作制造机器人，那么机器人和送货应用程序将完全无障碍。因此，我们需要设计服务的人与我们进行对话和合作。”</p>
<p class="translated">如果你已经看到这里，你可能想知道如何参加。嗯，你可以在这里只花5美元买到票。</p>
<p>	
	
	</p>
<p> </p>
			</div>

			</div>    
</body>
</html>