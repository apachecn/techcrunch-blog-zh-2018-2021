<html>
<head>
<title>MEPs call for European AI rules to ban biometric surveillance in public </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">欧洲议会议员呼吁欧洲人工智能规则禁止公共场合的生物识别监控</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2021/04/15/meps-call-for-european-ai-rules-to-ban-biometric-surveillance-in-public/">https://web.archive.org/web/https://techcrunch.com/2021/04/15/meps-call-for-european-ai-rules-to-ban-biometric-surveillance-in-public/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">欧洲议会(European parliament)一个由 40 名欧洲议员组成的跨党派团体呼吁欧盟委员会加强一项即将出台的人工智能立法提案，包括彻底禁止在公共场所使用面部识别和其他形式的生物识别监控。</p>
<p class="translated">他们还敦促欧盟立法者禁止自动识别人们的敏感特征(如性别、性行为、种族/族裔、健康状况和残疾)——警告说，这种人工智能推动的做法带来了太大的权利风险，并可能加剧歧视。</p>
<p class="translated">预计该委员会将于下周提交其监管人工智能“高风险”应用的框架提案——但一份草案副本于本周泄露(通过<a href="https://web.archive.org/web/20230328072736/https://pro.politico.eu/news/european-commission-high-risk-ai-ban-tech">政治</a>)。而且，正如我们<a href="https://web.archive.org/web/20230328072736/https://techcrunch.com/2021/04/14/eu-plan-for-risk-based-ai-rules-to-set-fines-as-high-as-4-of-global-turnover-per-leaked-draft/">早些时候</a>报道的那样，这份泄露的草案并不包括禁止在公共场所使用面部识别或类似的生物识别远程识别技术，尽管承认公众对这个问题的关注。</p>
<p class="translated">“公共场所的生物识别大规模监控技术正受到广泛批评，因为它错误地报告了大量无辜公民，系统地歧视代表不足的群体，并对自由和多元化的社会产生了寒蝉效应。这就是为什么需要一项禁令，”欧洲议会议员们现在在给委员会的一封<a href="https://web.archive.org/web/20230328072736/https://www.patrick-breyer.de/wp-content/uploads/2021/04/MEP-Letter-to-the-Commission-on-Artificial-Intelligence-and-Biometric-Surveillance.pdf">信</a>中写道，这封信他们也公开了。</p>
<p class="translated">他们继续通过自动推断人们的敏感特征来警告歧视的风险——例如在预测性警务或通过生物特征不加区分地监控和跟踪人口的应用中。</p>

<p class="translated">“这可能导致伤害，包括侵犯隐私权和数据保护权；压制言论自由；使得揭露腐败更加困难；并对每个人的自主权、尊严和自我表达产生寒蝉效应——这尤其会严重伤害 LGBTQI+社区、有色人种和其他受歧视群体，”欧洲议会议员写道，呼吁欧盟委员会修改人工智能提案，宣布这种做法为非法，以保护欧盟公民的权利和面临更高歧视风险(因此来自人工智能强化的歧视性工具的风险也更高)的社区的权利。</p><p class="piano-inline-promo"/>
<p class="translated">“人工智能提案提供了一个受欢迎的机会，来禁止自动识别性别、性行为、种族/族裔、残疾和任何其他敏感和受保护的特征，”他们补充说。</p>
<p class="translated">泄露的委员会提案草案确实解决了不分青红皂白的大规模监控——提议禁止这种做法，并宣布通用社会信用评分系统为非法。</p>
<p class="translated">然而，欧洲议会议员希望立法者更进一步——警告泄露的草案措辞中的弱点，并建议进行修改，以确保拟议的禁令涵盖“所有无目标和不分青红皂白的大规模监控，无论有多少人暴露在该系统中”。</p>
<p class="translated">他们还对禁止公共当局(或为其工作的商业实体)进行大规模监控的提议表示震惊，警告说这有可能偏离现有的欧盟立法和欧盟最高法院在这一领域的解释。</p>
<p class="translated">他们写道:“我们强烈抗议拟议的第四条第二款，该款将免除公共当局甚至代表公共当局行事的私人行为者‘为了维护公共安全’”。“公共安全正是大规模监控的正当理由，是它实际相关的地方，也是法院一贯废除关于不加区别地批量处理个人数据的立法(如数据保留指令)的地方。这种分割需要删除。”</p>
<p class="translated">“这第二段甚至可以被解释为偏离其他二级立法，法院迄今为止解释为禁止大规模监控，”他们继续说。“拟议的人工智能法规需要非常明确地表明，其要求是对数据保护法律规定的补充，而不是取代。泄露的草案中没有这种明确性。”</p>
<p class="translated">欧盟委员会已被联系，要求就欧洲议会议员的呼吁置评，但不太可能在官方公布人工智能法规草案之前置评——预计该草案将于下周中期公布。</p>
<p class="translated">从现在到那时，人工智能提案是否会经历任何重大修改，还有待观察。但欧洲议会议员迅速发出警告，基本权利必须并将成为共同立法辩论的一个关键特征——如果规则不正面解决不道德的技术，立法者声称的确保“值得信赖”的人工智能的框架将看起来不可信。</p>



			</div>

			</div>    
</body>
</html>