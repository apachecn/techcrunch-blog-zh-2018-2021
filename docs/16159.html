<html>
<head>
<title>Ban biometric surveillance in public to safeguard rights, urge EU bodies • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">禁止在公共场合进行生物识别监控以维护权利，敦促欧盟机构 TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/http://techcrunch.com/2021/06/21/ban-biometric-surveillance-in-public-to-safeguard-rights-urge-eu-bodies/">https://web.archive.org/web/http://techcrunch.com/2021/06/21/ban-biometric-surveillance-in-public-to-safeguard-rights-urge-eu-bodies/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">欧盟机构进一步呼吁禁止公共场合的生物识别监控。</p>
<p class="translated">在今天发布的一份联合意见中，欧洲数据保护委员会(EDPB)和欧洲数据保护监管人(EDPS)沃伊切赫·维沃斯基呼吁欧盟关于使用人工智能技术的法规草案比委员会 4 月份在 T2 提出的提案更进一步，敦促计划中的立法应该得到加强，以包括“全面禁止在公共场所使用人工智能自动识别人类特征，如识别人脸、步态、指纹、DNA、声音、按键和其他生物统计或行为信号，以任何方式”</p>
<p class="translated">这种技术对欧盟公民的基本权利和自由——比如隐私和法律下的平等待遇——太有害了，不允许使用。</p>
<p class="translated">EDPB 负责确保欧盟隐私规则的统一应用，而 EDPS 监督欧盟机构遵守数据保护法的情况，并向欧盟委员会提供立法指导。</p>
<p class="translated">欧盟立法者关于监管人工智能应用的提案草案包含了对执法部门在公共场所使用生物识别监控的限制——但豁免范围非常广泛，这很快招致了数字权利和民间社会团体以及一些欧洲议会议员的主要批评。</p>
<p class="translated">EDPS 本人也<a href="https://web.archive.org/web/20230112193908/https://techcrunch.com/2021/04/23/eus-top-data-protection-supervisor-urges-ban-on-facial-recognition-in-public/">迅速敦促重新考虑</a>。现在他走得更远了，EDPB 也加入了批评的行列。</p>

<p class="translated">EDPB 和 EDPS 共同充实了对欧盟人工智能提案的一些担忧——同时欢迎欧盟立法者采取的整体“基于风险的方法”——例如，立法者必须小心确保与欧盟现有的数据保护框架保持一致，以避免权利风险。</p>
<p class="translated">“EDPB 和 EDPS 热烈欢迎在欧洲联盟内解决人工智能系统使用问题的目标，包括欧盟机构、团体或机关使用人工智能系统。与此同时，EDPB 和 EDPS 担心国际执法合作被排除在提案范围之外，”他们写道。</p>
<p class="translated">“EDPB 和 EDPS 还强调，需要明确澄清现有的欧盟数据保护立法(GDPR、欧盟数据保护条例和欧洲数据保护条例)适用于 AI 条例草案范围内的任何个人数据处理。”</p>
<p class="translated">除了呼吁在公共场合禁止使用生物识别监控，这两人还敦促全面禁止人工智能系统使用生物识别技术将个人分类为“基于种族、性别、政治或性取向或《基本权利宪章》第 21 条禁止歧视的其他理由的群体”。</p>
<p class="translated">鉴于谷歌在广告技术领域的努力，这是一个有趣的担忧，即根据用户的兴趣，用针对用户群(或群体)的广告取代个人的行为微观营销——这些网络用户群将由谷歌的人工智能算法定义。</p>
<p class="translated">(因此，推测<a href="https://web.archive.org/web/20230112193908/https://techcrunch.com/2021/03/24/google-isnt-testing-flocs-in-europe-yet/"> FLoCs </a>是否有造成法律歧视的风险是很有趣的——基于个人移动用户为了广告定位的目的而被分组的方式。当然，<a href="https://web.archive.org/web/20230112193908/https://www.eff.org/deeplinks/2021/03/googles-floc-terrible-idea">对群体扩大偏见和掠夺性广告的可能性的担忧</a>已经上升。有趣的是，谷歌避免在欧洲进行早期测试，可能是因为欧盟的数据保护制度。)</p>

<p class="translated">在今天的另一份建议中，EDPB 和 EDPS 也表达了一种观点，即使用人工智能来推断自然人的情绪是“非常不可取的，应该被禁止”——除非他们描述为“非常特定的情况，如一些健康目的，其中患者情绪识别很重要”。</p>
<p class="translated">“应该禁止将人工智能用于任何类型的社会评分，”他们继续说道——这触及了欧盟委员会的提案草案确实建议应该完全禁止的一个用例，欧盟立法者显然希望避免任何中国式的社会信用体系在该地区扎根。</p>
<p class="translated">然而，由于未能在拟议的法规中禁止公共场合的生物识别监控，欧盟委员会可能会冒着这样一个系统被偷偷开发的风险——即没有禁止私人行为者部署可用于远程和集体跟踪和描述人们行为的技术。</p>
<p class="translated">EDPB 主席 Andrea Jelinek 和 Wiewiórowski 在一份声明中评论说，他们也有同样的观点，他们写道:</p>
<blockquote><p class="translated">在公众可进入的空间部署远程生物识别意味着这些地方匿名性的终结。实时面部识别等应用会干扰基本权利和自由，以至于质疑这些权利和自由的本质。这要求立即采用预防方法。<strong>如果我们想保护我们的自由，并为人工智能创造一个以人为本的法律框架，全面禁止在公共场所使用面部识别是必要的起点。</strong>拟议法规还应禁止任何类型的利用人工智能进行社会评分，因为这违背了欧盟的基本价值观，并可能导致歧视。</p></blockquote>
<p class="translated">在他们的联合意见中，他们还对欧盟委员会提议的人工智能法规的执行结构表示关切，认为(成员国内部的)数据保护机构应被指定为国家监管机构(“根据[人工智能]提案第 59 条”)——指出欧盟 DPA 已经在对涉及个人数据的人工智能系统执行 GDPR(一般数据保护法规)和 LED(执法指令)；并认为，如果赋予他们监管人工智能法规的权限，这将是“一种更协调的监管方法，并有助于整个欧盟对数据处理条款的一致解释”。</p>
<p class="translated">他们也不满意委员会让自己在计划中的欧洲人工智能委员会(EAIB)中占据主导地位的计划——认为这“与独立于任何政治影响的人工智能欧洲机构的需要相冲突”。他们补充称，为了确保董事会的独立性，该提案应该给予它更多的自主权，并“确保它能够主动行动”。</p>
<p class="translated">已联系该委员会置评。</p>
<p class="translated"><strong>更新:</strong>该委员会的一名发言人指出，GDPR 原则上已经禁止使用远程生物识别系统进行身份识别，除非有有限的例外情况适用。(例如出于重大公共利益的原因。)</p>
<p class="translated">该官员还指出，任何此类特殊用途都必须以欧盟或国内法为依据，才算合法；有正当理由、相称并受到充分保障；并且还必须遵守《欧盟基本权利宪章》。</p>
<p class="translated">这位发言人告诉我们:“有了新的规定，我们希望建立数据保护法律的补充规则，而不是禁止一些事先已经被禁止的东西(某些狭隘的例外)。”。</p>
<p class="translated">“出于执法目的，我们建议禁止在公共场所使用实时远程生物识别系统，这些场所并非绝对需要保护详尽列出的执法目的(关于犯罪受害者，如失踪儿童；对生命和人身安全的具体和紧迫威胁，如即将发生的恐怖袭击；或者调查/检测有限的严重犯罪清单)。</p>
<p class="translated">“这导致了一种全面的欧盟方法，它提供了足够的保护，并将这些系统的使用限制在保护压倒一切的公共利益所必需和相称的严格最低限度。”</p>
<p class="translated">“GDPR 列出了几个理由，可以证明这种处理‘特殊类别’的个人数据，包括生物特征数据，”他们补充说。“这里的一个主要相关理由是‘基于欧盟或国内法的重大公共利益’。法律必须与追求的目标相称，尊重数据保护权的实质，并提供适当的保障。</p>
<p class="translated">“执法指令还列出了几个理由，最相关的一个是‘欧盟或国家法律授权’。根据执法指令，只有在绝对必要的情况下，并在对数据主体的权利和自由采取适当保护措施的情况下，才能处理‘敏感数据’。”</p>
<p class="translated">该委员会官员还指出了“执法领域之外的一些有益应用”，他们认为生物识别监控可以提供公益，例如帮助视力障碍者——称这就是为什么它选择了“更差异化的方法”，并决定反对彻底禁止。</p>

<p class="translated">人工智能法规是欧盟立法者最近几个月公布的一系列数字提案之一。随着欧盟努力采纳新的数字规则，不同欧盟机构之间的谈判——以及来自行业和民间社会的游说——仍在继续。</p>
<p class="translated">在另一个最近的相关发展中，英国信息专员上周就大数据监视系统构成的威胁发出了警告，这些系统能够利用像实时面部识别这样的技术——尽管她声称她无权认可或禁止一项技术。</p>
<p class="translated">但她的观点清楚地表明，生物识别监控的许多应用可能与英国的隐私和数据保护框架不兼容。</p>




			</div>

			</div>    
</body>
</html>