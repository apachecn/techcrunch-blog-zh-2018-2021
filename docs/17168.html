<html>
<head>
<title>New Apple technology will warn parents and children about sexually explicit photos in Messages </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">苹果新技术将警告父母和孩子短信中的露骨色情照片</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2021/08/05/new-apple-technology-will-warn-parents-and-children-about-sexually-explicit-photos-in-messages/">https://web.archive.org/web/https://techcrunch.com/2021/08/05/new-apple-technology-will-warn-parents-and-children-about-sexually-explicit-photos-in-messages/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">苹果今年晚些时候将推出新工具，如果孩子通过 Messages 应用程序发送或接收露骨的色情照片，这些工具将警告孩子和父母。该功能是苹果推出的几项新技术的一部分，旨在限制儿童性虐待材料(CSAM)在苹果平台和服务上的传播。</p>
<p class="translated">该公司表示，作为这些发展的一部分，苹果<a href="https://web.archive.org/web/20230309045432/https://techcrunch.com/2021/08/05/apple-icloud-photos-scanning/">将能够在 iPhone 和 iPad 等移动设备上以及上传到 iCloud 的照片中检测到已知的 CSAM 图像，同时仍然尊重消费者隐私。</a></p>
<p class="translated">与此同时，新的信息功能旨在帮助父母在帮助孩子学习网上交流时扮演更积极、更知情的角色。通过今年晚些时候推出的软件更新，Messages 将能够使用设备上的机器学习来分析图像附件，并确定共享的照片是否有色情内容。这项技术不需要苹果访问或读取孩子的私人通信，因为所有的处理都发生在设备上。没有任何东西被传回云中的苹果服务器。</p>
<p class="translated">如果在邮件主题中发现敏感照片，该图像将被阻止，照片下方将出现一个标签，说明“这可能是敏感的”，并带有一个链接，单击该链接可查看照片。如果孩子选择查看照片，则会出现另一个屏幕，显示更多信息。在这里，有一条消息通知孩子，敏感的照片和视频“显示了你用泳衣遮盖的私人身体部位”，“这不是你的错，但敏感的照片和视频可能会被用来伤害你。”</p>
<p class="translated">这也表明照片或视频中的人可能不希望它被看到，它可能已经在他们不知情的情况下被分享了。</p>
<p/><div id="attachment_2186143" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2186143" decoding="async" class="size-large wp-image-2186143" src="../Images/fb250640f1362c69ca3034fb3eb291e2.png" alt="" srcset="https://web.archive.org/web/20230309045432im_/https://techcrunch.com/wp-content/uploads/2021/08/messages-sensitive-material.png 2046w, https://web.archive.org/web/20230309045432im_/https://techcrunch.com/wp-content/uploads/2021/08/messages-sensitive-material.png?resize=150,78 150w, https://web.archive.org/web/20230309045432im_/https://techcrunch.com/wp-content/uploads/2021/08/messages-sensitive-material.png?resize=300,157 300w, https://web.archive.org/web/20230309045432im_/https://techcrunch.com/wp-content/uploads/2021/08/messages-sensitive-material.png?resize=768,402 768w, https://web.archive.org/web/20230309045432im_/https://techcrunch.com/wp-content/uploads/2021/08/messages-sensitive-material.png?resize=680,356 680w, https://web.archive.org/web/20230309045432im_/https://techcrunch.com/wp-content/uploads/2021/08/messages-sensitive-material.png?resize=1536,803 1536w, https://web.archive.org/web/20230309045432im_/https://techcrunch.com/wp-content/uploads/2021/08/messages-sensitive-material.png?resize=1200,628 1200w, https://web.archive.org/web/20230309045432im_/https://techcrunch.com/wp-content/uploads/2021/08/messages-sensitive-material.png?resize=50,26 50w" sizes="(max-width: 680px) 100vw, 680px" data-original-src="https://web.archive.org/web/20230309045432im_/https://techcrunch.com/wp-content/uploads/2021/08/messages-sensitive-material.png?w=680"/><p id="caption-attachment-2186143" class="wp-caption-text translated"><strong>图片来源:</strong>苹果</p></div>
<p class="translated">这些警告旨在帮助引导孩子做出正确的决定，选择不观看这些内容。</p><p class="piano-inline-promo"/>
<p class="translated">然而，如果孩子点击查看照片，他们将会看到一个额外的屏幕，通知他们如果他们选择查看照片，他们的父母将会收到通知。屏幕还解释说，他们的父母希望他们安全，并建议孩子在感到压力时与人交谈。它还提供了获得帮助的更多资源的链接。</p>
<p class="translated">屏幕底部仍然有一个选项来查看照片，但同样，这不是默认选择。相反，屏幕被设计成高亮显示<em>而不是</em>查看照片的选项。</p>
<p class="translated">这些类型的功能可以帮助保护儿童免受性侵犯，不仅通过引入中断通信并提供建议和资源的技术，还因为该系统会提醒父母。在许多孩子被捕食者伤害的案例中，父母甚至没有意识到孩子已经开始在网上或通过电话与捕食者交谈。这是因为<a href="https://web.archive.org/web/20230309045432/https://www.bark.us/blog/grooming-signs-sexual-predators/">儿童掠夺者非常控制欲强</a>，他们会试图获得孩子的信任，然后将孩子与父母隔离，这样他们就会对交流保密。在其他情况下，捕食者<a href="https://web.archive.org/web/20230309045432/https://www.sexualassaultvictimlawyers.com/the-grooming-process-how-sexual-predators-con-you-and-your-child/">也训练父母</a>。</p>
<p class="translated">在这两种情况下，苹果的技术都可以通过干预、识别和提醒被分享的明确材料来提供帮助。</p>
<p class="translated">然而，越来越多的 CSAM 材料被称为自我生成的 CSAM，或由儿童拍摄的图像，然后可能会在同意的情况下与儿童的伴侣或同龄人分享。换句话说，发色情短信或分享“裸照”根据 Thorn 公司 2019 年的一项调查，Thorn 是一家开发技术以打击儿童性剥削的公司，这种做法已经变得如此普遍，以至于 13 至 17 岁的女孩中有五分之一的人说他们分享了自己的裸体，十分之一的男孩也这样做了。但是孩子可能没有完全理解分享这些图像是如何让他们面临性虐待和性剥削的风险。</p>
<p class="translated">新的消息功能也将提供类似的保护。在这种情况下，如果孩子试图发送露骨的照片，他们会在照片发送前收到警告。如果孩子选择发送照片，家长也可以收到一条消息。</p>
<p class="translated">苹果公司表示，这项新技术将在今年晚些时候作为软件更新的一部分，在美国为 iOS 15、iPadOS 15 和 macOS Monterey 的 iCloud 家庭帐户设置。</p>
<p class="translated">此次更新还将包括对 Siri 和搜索的更新，这些更新将提供更多的指导和资源，以帮助儿童和父母保持在线安全，并在不安全的情况下获得帮助。例如，用户可以问 Siri 如何举报 CSAM 或儿童剥削。当用户搜索与 CSAM 相关的查询时，Siri 和 Search 也会进行干预，解释该主题是有害的，并提供资源以获得帮助。</p>
			</div>

			</div>    
</body>
</html>