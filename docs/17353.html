<html>
<head>
<title>How the law got it wrong with Apple Card • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">苹果卡 TechCrunch 的法律是如何出错的</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2021/08/14/how-the-law-got-it-wrong-with-apple-card/amp/">https://web.archive.org/web/https://techcrunch.com/2021/08/14/how-the-law-got-it-wrong-with-apple-card/amp/</a></blockquote><div><div class="content">

			
	
		
		

		
<p class="amp-featured-image translated"><amp-img src="https://web.archive.org/web/20230212202528im_/https://techcrunch.com/wp-content/uploads/2021/08/GettyImages-1175965941.jpg?w=1024" class="attachment-post-thumbnail size-post-thumbnail wp-post-image amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" alt="BRAZIL - 2019/10/13: In this illustration the homepage of the Apple Card website is seen displayed on the computer screen through a magnifying glass. (Photo Illustration by Rafael Henrique/SOPA Images/LightRocket via Getty Images)" srcset="https://web.archive.org/web/20230212202528im_/https://techcrunch.com/wp-content/uploads/2021/08/GettyImages-1175965941.jpg 1024w, https://web.archive.org/web/20230212202528im_/https://techcrunch.com/wp-content/uploads/2021/08/GettyImages-1175965941.jpg?resize=150,100 150w, https://web.archive.org/web/20230212202528im_/https://techcrunch.com/wp-content/uploads/2021/08/GettyImages-1175965941.jpg?resize=300,200 300w, https://web.archive.org/web/20230212202528im_/https://techcrunch.com/wp-content/uploads/2021/08/GettyImages-1175965941.jpg?resize=768,512 768w, https://web.archive.org/web/20230212202528im_/https://techcrunch.com/wp-content/uploads/2021/08/GettyImages-1175965941.jpg?resize=680,454 680w, https://web.archive.org/web/20230212202528im_/https://techcrunch.com/wp-content/uploads/2021/08/GettyImages-1175965941.jpg?resize=50,33 50w" layout="intrinsic" i-amphtml-layout="intrinsic"> <i-amphtml-sizer class="i-amphtml-sizer"> <img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src=""/> </i-amphtml-sizer> <noscript> <img src="../Images/91b8fa16f622c23906c33149c352fc1d.png" class="attachment-post-thumbnail size-post-thumbnail wp-post-image" alt="BRAZIL - 2019/10/13: In this illustration the homepage of the Apple Card website is seen displayed on the computer screen through a magnifying glass. (Photo Illustration by Rafael Henrique/SOPA Images/LightRocket via Getty Images)" decoding="async" loading="lazy" srcset="https://web.archive.org/web/20230212202528im_/https://techcrunch.com/wp-content/uploads/2021/08/GettyImages-1175965941.jpg 1024w, https://web.archive.org/web/20230212202528im_/https://techcrunch.com/wp-content/uploads/2021/08/GettyImages-1175965941.jpg?resize=150,100 150w, https://web.archive.org/web/20230212202528im_/https://techcrunch.com/wp-content/uploads/2021/08/GettyImages-1175965941.jpg?resize=300,200 300w, https://web.archive.org/web/20230212202528im_/https://techcrunch.com/wp-content/uploads/2021/08/GettyImages-1175965941.jpg?resize=768,512 768w, https://web.archive.org/web/20230212202528im_/https://techcrunch.com/wp-content/uploads/2021/08/GettyImages-1175965941.jpg?resize=680,454 680w, https://web.archive.org/web/20230212202528im_/https://techcrunch.com/wp-content/uploads/2021/08/GettyImages-1175965941.jpg?resize=50,33 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230212202528im_/https://techcrunch.com/wp-content/uploads/2021/08/GettyImages-1175965941.jpg?w=1024"/> </noscript> </amp-img></p><p class="translated"><strong>图片来源:</strong> <a href="https://web.archive.org/web/20230212202528/https://www.gettyimages.com/search/photographer?family=editorial&amp;photographer=SOPA+Images" target="_blank"> SOPA 图片</a> / Getty Images</p><div class="article__contributor-byline-wrapper">
<div class="article__contributor-byline">
	<div class="contributor-byline__contributor">
		<p class="byline__author translated"><span class="byline__author-name">利兹·奥沙利文</span><span class="byline__author-title amp-wp-19fae44" data-amp-original-style="display: block;">撰稿人</span></p>

				
			</div>

		<div class="contributor-byline__bio"><p class="translated">利兹·奥沙利文是</p><a href="https://web.archive.org/web/20230212202528/http://www.getparity.ai/">Parity</a><p class="translated">，一个为企业自动化模型风险和算法治理的平台。她还建议监督技术监督项目和运动，以停止所有人工智能的黑仔机器人。</p></div>
	
		<div class="contributor-byline__more-articles">
		<span class="more-articles-title">More posts by this contributor</span>
		
	</div>
	</div>
</div><p class="translated">算法正义的倡导者已经开始看到他们众所周知的“上法庭的日子”，对像 UHG 和苹果卡这样的企业进行法律调查。苹果卡案件是一个强有力的例子，表明当前的反歧视法律跟不上可量化公平这一新兴领域的科学研究的快速步伐。</p>
<p class="translated">虽然苹果和他们的承销商被发现没有违反公平贷款规定，这可能是事实，但这项裁决带有明确的警告，应该是对在任何监管空间内使用机器学习的企业的警告。除非高管们开始更认真地对待算法的公平性，否则他们未来的日子将充满法律挑战和名誉损害。</p>
<h2 class="translated">苹果卡怎么了？</h2>
<p class="translated">2019 年末，初创公司领导人和社交媒体名人大卫·海涅迈尔·汉森在<a href="https://web.archive.org/web/20230212202528/https://twitter.com/dhh/status/1192540900393705474?lang=en"> Twitter </a>上提出了一个重要问题，引起了广泛关注和掌声。在近 5 万个赞和转发中，他要求苹果公司和他们的承销合作伙伴高盛解释为什么他和他的妻子拥有相同的财务能力，却被授予不同的信用额度。对于算法公平领域的许多人来说，这是一个分水岭时刻，我们倡导的问题成为主流，在纽约金融服务局(DFS)的调查中达到高潮。</p>
<p class="translated">乍看之下，信贷承销商可能会感到振奋，因为 DFS 在 3 月份得出结论，高盛的承销算法没有违反 1974 年为保护妇女和少数族裔免受贷款歧视而制定的严格的金融准入规则。虽然这一结果令活动人士感到失望，但对于我们这些在金融领域与数据团队密切合作的人来说，并不意外。</p>
<p class="translated">在金融机构的一些算法应用中，实验的风险远远大于任何收益，信用承销就是其中之一。我们本可以预测高盛会被判无罪，因为公平借贷的法律(如果已经过时的话)是明确的,<a href="https://web.archive.org/web/20230212202528/https://www.nytimes.com/2020/10/07/business/citigroup-fine-risk-management.html">严格执行。</a></p>
<p class="translated">然而，在我看来，毫无疑问的是，高盛/苹果算法以及当今市场上所有其他的信用评分和承销算法都具有歧视性。我也不怀疑，如果研究人员被允许访问我们验证这一说法所需的模型和数据，这些算法将会崩溃。我知道这一点，因为<a href="https://web.archive.org/web/20230212202528/https://www.dfs.ny.gov/system/files/documents/2021/03/rpt_202103_apple_card_investigation.pdf">纽约 DFS 部分发布了</a>其审核高盛算法的方法，正如你可能预期的那样，他们的审计远远低于当今现代算法审计师所持有的标准。</p>
<h2 class="translated">DFS(现行法律下)是如何评估 Apple 卡的公平性的？</h2>
<p class="translated">为了证明苹果的算法是“公平的”，DFS 首先考虑高盛是否使用了潜在申请人的“禁止特征”，如性别或婚姻状况。这一条对高盛来说很容易通过——他们没有将种族、性别或婚姻状况作为模型的输入。然而，多年来我们已经知道，一些模型特性可以充当受保护类的<a href="https://web.archive.org/web/20230212202528/https://abcnews.go.com/GMA/story?id=2623263&amp;page=1">“代理”</a>。</p>
<p>	</p><div class="article-block block--pullout block--right">
		<blockquote class="translated">例如，如果你是黑人、女性和孕妇，你获得信贷的可能性可能会低于所有受保护类别的平均水平。</blockquote>
	</div>
	
<p class="translated">基于 50 年法律先例的 DFS 方法论没有提到他们是否考虑过这个问题，但我们可以猜测他们没有。因为如果他们有，他们会很快发现<a href="https://web.archive.org/web/20230212202528/https://shiftprocessing.com/credit-score/#race">信用评分</a>与种族紧密相关，以至于一些州正在考虑禁止它用于<a href="https://web.archive.org/web/20230212202528/https://news.bloomberglaw.com/insurance/credit-based-insurance-premiums-raise-concerns-about-racial-bias">意外保险</a>。代理功能只是最近才进入研究的聚光灯下，给了我们第一个科学如何超越监管的例子。</p>
<p class="translated">在没有受保护特征的情况下，DFS 然后寻找内容相似但属于不同受保护类别的人的信用档案。从某种不精确的意义上来说，他们试图找出如果我们在申请中“翻转”性别，信贷决策会发生什么。男性申请人的女性版本会得到同样的待遇吗？</p>
<p class="translated">直觉上，这似乎是定义“公平”的一种方式。在机器学习公平领域，有一个叫做<a href="https://web.archive.org/web/20230212202528/https://dl.acm.org/doi/abs/10.1145/3351095.3372845">【翻转测试】</a>的概念，它是一个叫做<a href="https://web.archive.org/web/20230212202528/https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3819799">【个体公平】</a>的概念的众多衡量标准之一，听起来确实如此。我向领先的精品人工智能律师事务所 bnh.ai 的首席科学家帕特里克霍尔(Patrick Hall)询问了调查公平贷款案件时最常见的分析。在提到 DFS 用来审计 Apple Card 的方法时，他称之为基本回归，或“1970 年代版本的翻转测试”，给我们带来了不充分法律的第二个例子。</p>
<h2 class="translated">算法公平的新词汇</h2>
<p class="translated">自 2016 年 Solon Barocas 的开创性论文<a href="https://web.archive.org/web/20230212202528/http://www.californialawreview.org/wp-content/uploads/2016/06/2Barocas-Selbst.pdf">“大数据的不同影响”</a>以来，研究人员一直在努力将核心哲学概念定义为数学术语。几个会议<a href="https://web.archive.org/web/20230212202528/https://facctconference.org/">涌现出来，在最著名的人工智能事件中出现了新的公平轨道。这个领域正处于</a><a href="https://web.archive.org/web/20230212202528/https://blog.einstein.ai/ethics-in-ai-research-papers-and-articles/">高速增长的时期</a>，法律还没有跟上步伐。但是就像发生在网络安全行业的事情一样，这种法律上的暂缓不会永远持续下去。</p>
<p class="translated">也许我们可以原谅 DFS 的垒球审计，因为管理公平贷款的法律诞生于民权运动，自诞生以来的 50 多年里没有发生太大变化。早在机器学习公平性研究真正起飞之前，法律先例就已经确立了。如果 DFS 有适当的装备来应对评估苹果卡公平性的挑战，他们就会使用<a href="https://web.archive.org/web/20230212202528/https://www.frontiersin.org/articles/10.3389/frai.2021.695301/full">强大的词汇</a>进行算法评估，这种评估在过去五年中已经开花结果。</p>
<p class="translated">例如，DFS 的报告没有提到衡量“均等赔率”，这是一个臭名昭著的调查路线，最早于 2018 年由 Joy Buolamwini，Timnit Gebru 和 Deb Raji 提出。他们的<a href="https://web.archive.org/web/20230212202528/http://gendershades.org/">“性别阴影”</a>论文证明，面部识别算法对深色女性面孔的猜错率高于对浅色皮肤受试者的猜错率，这一推理适用于除计算机视觉以外的许多预测应用。</p>
<p class="translated">均等赔率会问苹果的算法:它能多长时间正确预测信用度？它猜错的频率有多高？在不同性别、种族或残疾状况的人群中，这些错误率是否存在差异？据霍尔说，这些措施很重要，但太新了，还不能完全编入法律体系。</p>
<p class="translated">如果事实证明高盛经常低估现实世界中的女性申请人，或者分配的利率高于黑人申请人真正应得的利率，那么很容易看出这将如何在全国范围内伤害这些得不到充分服务的人群。</p>
<h2 class="translated">金融服务业的“第 22 条军规”</h2>
<p class="translated">现代审计人员知道，法律先例规定的方法未能捕捉到少数类别内交叉组合的公平性方面的细微差别——这个问题因机器学习模型的复杂性而加剧。例如，如果你是黑人、女性和孕妇，你获得信贷的可能性可能会低于所有受保护类别的平均水平。</p>
<p class="translated">如果不特别关注这些代表性不足的群体的独特性，他们可能永远也不会从系统的整体审计中受益，因为从定义上来说，少数群体的样本规模在整个系统中是一个较小的数字。这就是为什么现代审计师更喜欢<a href="https://web.archive.org/web/20230212202528/https://arxiv.org/pdf/1104.3913.pdf">【通过认知实现公平】</a>的方法，这种方法允许我们在明确了解每个群体中个人的人口统计数据的情况下衡量结果。</p>
<p class="translated">但是有一个第二十二条军规。在金融服务和其他高度监管的领域，审计人员通常不能使用“通过意识实现公平”，因为他们可能从一开始就被阻止收集敏感信息。这一法律约束的目的是防止贷款人受到歧视。在命运的残酷扭曲中，这个<a href="https://web.archive.org/web/20230212202528/https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/?utm_source=WIR_REG_GATE">为算法歧视提供了掩护</a>，给了我们第三个法律不完善的例子。</p>

<p class="translated">事实上，我们无法收集这些信息，这阻碍了我们发现模型如何对待服务不足群体的能力。没有它，我们可能永远无法在实践中证明我们所知道的事实——例如，全职妈妈的信用档案会更薄，因为她们不会以配偶双方的名义进行每一笔基于信用的购物。少数群体更有可能做零工、给员工小费或参与以现金为基础的行业，这导致他们的收入状况具有共性，而对大多数人来说却不那么常见。</p>
<p class="translated">重要的是，申请人信用档案上的这些差异并不一定转化为真正的财务责任或信誉。如果你的目标是准确预测信用度，你会想知道这个方法(例如，信用评分)在哪里失效。</p>
<h2 class="translated">这对使用人工智能的企业意味着什么</h2>
<p class="translated">在苹果的例子中，值得一提的是故事的一个充满希望的尾声，苹果对他们的信贷政策进行了<a href="https://web.archive.org/web/20230212202528/https://techcrunch.com/2021/04/20/apple-announces-apple-card-family-for-spouses-to-build-credit-together-and-over-13s-to-use-it-too/">相应的更新</a>，以打击受我们过时的法律保护的歧视。在苹果首席执行官蒂姆·库克的声明中，他很快强调了“行业[计算]信用评分的方式缺乏公平性。”</p>
<p class="translated">他们的新政策允许配偶或父母合并信用档案，这样较弱的信用档案可以从较强的信用档案中受益。这是一个很好的例子，说明一家公司提前考虑采取措施，实际上可能会减少我们世界中结构性存在的歧视。在更新他们的政策时，苹果走在了监管的前面，这可能是这次调查的结果。</p>
<p class="translated">这对苹果公司来说是一个战略优势，因为纽约 DFS 详尽地提到了这个领域现行法律的不足，这意味着监管的更新可能比许多人想象的要快。引用金融服务局局长 Linda A. Lacewell 的话来说:“目前形式的信用评分的使用以及禁止贷款歧视的法律和法规需要加强和现代化。”根据我自己与监管机构合作的经验，这是今天的 T2 当局非常热衷于探索的事情。</p>
<p class="translated">我毫不怀疑美国监管机构正在努力改善管理人工智能的法律，利用这个强大的自动化和数学平等词汇。T4、美联储、OCC、CFPB、联邦贸易委员会和国会都渴望解决算法歧视问题，尽管他们的步伐很慢。</p>
<p class="translated">与此同时，我们有充分的理由相信算法上的歧视很猖獗，主要是因为这个行业在接受过去几年带来的学术语言方面也很慢。企业没有理由不利用这一新的公平领域，也没有理由不根除在某种程度上得到保证的预测性歧视。欧盟<a href="https://web.archive.org/web/20230212202528/https://digital-strategy.ec.europa.eu/en/news/europe-fit-digital-age-commission-proposes-new-rules-and-actions-excellence-and-trust-artificial">同意</a>，专门适用于人工智能的法律草案将在未来两年内通过。</p>
<p class="translated">机器学习公平领域已经很快成熟，每年都有新技术被发现，有无数的<a href="https://web.archive.org/web/20230212202528/https://techcrunch.com/2020/12/09/arthur-ai-snags-15m-series-a-to-grow-machine-learning-monitoring-tool/">工具</a>提供帮助。这一领域现在才达到可以用某种程度的<a href="https://web.archive.org/web/20230212202528/https://www.getparity.ai/">自动化</a>来规定这一点。<a href="https://web.archive.org/web/20230212202528/https://www.responsible.ai/">标准机构</a>已经介入提供指导，以降低这些问题的频率和严重性，即使美国法律的采纳速度缓慢。</p>
<p class="translated">因为不管算法歧视是不是故意的，都是违法的。因此，任何将高级分析用于医疗保健、住房、招聘、金融服务、教育或政府相关应用的人都可能在不知情的情况下违反这些法律。</p>
<p class="translated">在对人工智能在敏感情况下的无数应用提供更清晰的监管指导之前，该行业只能靠自己来找出公平的最佳定义。</p>



		

			
	
		

			<amp-pixel src="https://web.archive.org/web/20230212202528im_/https://ampmetrics.techcrunch.com/pixel.gif" placeholder="" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/>
		<amp-analytics data-credentials="include" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed">
		
	</amp-analytics>
	<amp-pixel src="https://web.archive.org/web/20230212202528im_/https://pixel.wp.com/g.gif?v=ext&amp;blog=136296444&amp;post=2189615&amp;tz=-8&amp;srv=techcrunch.com&amp;host=techcrunch.com&amp;rand=RANDOM&amp;ref=DOCUMENT_REFERRER" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/><amp-analytics id="tc_googleanalytics" type="googleanalytics" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/><amp-analytics id="tc_comscore" type="comscore" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/><amp-analytics id="tc_parsely" type="parsely" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/>	</div>

</div>    
</body>
</html>