<html>
<head>
<title>NVIDIA's latest tech makes AI voices more expressive and realistic • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">英伟达的最新技术使人工智能的声音更具表现力和真实感 TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2021/08/31/nvidias-latest-tech-makes-ai-voices-more-expressive-and-realistic/">https://web.archive.org/web/https://techcrunch.com/2021/08/31/nvidias-latest-tech-makes-ai-voices-more-expressive-and-realistic/</a></blockquote><div><header class="article__header ">
	<p class="article__title-wrapper">
						</p><h1 class="article__title translated">英伟达的最新技术使人工智能的声音更具表现力和真实感</h1>
		

			
	
			
	</header>

			<div class="article-content">
				<div class="article__contributor-byline-wrapper">
<div class="article__contributor-byline">
	

		<div class="contributor-byline__bio"><p class="translated">史蒂夫·登特是</p><a href="https://web.archive.org/web/20221007042656/https://www.engadget.com/">Engadget</a><p>.	</p></div>
	
		<div class="contributor-byline__more-articles">
		<span class="more-articles-title">More posts by this contributor</span>
		
	</div>
	</div>
</div><p id="speakable-summary" class="translated">亚马逊的 Alexa、谷歌助手和其他人工智能助手的声音远远领先于老派的 GPS 设备，但它们仍然缺乏节奏、语调和其他使语音听起来像人类的品质。NVIDIA 公司在<a href="https://web.archive.org/web/20221007042656/https://www.interspeech2021.org/" target="_blank" rel="noopener" data-ylk="elm:context_link;itc:0" data-rapid_p="19" data-v9y="1"> Interspeech 2021 </a>大会上宣布，该公司推出了新的研究和工具，可以通过让你用自己的声音训练人工智能系统来捕捉这些自然语音质量。</p>
<p class="translated">为了改善其人工智能语音合成，英伟达的文本到语音研究团队开发了一个名为 RAD-TTS 的模型，这是一个在 NAB 广播大会竞赛中获奖的项目，旨在开发最真实的化身。该系统允许个人用自己的声音训练文本到语音的模型，包括语速、音调、音色等。</p>
<p class="embed breakout embed--video embed--youtube translated"><iframe title="All the Feels: NVIDIA Shares Expressive Speech Synthesis Research at Interspeech" src="https://web.archive.org/web/20221007042656if_/https://www.youtube.com/embed/RknIx6XmffA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">视频</iframe></p>
<p class="translated">RAD-TTS 的另一个功能是语音转换，它允许用户用另一个人的声音传递一个人的话。该界面对合成语音的音高、持续时间和能量进行精细的帧级控制。</p>
<p class="translated">使用这项技术，英伟达的研究人员为其自己的<a href="https://web.archive.org/web/20221007042656/https://www.youtube.com/playlist?list=PLZHnYvH1qtObE_PjzaAFqS_CpmumGx5cW" target="_blank" rel="noopener" data-ylk="elm:context_link;itc:0" data-rapid_p="21" data-v9y="1">我是人工智能视频系列</a>创建了更多听起来像对话的语音旁白，使用合成而不是人类的声音。目的是让旁白与视频的语气和风格相匹配，迄今为止，许多人工智能旁白视频都没有做到这一点。结果仍然有点机器人化，但比我听过的任何人工智能解说都要好。</p>
<p class="translated">“通过这个界面，我们的视频制作人可以记录自己阅读视频脚本，然后使用人工智能模型将他的讲话转换为女性解说员的声音。使用这种基线旁白，制片人可以像配音演员一样指导人工智能——调整合成语音以强调特定的单词，并修改旁白的节奏以更好地表达视频的语气，”英伟达写道。</p>
<p class="translated">NVIDIA 正在向任何想通过开源的 NVIDIA NeMo Python toolkit for GPU-accelerated conversatile AI 进行尝试的人分发一些这项研究——当然，这些研究是为了在 NVIDIA GPUs 上高效运行而优化的——该工具包位于该公司的 NGC 容器中心和其他软件上。</p>
<p class="translated">“其中几个模型在英伟达 DGX 系统上接受了数万小时的音频数据训练。该公司写道:“开发人员可以针对他们的用例微调任何模型，在英伟达张量核心 GPU 上使用混合精度计算来加速训练。”</p><p class="piano-inline-promo"/>
<p class="translated"><strong>编者按:</strong> <em>本帖原载于<a href="https://web.archive.org/web/20221007042656/https://www.engadget.com/nvidi-as-latest-tech-makes-ai-voices-more-expressive-and-realistic-130021480.html"> Engadget </a>。</em></p>
			</div>

			</div>    
</body>
</html>